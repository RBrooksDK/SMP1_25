{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"<p> Stochastic Modelling and Processes - Spring 2025 <p>Repository for SMP1-S25 at VIA</p> <p>Checkout the homepage!</p> </p> <p> </p>"},{"location":"#course-information","title":"Course information","text":"<ul> <li>Course responsible: Associate Professor Richard Brooks, rib@via.dk</li> <li>5 ECTS (European Credit Transfer System), corresponding to 130 hours of work</li> <li>11 sessions, each with a duration of 4 lessons, starting in week 6</li> <li>Bachelor level course - the course is academically challenging working on problems independently.</li> <li>Grade: 7-step scale</li> <li>Type of assessment: 4-hour written exam (see exam description in the menu to the left)</li> <li>Recommended prerequisites: In \"Sessions\" in the left menu, a dedicated entry is made for prerequisites.</li> </ul>"},{"location":"#lectures-and-course-organization","title":"Lectures and course organization","text":"<p>The course is scheduled to start in week 6 and will be held on Tuesdays from 12:45 to 16:05 in room C04.16. In general, each session is made up of four activities:</p> <ol> <li>At the beginning of each session, there will be a short recap of the previous session.</li> <li>We then go through the exercises from the previous session.</li> <li>We will go through the theory of the current session.</li> <li>After classes, and before the next session, you will have to solve exercises from the current session.</li> </ol> <p>This then loops back to (1) at the beginning of the next session.</p> <p>There are no mandatory assignments, but it is highly recommended to work on the exercises for each session. No instruction is provided for the exercises so you will have to work on them on your own or form study groups.</p>"},{"location":"#course-content-and-learning-objectives","title":"Course content and learning objectives","text":"<p>Stochastic Modelling and Processes is the art of making sense of randomness in the world around us. We examine probability theory, finding the tools to describe and analyse random systems mathematically. You'll learn about random variables \u2014 their mean, variance, and the distributions that define them \u2014 and learn how these concepts power everything from decision-making to machine learning.</p> <p>Learning Objectives</p> <ul> <li>Probability: Understand the fundamental concepts of probability theory, including experiments, sample spaces, independence, conditional probability, and Bayes' theorem. Learn to approach random systems methodically using probabilistic reasoning.</li> <li>Random Variables: Describe and analyse random systems through random variables. Understand their characteristics, including mean, variance, standard deviation, and commonly used distributions like normal, binomial, and Poisson.</li> <li>Point Estimation: Learn techniques to estimate population parameters from sample data and evaluate the quality and reliability of these estimates.</li> <li>Statistical Intervals: Construct and interpret confidence intervals for population parameters. Learn to assess the precision of estimates and their implications for statistical inference.</li> <li>Hypothesis Testing: Explore the principles of hypothesis testing. Learn to formulate null and alternative hypotheses, compute and interpret p-values, and make informed decisions based on statistical evidence.</li> <li>Regression Analysis: Investigate relationships between variables using regression models. Understand how to fit, interpret, and assess the quality of regression models for real-world data.</li> <li>Stochastic Processes: Model and analyse systems that evolve over time using stochastic processes, including applications of Markov Chains for dynamic systems.</li> <li>Python for Statistical Modelling: Gain hands-on experience with Python for data analysis, simulating random variables, conducting statistical tests, and visualizing statistical data to reinforce theoretical understanding.</li> <li>Critique and Evaluate Statistical Models: Develop the competence to critically assess statistical models and results. Identify sources of error, critique experimental designs, and propose improvements for better reliability.</li> </ul> <p>But it's not just about theory. You'll get hands-on with Python, simulating randomness, running statistical tests, and exploring applications of stochastic models. By the end, you\u2019ll not only understand how to model uncertainty but also how to use it to make informed predictions and decisions.</p>"},{"location":"#resources","title":"Resources","text":"<p>ASPE: Montgomery, D.C. &amp; Runger, G.C.. Applied Statistics and Probability for Engineers, 7<sup>th</sup> edition. All references are to chapters or exercises (found in the end of the book). Solutions to all exercises from the book are uploaded. You need to retrieve a copy however you usually retrieve books.</p> <p>Non-session specific resources such as the exercises from the book, solutions, old exam cases, etc. can be found her:</p> <p>General Resources SMP</p> <p>This folder is always accessible in the menu to the left.</p> <p>The Wiseflow code for all flows that are used during the course is always 0000. This is not the code for the actual exam in June, though.</p> <p>The course is loosely built up around H. Pishro-Nik's https://www.probabilitycourse.com/</p> <p>I have compiled and uploaded all session from January 2021 to YouTube. The link below will take you to a playlist containing all 10 sessions (theory only)</p> <p>Stochastic Modelling 2021 \u2013 All sessions</p> <p>Make sure you install a working version of Jupyter Notebook and Python version 3.7 or higher. The easiest way to install Python and Jupyter is using Anaconda Distribution. You can choose whichever framework you want to work in as long as it can handle Jupyter Notebooks. Installing VS Code with a Jupyter Notebook extension seems to be a popular choice.</p>"},{"location":"#historical-notes","title":"Historical Notes","text":"<p>Stochastic Modelling and Processes was first offered in 2014 and has been scheduled 1\u20132 times per year since. The course responsible is Richard Brooks (RIB) and has been the only lecturer teaching the course.</p> <p>Grade Distribution 2024 (ordinary exam only)</p> Grade Count 12 3 10 8 7 7 4 5 02 4 00 6 -3 1"},{"location":"00_Important_Recap/","title":"00 Prerequisties","text":"Prerequisites <p>Students taking the course are expected to have basic mathematical skills (e.g. from IT-DMA1 or IT-MSE1). The course is designed to be self-contained, but it is recommended that students have a basic understanding of the following topics:</p>"},{"location":"00_Important_Recap/#material","title":"Material","text":"<p>Session material</p>"},{"location":"00_Important_Recap/#topics","title":"Topics","text":"<p>Most of the topics can be found in our course Mathematics for Software Engineers (MSE). I have written a book for that course, and it covers the topics quite well. The references below are to the slides found in the material above as well as the book chapters that also correspond to the MSE course sessions.</p>"},{"location":"00_Important_Recap/#boolean-algebra","title":"Boolean Algebra","text":"<ul> <li>Ch. 4</li> <li>Similar to sets, so all rules also apply for sets</li> <li>Addition is same as union, multiplication the same as intersection and negation same as complement</li> <li>Important: Slide 12 about identities</li> </ul>"},{"location":"00_Important_Recap/#sets","title":"Sets","text":"<ul> <li>Ch. 5</li> <li>Basic understanding of sets</li> <li>Important: Equivalence slide 29</li> <li>You should have also gone through this in DBS1</li> </ul>"},{"location":"00_Important_Recap/#combinatorics","title":"Combinatorics","text":"<ul> <li>Ch. 5</li> <li>All rules are important, and I assume you know them</li> <li>The most used one is combinations on slide 12</li> <li>Important: Formulas Slide 12</li> </ul>"},{"location":"00_Important_Recap/#probability-1-2-23-probability-2-slide-3","title":"Probability 1 + 2 (2.3 = Probability 2 slide 3)","text":"<ul> <li>Ch. 5-6</li> <li>All rules of probability</li> <li>Important: Union 1.13, Conditional 2.2, Independence 2.3, Intersection 2.6, Law of Total Probability 2.8, Bayes\u2019 Theorem 2.10, Contingency Table 2.12, Joint Probability 2.14</li> </ul>"},{"location":"00_Important_Recap/#sequences-and-summation","title":"Sequences and Summation:","text":"<ul> <li>Appendix A</li> <li>The important part is Series from slide 19 onwards, not so much sequences (slides 1-18)</li> <li>Convergence slide 23</li> <li>Closed form formulae for series slide 24</li> <li>Useful summations and closed form slide 25</li> <li>Changing limits slide 26</li> </ul>"},{"location":"00_Important_Recap/#matrix-algebra","title":"Matrix Algebra:","text":"<ul> <li>Ch. 7-9</li> <li>Basic understanding of matrices</li> <li>Using matrices for solving systems of equations</li> <li>Inverse matrices</li> <li>Matrix exponentiation</li> </ul> <p>In Lesson 3, you will need to brush up on integrals. It seems that Khan Academy has some nice tutorials on integrals that you may want to check out:  Connecting the First and Second Fundamental Theorems of Calculus,  Antiderivative of x + 1,  and  Reverse Power Rule for Definite Integrals.</p>"},{"location":"01_Introduction_%2B_Recap_Probability_%2B_Stochastic_Variables/","title":"01 Introduction to Probability and Random Variables","text":"Introduction + Probability + Stochastic Variables"},{"location":"01_Introduction_%2B_Recap_Probability_%2B_Stochastic_Variables/#session-preparation","title":"Session Preparation:","text":"<p>ASPE: 1-2</p> <p>There are no exercises to be solved before class, since it is the first class. However, it is recommended to go through the material and make sure you understand the concepts.</p> <p>Also, check out the prerequisites for the course.</p>"},{"location":"01_Introduction_%2B_Recap_Probability_%2B_Stochastic_Variables/#session-material","title":"Session Material","text":"<p>Session Notes</p> <p>Session material</p> <p>Make sure you are acquainted with common Series, Approximations, and Identities</p> <p>Session from 20/21:</p>"},{"location":"01_Introduction_%2B_Recap_Probability_%2B_Stochastic_Variables/#session-description","title":"Session Description","text":"<p>In this session, we will look at the foundational principles of statistics and probability theory, starting with an understanding of why these fields are essential for analysing data and making predictions. We will discuss the distinction between samples and populations, along with key measures and scales of measurement. The session will introduce random experiments and the foundational concepts of probabilities.</p> <p>Building on this, we will review key concepts in probability, including types of probability, conditional probability, and conditional independence. Finally, we introduce the concept of a random variable.</p>"},{"location":"01_Introduction_%2B_Recap_Probability_%2B_Stochastic_Variables/#key-concepts","title":"Key Concepts","text":"<ul> <li>Importance of Statistics and Probability Theory</li> <li>Samples vs. Populations</li> <li>Measures and Scales of Measurement</li> <li>Random Experiments and Probabilities</li> <li>Types of Probability</li> <li>Conditional Probability</li> <li>Conditional Independence</li> <li>Expectation and Variance</li> <li>Independent Random Variables</li> <li>Functions of Random Variables</li> </ul>"},{"location":"01_Introduction_%2B_Recap_Probability_%2B_Stochastic_Variables/#exercises","title":"Exercises","text":"<p>Full solutions to the Exam case exercises (8-10) can be found in the general resource folder</p>"},{"location":"01_Introduction_%2B_Recap_Probability_%2B_Stochastic_Variables/#exercise-1","title":"Exercise 1","text":"<p>Heart failures are due to either natural occurrences (87%) or outside factors (13%). Outside factors are related to induced substances (73%) or foreign objects (27%). Natural occurrences are caused by arterial blockage (56%), disease (27%), and infection (e.g., staph infection) (17%).</p> <ol> <li> <p>Determine the probability that a failure is due to an induced substance.</p> </li> <li> <p>Determine the probability that a failure is due to disease or infection.</p> </li> </ol> Answer <ol> <li> <p>\\(P(\\text{induced substance}) = 0.13 \\times 0.73 = 0.0949\\)</p> </li> <li> <p>\\(P(\\text{disease or infection}) = 0.87\\times (0.27+0.17) = 0.3828\\)</p> </li> </ol>"},{"location":"01_Introduction_%2B_Recap_Probability_%2B_Stochastic_Variables/#exercise-2","title":"Exercise 2","text":"<p>Computer keyboard failures are due to faulty electrical connects (12%) or mechanical defects (88%). Mechanical defects are related to loose keys (27%) or improper assembly (73%). Electrical connect defects are caused by defective wires (35%), improper connections (13%), or poorly welded wires (52%).</p> <ol> <li> <p>Find the probability that a failure is due to loose keys.</p> </li> <li> <p>Find the probability that a failure is due to improperly connected or poorly welded wires.</p> </li> </ol> Answer <ol> <li> <p>\\(P(\\text{loose keys}) = 0.88 \\times 0.27 = 0.2376\\)</p> </li> <li> <p>\\(P(\\text{improperly connected or poorly welded wires}) = 0.12 \\times (0.13 + 0.52) = 0.078\\)</p> </li> </ol>"},{"location":"01_Introduction_%2B_Recap_Probability_%2B_Stochastic_Variables/#exercise-3","title":"Exercise 3","text":"<p>Two teams \\(A\\) and \\(B\\) play a football match, and we are interested in the winner. The sample space can be defined as:  </p> \\[ S = \\{a, b, d\\} \\] <p>where \\(a\\) shows the outcome that \\(A\\) wins, \\(b\\) shows the outcome that \\(B\\) wins, and \\(d\\) shows the outcome that they draw. Suppose that we know that:</p> <ul> <li>The probability that \\(A\\) wins is \\(P(a) = P(\\{a\\}) = 0.5\\).  </li> <li>The probability of a draw is \\(P(d) = P(\\{d\\}) = 0.25\\).</li> </ul> <p>Based on this,</p> <ol> <li> <p>Find the probability that \\(B\\) wins.</p> </li> <li> <p>Find the probability that \\(B\\) wins or a draw occurs.</p> </li> </ol> Answer <ol> <li> <p>\\(P(b) = 1 - P(a) - P(d) = 1 - 0.5 - 0.25 = 0.25\\)</p> </li> <li> <p>\\(P(b \\cup d) = P(b) + P(d) = 0.25 + 0.25 = 0.5\\)</p> </li> </ol>"},{"location":"01_Introduction_%2B_Recap_Probability_%2B_Stochastic_Variables/#exercise-4","title":"Exercise 4","text":"<p>Let \\(A\\) and \\(B\\) be two events such that:  </p> \\[     P(A) = 0.4, \\quad P(B) = 0.7, \\quad P(A \\cup B) = 0.9 \\] <ol> <li> <p>Find \\(P(A \\cap B)\\).</p> </li> <li> <p>Find \\(P(A^c \\cap B)\\).</p> </li> <li> <p>Find \\(P(A - B)\\).</p> </li> <li> <p>Find \\(P(A^c - B)\\).</p> </li> <li> <p>Find \\(P(A^c \\cup B)\\).</p> </li> <li> <p>Find \\(P(A \\cap (B \\cup A^c))\\).</p> </li> </ol> Answer <ol> <li> <p>\\(P(A \\cap B) = P(A) + P(B) - P(A \\cup B) = 0.4 + 0.7 - 0.9 = 0.2\\)</p> </li> <li> <p>\\(P(A^c \\cap B) = P(B) - P(A \\cap B) = 0.7 - 0.2 = 0.5\\)</p> </li> <li> <p>\\(P(A - B) = P(A) - P(A \\cap B) = 0.4 - 0.2 = 0.2\\)</p> </li> <li> <p>\\(P(A^c - B) = 1 - P(A \\cup B) = 1 - 0.9 = 0.1\\)</p> </li> <li> <p>\\(P(A^c \\cup B) = 1 - P(A - B) = 1 - 0.2 = 0.8\\)</p> </li> <li> <p>\\(P(A \\cap (B \\cup A^c)) = P(A \\cap B) = 0.2\\)</p> </li> </ol>"},{"location":"01_Introduction_%2B_Recap_Probability_%2B_Stochastic_Variables/#exercise-5","title":"Exercise 5","text":"<p>Consider a random experiment with a sample space: </p> \\[ S = \\{1, 2, 3, \\cdots\\}. \\] <p>Suppose that we know:  </p> \\[ P(k) = P(\\{k\\}) = \\frac{c}{3^k} \\quad \\textrm{for} \\quad k = 1, 2, \\cdots \\] <p>where \\(c\\) is a constant number.</p> <ol> <li> <p>Find \\(c\\).</p> </li> <li> <p>Find \\(P(\\{2, 4, 6\\})\\).</p> </li> <li> <p>Find \\(P(\\{3, 4, 5, \\cdots\\})\\).</p> </li> </ol> Answer <ol> <li> <p>To find \\(c\\), use the fact that the sum of all probabilities must equal 1:</p> \\[ \\sum_{k=1}^\\infty P(k) = \\sum_{k=1}^\\infty \\frac{c}{3^k} = 1. \\] <p>This is a geometric series with the first term \\(\\frac{c}{3}\\) and ratio \\(\\frac{1}{3}\\):</p> \\[ \\sum_{k=1}^\\infty \\frac{c}{3^k} = \\frac{c}{3} \\cdot \\frac{1}{1 - \\frac{1}{3}} = \\frac{c}{3} \\cdot \\frac{3}{2} = \\frac{c}{2}.$ \\] <p>Therefore, \\(\\frac{c}{2} = 1 \\implies c = 2\\).</p> </li> <li> <p>\\(P(\\{2, 4, 6\\})\\):</p> \\[ P(\\{2, 4, 6\\}) = P(2) + P(4) + P(6) = \\frac{2}{3^2} + \\frac{2}{3^4} + \\frac{2}{3^6}. \\] <p>Compute each term:</p> \\[ P(\\{2, 4, 6\\}) = \\frac{2}{9} + \\frac{2}{81} + \\frac{2}{729} = \\frac{162 + 18 + 2}{729} = \\frac{182}{729} \\approx 0.25. \\] </li> <li> <p>\\(P(\\{3, 4, 5, \\cdots\\})\\):</p> \\[ P(\\{3, 4, 5, \\cdots\\}) = \\sum_{k=3}^\\infty P(k) = \\sum_{k=3}^\\infty \\frac{2}{3^k}. \\] <p>This is a geometric series starting at \\(k=3\\) with the first term \\(\\frac{2}{3^3} = \\frac{2}{27}\\) and ratio \\(\\frac{1}{3}\\):</p> \\[ P(\\{3, 4, 5, \\cdots\\}) = \\frac{\\frac{2}{27}}{1 - \\frac{1}{3}} = \\frac{\\frac{2}{27}}{\\frac{2}{3}} = \\frac{2}{27} \\cdot \\frac{3}{2} = \\frac{1}{9}. \\] </li> </ol>"},{"location":"01_Introduction_%2B_Recap_Probability_%2B_Stochastic_Variables/#exercise-6","title":"Exercise 6","text":"<p>Let \\(T\\) be the time needed (in hours) to complete a job at a certain factory. By using the historical data, we know that:</p> \\[ P(T \\leq t) =  \\begin{cases}  \\frac{1}{16}t^2 &amp; \\text{for } 0 \\leq t \\leq 4, \\\\ 1 &amp; \\text{for } t &gt; 4. \\end{cases} \\] <ol> <li> <p>Find the probability that the job is completed in less than one hour, i.e., find \\(P(T \\leq 1)\\).</p> </li> <li> <p>Find the probability that the job needs more than 2 hours.</p> </li> <li> <p>Find the probability that \\(1 \\leq T \\leq 3\\).</p> </li> </ol> Answer <ol> <li> <p>Using the given formula for \\(P(T \\leq t)\\) when \\(0 \\leq t \\leq 4\\):</p> \\[ P(T \\leq 1) = \\frac{1}{16}(1)^2 = \\frac{1}{16}. \\] </li> <li> <p>Using the complement rule:</p> \\[ P(T &gt; 2) = 1 - P(T \\leq 2). \\] <p>Compute \\(P(T \\leq 2)\\) using the given formula:</p> \\[ P(T \\leq 2) = \\frac{1}{16}(2)^2 = \\frac{4}{16} = \\frac{1}{4}. \\] <p>Therefore:</p> \\[ P(T &gt; 2) = 1 - \\frac{1}{4} = \\frac{3}{4}. \\] </li> <li> <p>Using the subtraction rule:</p> \\[ P(1 \\leq T \\leq 3) = P(T \\leq 3) - P(T &lt; 1). \\] <p>Compute \\(P(T \\leq 3)\\):</p> \\[ P(T \\leq 3) = \\frac{1}{16}(3)^2 = \\frac{9}{16}. \\] </li> </ol>"},{"location":"01_Introduction_%2B_Recap_Probability_%2B_Stochastic_Variables/#exercise-7","title":"Exercise 7","text":"<p>You choose a point \\((A,B)\\) uniformly at random in the unit square \\(\\{(x,y):0 \\leq x,y \\leq 1\\}\\).</p> <p>What is the probability that the equation</p> \\[ \\begin{align*}     AX^2+X+B=0 \\end{align*} \\] <p>has real solutions?</p> Answer <p>\\(\\frac{1}{4}+\\frac{1}{4} \\ln 4 \\approx 0.5966\\)</p> <p>Also, see more elaborate solution here</p>"},{"location":"01_Introduction_%2B_Recap_Probability_%2B_Stochastic_Variables/#exercise-8-exam-20142-ab","title":"Exercise 8 (Exam 2014.2 (a+b))","text":"<p>An IT company receives its printed circuit boards from two different suppliers, 1 and 2. Records show that 5% of the circuit boards from supplier 1 and 3% of the circuit boards from supplier 2 are defective. 60% of the company\u2019s current circuit boards come from supplier 2, and the remaining from supplier 1. The company usually keeps a stock of 2000 circuit boards. </p> <ol> <li>Based on this information, construct a contingency table of the company\u2019s circuit board stock. Place supplier in the columns and defective/non-defective in the rows.</li> <li>If a randomly chosen circuit board from the company\u2019s stock is chosen and turns out to be defective, what is the probability that the circuit board is from supplier 1?</li> </ol> Answer <ol> <li> <p>The contingency table is as follows:</p> Supplier 1 Supplier 2 Total Defectives 40 36 76 Non-Defectives 760 1164 1924 Total 800 1200 2000 </li> <li> <p>The probability that a circuit board is from supplier 1 given that it is defective is:</p> \\[ P(\\text{Supplier 1} | \\text{Defective}) = \\frac{P(\\text{Supplier 1} \\cap \\text{Defective})}{P(\\text{Defective})} = \\frac{40/2000}{76/2000} = \\frac{40}{76} \\approx 0.5263. \\] </li> </ol>"},{"location":"01_Introduction_%2B_Recap_Probability_%2B_Stochastic_Variables/#exercise-9-exam-20152","title":"Exercise 9 (Exam 2015.2)","text":"<p>A batch of 1000 hard drives from three suppliers were tested. 2% of the hard drives from Toshiba and 2% of the hard drives from Seagate were defective, and in the entire batch there were 3% defectives in total. In the batch, 50% were Western Digital hard drives and 30% were Toshibas.</p> <ol> <li>Based on this information, create a 3 x 2 contingency table of the hard drives.</li> <li>What is the probability that a defective product came from Seagate?</li> <li>What is the probability of randomly selecting a Western Digital hard drive from the entire batch?</li> </ol> Answer <ol> <li> <p>The contingency table is as follows:</p> Supplier Defective Non-Defective Total Toshiba (30%) 6 294 300 Seagate (20%) 4 196 200 Western Digital (50%) 20 480 500 Total 30 970 1000 </li> <li> <p>The probability that a defective product came from Seagate is:</p> \\[ P(\\text{Seagate} | \\text{Defective}) = \\frac{P(\\text{Seagate} \\cap \\text{Defective})}{P(\\text{Defective})} = \\frac{4/1000}{30/1000} = \\frac{4}{30} = \\frac{2}{15} \\approx 0.1333. \\] </li> <li> <p>The probability of randomly selecting a Western Digital hard drive from the entire batch is:</p> \\[ P(\\text{Western Digital}) = \\frac{500}{1000} = 0.5. \\] </li> </ol>"},{"location":"01_Introduction_%2B_Recap_Probability_%2B_Stochastic_Variables/#exercise-10-exam-2016-new-test3","title":"Exercise 10 (Exam 2016 New Test.3)","text":"<p>The probability that a regularly scheduled flight departs on time is 0.83; the probability that it arrives on time is 0.82; and the probability that it departs and arrives on time is 0.78. Find the probability that a plane</p> <ol> <li>Arrives on time, given that it departed on time</li> <li>Departed on time, given that it has arrived on time</li> <li>Arrives on time, given that it did not depart on time</li> </ol> Answer <ol> <li> <p>\\(P(\\text{Arrives on time} | \\text{Departs on time}) = \\frac{P(\\text{Arrives on time} \\cap \\text{Departs on time})}{P(\\text{Departs on time})} = \\frac{0.78}{0.83} \\approx 0.9398\\)</p> </li> <li> <p>\\(P(\\text{Departs on time} | \\text{Arrives on time}) = \\frac{P(\\text{Departs on time} \\cap \\text{Arrives on time})}{P(\\text{Arrives on time})} = \\frac{0.78}{0.82} \\approx 0.9512\\)</p> </li> <li> <p>\\(P(\\text{Arrives on time} | \\text{Did not depart on time}) = \\frac{P(\\text{Arrives on time} \\cap \\text{Did not depart on time})}{P(\\text{Did not depart on time})} = \\frac{0.04}{0.17} \\approx 0.2353\\)</p> </li> </ol>"},{"location":"02_Discrete_Random_Variables/","title":"02 Discrete Random Variables","text":"Discrete Random Variables"},{"location":"02_Discrete_Random_Variables/#session-preparation","title":"Session Preparation:","text":"<p>ASPE: 3</p> <p>Solve the exercises from session 1 before class.</p>"},{"location":"02_Discrete_Random_Variables/#session-material","title":"Session Material","text":"<p>Recap and Exercises - notes</p> <p>Session notes</p> <p>Session material</p> <p>Session from 20/21:</p>"},{"location":"02_Discrete_Random_Variables/#session-description","title":"Session Description","text":"<p>In this session, we look at a variety of discrete probability distributions, laying the foundation for analysing and modelling random processes. We begin with the Bernoulli distribution, which describes experiments with two possible outcomes, and extend this to the Binomial and Geometric distributions. Building on these, we move on to the Negative Binomial (Pascal) distribution and the Hypergeometric distribution, highlighting their applications in scenarios where sampling without replacement plays a role. </p> <p>The Poisson distribution, a model for counting events over time or space, is introduced, along with its use as an approximation for the Binomial distribution under specific conditions. Finally, we discuss key properties of these distributions, including their probability mass function (PMF) and cumulative distribution functions (CDFs), expectations, and variances.</p>"},{"location":"02_Discrete_Random_Variables/#key-concepts","title":"Key Concepts","text":"<ul> <li>Bernoulli Distribution</li> <li>Geometric Distribution</li> <li>Binomial Distribution</li> <li>Negative Binomial (Pascal) Distribution</li> <li>Hypergeometric Distribution</li> <li>Poisson Distribution</li> <li>Poisson as an Approximation for Binomial</li> <li>Probability Mass Function (PMF)</li> <li>Cumulative Distribution Function (CDF)</li> <li>Expectation and Variance</li> </ul>"},{"location":"02_Discrete_Random_Variables/#exercises","title":"Exercises","text":"<p>Full solutions to the exercises can be found in Session material.</p> <p>Note, sometimes we use '\\(=\\)' instead of '\\(\\approx\\)' when we state probabilities with a given decimal precision.</p>"},{"location":"02_Discrete_Random_Variables/#exercise-1","title":"Exercise 1","text":"<p>A computer system uses passwords that are exactly six characters and each character is one of the 26 letters (a\u2013z) or 10 integers (0\u20139). Suppose that 10,000 users of the system have unique passwords. A hacker randomly selects (with replacement) 100,000 passwords from the potential set, and a match to a user\u2019s password is called a hit.</p> <ol> <li>What is the distribution of the number of hits?</li> <li>What is the probability of no hits?</li> <li>What are the mean and variance of the number of hits?</li> </ol> Answer <ol> <li>The distribution of the number of hits is Binomial with \\(n = 10^5\\) and \\(p=\\frac{10^5}{36^6}\\)</li> <li>\\(P(X=0) = 0.6317\\)</li> <li>\\(\\mu = \\sigma^2 = 0.4594\\)</li> </ol>"},{"location":"02_Discrete_Random_Variables/#exercise-2","title":"Exercise 2","text":"<p>Because all airline passengers do not show up for their reserved seat, an airline sells 125 tickets for a flight that holds only 120 passengers. The probability that a passenger does not show up is 0.10, and the passengers behave independently.</p> <ol> <li>What is the probability that every passenger who shows up can take the flight?</li> <li>What is the probability that the flight departs with empty seats?</li> </ol> Answer <ol> <li>\\(p = 0.9961 \\)</li> <li>\\(p = 0.9886\\)</li> </ol>"},{"location":"02_Discrete_Random_Variables/#exercise-3","title":"Exercise 3","text":"<p>A player of a video game is confronted with a series of opponents and has an 80% probability of defeating each one. Success with any opponent is independent of previous encounters. Until defeated, the player continues to contest opponents.</p> <ol> <li>What is the probability mass function of the number of opponents contested in a game?</li> <li>What is the probability that a player defeats at least two opponents in a game?</li> <li>What is the expected number of opponents contested in a game?</li> <li>What is the probability that a player contests four or more opponents in a game?</li> <li>What is the expected number of game plays until a player contests four or more opponents?</li> </ol> Answer <ol> <li>\\(P(X=k) = 0.8^{k-1} \\cdot 0.2\\)</li> <li>\\(p = 0.64\\)</li> <li>\\(E[X] = 5\\)</li> <li>\\(p = 0.512\\)</li> <li>\\(E[Y] \\approx 1.9531\\)</li> </ol>"},{"location":"02_Discrete_Random_Variables/#exercise-4","title":"Exercise 4","text":"<p>Astronomers treat the number of stars in a given volume of space as a Poisson random variable. The density in the Milky Way Galaxy in the vicinity of our solar system is one star per 16 cubic light-years.</p> <ol> <li>What is the probability of no stars in 16 cubic light-years?</li> <li>What is the probability of two or more stars in 16 cubic light-years?</li> <li>How many cubic light-years of space must be studied so that the probability of one or more stars exceeds 0.95?</li> </ol> Answer <ol> <li>\\(P(X=0)=e^{-1} \\approx 0.3679\\)</li> <li>\\(P(X \\geq 2) \\approx 0.2642\\)</li> <li>At least 48 cubic light-years of space must be studied.</li> </ol>"},{"location":"02_Discrete_Random_Variables/#exercise-5","title":"Exercise 5","text":"<p>A congested computer network has a 1% chance of losing a data packet that must be resent, and packet losses are independent events. An e-mail message requires 100 packets.</p> <ol> <li>What is the distribution of the number of packets in an e-mail message that must be resent? Include the parameter values.</li> <li>What is the probability that at least one packet is resent?</li> <li>What is the probability that two or more packets are resent?</li> <li>What are the mean and standard deviation of the number of packets that are resent?</li> <li>If there are 10 messages and each contains 100 packets, what is the probability that at least one message requires that two or more packets be resent?</li> </ol> Answer <ol> <li>\\(X \\sim \\operatorname{Binomial}(n=100, p=0.01)\\)</li> <li>\\(P(X \\geq 1)=0.634\\)</li> <li>\\(P(X \\geq 2)=0.2642\\)</li> <li>\\(\\mu = 1, \\sigma = 0.995\\)</li> <li>\\(P(Y \\geq 1)=0.9535\\)</li> </ol>"},{"location":"02_Discrete_Random_Variables/#exercise-6","title":"Exercise 6","text":"<p>A manufacturer of a consumer electronics product expects 2% of units to fail during the warranty period. A sample of 500 independent units is tracked for warranty performance.</p> <ol> <li>What is the probability that none fails during the warranty period?</li> <li>What is the expected number of failures during the warranty period?</li> <li>What is the probability that more than two units fail during the warranty period?</li> </ol> Answer <ol> <li>\\(P(X=0) \\approx 0.0000\\)</li> <li>\\(E[X] = 10\\)</li> <li>\\(P(X &gt; 2) \\approx 0.9974\\)</li> </ol>"},{"location":"02_Discrete_Random_Variables/#exercise-7","title":"Exercise 7","text":"<p>The probability that a patient recovers from a rare blood disease is 0.4. If 15 people are known to have contracted this disease, what is the probability that:</p> <ol> <li> <p>At least 10 survive</p> </li> <li> <p>From 3 to 8 survive</p> </li> <li> <p>Exactly 5 survive</p> </li> <li> <p>Find the mean and variance.</p> </li> </ol> Answer <ol> <li>\\(P(X \\geq 10) \\approx 0.0338\\)</li> <li>\\(P(3 \\leq X \\leq 8) \\approx 0.8778\\)</li> <li>\\(P(X=5) \\approx 0.1859\\)</li> <li>\\(\\mu = 6, \\sigma^2 = 3.6\\)</li> </ol>"},{"location":"02_Discrete_Random_Variables/#exercise-8","title":"Exercise 8","text":"<p>A large chain retailer purchases a certain kind of electronic device from a manufacturer. The manufacturer indicates that the defective rate of the device is 3%.</p> <ol> <li> <p>The inspector of the retailer randomly picks 20 items from a shipment. What is the probability that there will be at least one defective item among them?</p> </li> <li> <p>Suppose that the retailer receives 10 shipments in a month and the inspector randomly tests 20 devices per shipment. What is the probability that there will be 3 shipments containing at least one defective device?</p> </li> </ol> Answer <ol> <li>\\(P(X \\geq 1) \\approx 0.4562\\)</li> <li>\\(P(Y=3) \\approx 0.1602\\)</li> </ol>"},{"location":"02_Discrete_Random_Variables/#exercise-9","title":"Exercise 9","text":"<p>High flows result in the closure of a causeway. From past records, the road is closed for this reason on 10 days during a 20-year period. At an adjoining village, there is concern about the closure of the causeway because it provides the only access. The villagers assume that the probability of a closure of the road for more than one day during a year is less than 0.10. Is this correct? Please show using the Poisson distribution.</p> Answer <p>The probability of a closure of the road for more than one day during a year is 0.0902.</p>"},{"location":"02_Discrete_Random_Variables/#exercise-10","title":"Exercise 10","text":"<p>A company performs inspection on shipments from suppliers in order to detect nonconforming products. Assume a lot contains 1000 items and 1% is nonconforming. Assuming that the number of nonconforming products in the sample is binomial, what sample size is needed so that the probability of choosing at least one nonconforming item in the sample is at least 0.9?</p> Answer <p>A sample size of at least 230 is needed.</p>"},{"location":"02_Discrete_Random_Variables/#exercise-11","title":"Exercise 11","text":"<p>The number of errors in a textbook follows a Poisson distribution with a mean of 0.01 error per page. What is the probability that there are three or less errors in 100 pages?</p> Answer <p>\\(P(X \\leq 3) \\approx 0.981\\)</p>"},{"location":"02_Discrete_Random_Variables/#additional-exercises","title":"Additional Exercises","text":"<pre><code>while student is \"bored\":\n    additional_exercises = [\n        \"Exam 2014.3 (a-c)\",\n        \"Exam 2016 New Test.2\",\n        \"Exam 2018.2\"\n    ]\n</code></pre>"},{"location":"03_Continuous_Random_Variables/","title":"03 Continuous Random Variables","text":"Continuous Random Variables"},{"location":"03_Continuous_Random_Variables/#session-preparation","title":"Session Preparation:","text":"<p>ASPE: 4 (not 4.8-4.11)</p> <p>Solve the exercises from session 2 before class.</p> <p>Today you will need to brush up on your basic calculus skills as this will not be recapped in depth. It seems that Khan Academy has some nice tutorials on integrals that you may want to check out:</p> <ul> <li>Tutorial 1</li> <li>Tutorial 2</li> <li>Tutorial 3</li> </ul>"},{"location":"03_Continuous_Random_Variables/#session-material","title":"Session Material","text":"<p>Recap notes</p> <p>Session notes Part 1</p> <p>Session notes Part 2</p> <p>Session material</p> <p>Session from 20/21:</p>"},{"location":"03_Continuous_Random_Variables/#session-description","title":"Session Description","text":"<p>Continuous random variables are a type of random variable that can take on an infinite number of values within a given range. The most important elements of continuous random variables are the probability density function, the cumulative distribution function, and the expected value. The probability density function provides the probability that a continuous random variable will take on a value within a given range, while the cumulative distribution function gives the probability that the variable will take on a value less than or equal to a given value. The expected value, or mean, of a continuous random variable is calculated by integrating the product of the variable and its probability density function over the entire range of possible values.</p> <p>It is also important that you think about the relationship between the discrete case and the continuous case, and how this transfers to the relationship between sums and integrals.</p>"},{"location":"03_Continuous_Random_Variables/#key-concepts","title":"Key Concepts","text":"<ul> <li>Derivatives, integrals, antiderivatives</li> <li>General properties of continuous random variables</li> <li>The uniform distribution</li> <li>The probability density function</li> <li>The cumulative distribution function</li> <li>The normal distribution</li> <li>The exponential distribution</li> </ul>"},{"location":"03_Continuous_Random_Variables/#exercises","title":"Exercises","text":"<p>Full solutions to the exercises can be found in the general resource folder</p>"},{"location":"03_Continuous_Random_Variables/#exercise-1-exam-20141","title":"Exercise 1 (Exam 2014.1)","text":"<p>Let \\(X\\) denote a continuous stochastic variable with the following probability density function:</p> \\[     f(x) =     \\begin{cases}     c x^4 &amp; \\text{for } -1 \\leq x \\leq 1, \\\\     0 &amp; \\text{otherwise,}     \\end{cases} \\] <p>where \\(c\\) is a constant.</p> <ol> <li> <p>Show that the cumulative probability function of \\(X\\) is:</p> \\[ F(x) = \\begin{cases} 0 &amp; \\text{for } x &lt; -1, \\\\ \\frac{1}{5} c\\left(x^5 + 1\\right) &amp; \\text{for } -1 \\leq x \\leq 1, \\\\ 1 &amp; \\text{for } x &gt; 1. \\end{cases} \\] </li> <li> <p>Determine the constant \\(c\\) and restate both the probability density function and the cumulative probability function using the actual value of \\(c\\).</p> </li> <li> <p>Compute \\(P\\left(-\\frac{1}{2} &lt; X &lt; \\frac{1}{2}\\right)\\) and \\(P(X &gt; 0)\\).</p> </li> <li> <p>Find the expected value and variance of \\(X\\).</p> </li> </ol> Answer <ol> <li>Can be shown either by integrating the probability density function or by differentiating the cumulative probability function.</li> <li>\\(c = \\frac{5}{2}\\)</li> <li>\\(P\\left(-\\frac{1}{2} &lt; X &lt; \\frac{1}{2}\\right) = \\frac{1}{32} = 0.0315\\) and \\(P(X &gt; 0) = \\frac{1}{2} = 0.5\\)</li> <li>\\(E[X] = 0\\) and \\(VAR(X) = \\frac{5}{7}\\)</li> </ol>"},{"location":"03_Continuous_Random_Variables/#exercise-2-exam-20143-not-de","title":"Exercise 2 (Exam 2014.3 (not d+e))","text":"<p>A central database server receives, on the average, 25 requests per second from its clients. Assuming that requests received by a database follow a Poisson distribution</p> <ol> <li>What is the probability that the server will receive no requests in a 10-millisecond interval?</li> <li>What is the probability that the server will receive more than 2 requests in a 10-millisecond interval?</li> <li>What is the probability that the server will receive between 2 and 4 (both included) requests in a 20-millisecond interval?</li> </ol> <p>Let T be the time in seconds between requests.</p> <ol> <li>What is the probability that less than or equal to 10 milliseconds will elapse between job requests?</li> <li>What is the probability that more than 100 milliseconds will elapse between requests?</li> </ol> Answer <ol> <li>\\(P(X=0) = 0.7788\\)</li> <li>\\(P(X&gt;2) = 0.0022\\)</li> <li>\\(P(2 \\leq X \\leq 4) = 0.09\\)</li> <li>\\(P(T \\leq 0.01) = 0.2212\\)</li> <li>\\(P(T &gt; 0.1) = 0.0821\\)</li> </ol>"},{"location":"03_Continuous_Random_Variables/#exercise-3-exam-20181","title":"Exercise 3 (Exam 2018.1)","text":"<p>Let \\(X\\) denote a continuous stochastic variable with the following density function</p> \\[ f(x)= \\begin{cases}c\\left(1-x^2\\right) &amp; \\text { for }-1&lt;x&lt;1 \\\\ 0 &amp; \\text { otherwise }\\end{cases} \\] <ol> <li>Determine the value of \\(c\\) and state the cumulative distribution function of \\(X\\).</li> <li>Determine \\(P\\left(X \\leq \\frac{1}{2}\\right)\\) and \\(P\\left(X \\leq-\\frac{1}{4}\\right)\\)</li> <li>Determine the expected value and the variance of \\(X\\).</li> </ol> Answer <p>a. \\(c = \\frac{3}{4}\\) and \\(F(x) = \\begin{cases}0 &amp; \\text { for } x&lt;-1 \\\\ \\frac{3}{4}\\left(x-\\frac{x^3}{3}\\right) + \\frac{1}{2} &amp; \\text { for }-1 \\leq x \\leq 1 \\\\ 1 &amp; \\text { for } x&gt;1\\end{cases}\\)</p> <p>b. \\(P\\left(X \\leq \\frac{1}{2}\\right) = 0.8438\\) and \\(P\\left(X \\leq-\\frac{1}{4}\\right) = 0.3164\\)</p> <p>c. \\(E[X] = 0\\) and \\(VAR(X) = 0.2\\)</p>"},{"location":"03_Continuous_Random_Variables/#exercise-4-re-exam-20181","title":"Exercise 4 (Re-exam 2018.1)","text":"<p>Compute the expected value, \\(E(X)\\), if \\(X\\) has a density function as follows:</p> <ol> <li>\\(f(x)= \\begin{cases}\\frac{1}{4} x e^{-\\frac{x}{2}} &amp; x&gt;0 \\\\ 0 &amp; \\text { otherwise }\\end{cases}\\)</li> <li> <p>\\(f(x)= \\begin{cases}5 x^{-2} &amp; x&gt;5 \\\\ 0 &amp; \\text { otherwise }\\end{cases}\\)</p> <p>The density function of \\(X\\) is given by</p> \\[ f(x)= \\begin{cases}a+b x^2 &amp; 0 \\leq x \\leq 1 \\\\ 0 &amp; \\text { otherwise }\\end{cases} \\] </li> <li> <p>If \\(E(X)=\\frac{3}{5}\\), find \\(a\\) and \\(b\\).</p> </li> </ol> Answer <ol> <li>\\(E(X) = 4\\)</li> <li>\\(E(X) = \\infty \\)</li> <li>\\(a = \\frac{3}{5}\\) and \\(b = \\frac{6}{5}\\)</li> </ol>"},{"location":"03_Continuous_Random_Variables/#exercise-5-exam-20201","title":"Exercise 5 (Exam 2020.1)","text":"<p>The length of time \\(X\\) (in hours), needed by students in the SMP course to complete the three-hour exam is a continuous random variable with the following density function:</p> \\[ f(x) = \\begin{cases} q\\left(x^2 + x\\right) &amp; \\text{if } 0 \\leq x \\leq 3, \\\\ 0 &amp; \\text{else}. \\end{cases} \\] <ol> <li> <p>Find the value of \\(q\\) that makes \\(f(x)\\) a probability density function.</p> </li> <li> <p>Find the cumulative distribution function.</p> </li> <li> <p>Find the probability that a student will complete the exam in:</p> <ul> <li>(i) Less than an hour.</li> <li>(ii) Between one and two hours.</li> <li>(iii) More than two hours.</li> <li>(iv) During the final ten minutes of the exam.</li> </ul> </li> <li> <p>Find the mean time needed to complete the three-hour SMP exam.</p> </li> <li> <p>Find the variance and standard deviation of \\(X\\).</p> </li> </ol> Answer <ol> <li>\\(q = \\frac{2}{27} \\approx 0.0741\\)</li> <li>\\(F(x) = \\begin{cases}0 &amp; \\text{if } x &lt; 0, \\\\ \\frac{2 x^3}{81}+\\frac{x^2}{27} &amp; \\text{if } 0 \\leq x \\leq 3, \\\\ 1 &amp; \\text{if } x &gt; 3.\\end{cases}\\)</li> <li>(i) \\(P(X&lt;1)=5 / 81=0.0617\\), (ii) \\(P(1&lt;X&lt;2)=23 / 81=0.284\\), (iii) \\(P(X&gt;2)=53 / 81=0.6543\\), (iv) \\(P(X&gt;17 / 6)=0.1411\\)</li> <li>\\(E[X] = 13/6 =2.1667 \\text { hours } \\)</li> <li>\\(\\operatorname{Var}(X)=0.4056\\) hours \\(^2\\) and \\(\\mathrm{SD}(X)=0.6368\\) hours</li> </ol>"},{"location":"04_Multivariate_Random_Variables/","title":"04 Normal and Exponential Distributions  and Multivariate Random Variables","text":"Normal and Exponential Distributions  and Multivariate Random Variables"},{"location":"04_Multivariate_Random_Variables/#session-preparation","title":"Session Preparation:","text":"<p>ASPE: 5 (not 5.5-5.8)</p> <p>Solve the exercises from session 3 before class.</p>"},{"location":"04_Multivariate_Random_Variables/#session-material","title":"Session Material","text":"<p>Recap Notes</p> <p>CRVs Part 2 Notes</p> <p>Session notes</p> <p>Session material</p> <p>Session from 20/21:</p>"},{"location":"04_Multivariate_Random_Variables/#session-description","title":"Session Description","text":"<p>This is arguably the most difficult of all the topics.</p> <p>Multivariate random variables are a collection of random variables that are correlated with each other. The most important elements of multivariate random variables include their mean vector, covariance matrix, and joint probability density function. The mean vector represents the average value of each variable, while the covariance matrix reflects the degree of correlation and variability among the variables. The joint probability density function specifies the probability of obtaining a particular combination of values for the variables. Understanding the key elements of multivariate random variables is crucial for performing statistical analyses, making predictions, and making decisions based on data.</p>"},{"location":"04_Multivariate_Random_Variables/#key-concepts","title":"Key Concepts","text":"<ul> <li>Joint Probability Distributions</li> <li>Conditional Probability Distributions</li> <li>Conditional Expectation</li> <li>Covariance and Correlation</li> </ul>"},{"location":"04_Multivariate_Random_Variables/#exercises","title":"Exercises","text":"<p>Full solutions to the exercises can be found in Session material.</p>"},{"location":"04_Multivariate_Random_Variables/#exercise-1","title":"Exercise 1","text":"<p>Let the simultaneous probability mass function (also called simultaneous probability density function or pdf) for the two discrete random variables \\(X\\) and \\(Y\\) be given by the table:</p> \\(y \\backslash x\\) 1 2 3 5 \\(\\frac{1}{12}\\) 0 0 6 \\(\\frac{2}{12}\\) 0 \\(\\frac{2}{12}\\) 7 \\(\\frac{2}{12}\\) \\(\\frac{1}{12}\\) \\(\\frac{2}{12}\\) 8 0 \\(\\frac{2}{12}\\) 0 <ol> <li> <p>Find the marginal PMFs of \\(X\\) and \\(Y\\).</p> </li> <li> <p>Find \\(E[X]\\), \\(E[Y]\\), and \\(E[XY]\\). Hint: It works in more or less the same way as for one variable.</p> </li> <li> <p>Specify whether \\(X\\) and \\(Y\\) are independent.</p> </li> <li> <p>Find \\(f_{X \\mid Y}(x \\mid y=6)\\).</p> </li> </ol> Answer <ol> <li> <p>The marginal PMFs of \\(X\\) and \\(Y\\) are:</p> \\[ f_X(x) =  \\begin{cases} \\frac{5}{12} &amp; \\text{for } x=1, \\\\ \\frac{1}{4} &amp; \\text{for } x=2, \\\\ \\frac{1}{3} &amp; \\text{for } x=3, \\\\ 0 &amp; \\text{otherwise,} \\end{cases} \\] \\[ f_Y(y) =  \\begin{cases} \\frac{1}{12} &amp; \\text{for } y=5, \\\\ \\frac{4}{12} &amp; \\text{for } y=6, \\\\ \\frac{5}{12} &amp; \\text{for } y=7, \\\\ \\frac{2}{12} &amp; \\text{for } y=8, \\\\ 0 &amp; \\text{otherwise.} \\end{cases} \\] </li> <li> <p>\\(\\mathrm{EX}=1.92, \\mathrm{EY}=6.67, \\mathrm{E}[\\mathrm{XY}]=12.92\\)</p> </li> <li> <p>Not</p> </li> <li> <p>\\(f_{X \\mid Y}(1 \\mid 6)=0.5, \\quad f_{X \\mid Y}(2 \\mid 6)=0, \\quad f_{X \\mid Y}(3 \\mid 6)=0.5\\)</p> </li> </ol>"},{"location":"04_Multivariate_Random_Variables/#exercise-2","title":"Exercise 2","text":"<p>Let the simultaneous probability mass function for the two discrete random variables \\(X\\) and \\(Y\\) be given by the table:</p> \\(y \\backslash x\\) 4 5 7 -3 \\(k\\) 0 0 -1 \\(\\frac{2}{10}\\) 0 \\(k\\) 0 \\(\\frac{1}{10}\\) 0 \\(\\frac{4}{10}\\) 5 0 \\(k\\) 0 <ol> <li> <p>What is the value of \\(k\\)?</p> </li> <li> <p>What are the marginal PMFs?</p> </li> <li> <p>Find:</p> <p>\\(E[X] =\\)</p> <p>\\(E[Y] =\\)</p> <p>\\(E[Y \\cdot X] =\\)</p> <p>\\(E[X^2] =\\)</p> <p>\\(E[Y^2] =\\)</p> <p>\\(P(Y &lt; 0) =\\)</p> <p>\\(P(X = 5, Y &gt; 0) =\\)</p> <p>\\(P(X &lt; 6, Y &lt; 0) =\\)</p> <p>\\(\\text{Var}(X) =\\)</p> </li> </ol> Answer <ol> <li> <p>\\(k = \\frac{1}{10}\\)</p> </li> <li> <p>The marginal PMFs are:</p> \\[ \\begin{aligned} &amp; f_X(x)= \\begin{cases}\\frac{4}{10} &amp; x=4 \\\\ \\frac{1}{10} &amp; x=5 \\\\ \\frac{1}{2} &amp; x=7\\end{cases} \\\\ &amp; f_Y(y)= \\begin{cases}\\frac{1}{10} &amp; y=-3 \\\\ \\frac{3}{10} &amp; y=-1 \\\\ \\frac{1}{2} &amp; y=0 \\\\ \\frac{1}{10} &amp; y=5\\end{cases} \\end{aligned} \\] </li> <li> <p>Find:</p> <p>\\(E[X] =5.6\\)</p> <p>\\(E[Y] =-0.1\\)</p> <p>\\(E[Y \\cdot X] =-0.2\\)</p> <p>\\(E[X^2] =33.4\\)</p> <p>\\(E[Y^2] =3.7\\)</p> <p>\\(P(Y &lt; 0) =0.4\\)</p> <p>\\(P(X = 5, Y &gt; 0) =0.1\\)</p> <p>\\(P(X &lt; 6, Y &lt; 0) =0.3\\)</p> <p>\\(\\text{Var}(X) =2.04\\)</p> </li> </ol>"},{"location":"04_Multivariate_Random_Variables/#exercise-3","title":"Exercise 3","text":"<p>Let \\(X \\sim N(3,9)\\).</p> <ol> <li>Find \\(P(X&gt;0)\\).</li> <li>Find \\(P(-3&lt;X&lt;8)\\).</li> <li>Find \\(P(X&gt;5 | X&gt;3)\\).</li> </ol> Answer <ol> <li>\\(P(X&gt;0)=\\Phi(1) \\approx 0.8413\\)</li> <li>\\(P(-3&lt;X&lt;8)=\\Phi\\left(\\frac{5}{3}\\right)-\\Phi(-2) \\approx 0.9295\\).</li> <li>\\(P(X&gt;5 \\mid X&gt;3)=2 \\times\\left(1-\\Phi\\left(\\frac{2}{3}\\right)\\right) \\approx 0.5050\\)</li> </ol>"},{"location":"04_Multivariate_Random_Variables/#exercise-4","title":"Exercise 4","text":"<p>Let \\(X \\sim N(3,9)\\) and \\(Y=5-X\\).</p> <ol> <li>Find \\(P(X&gt;2)\\).</li> <li>Find \\(P(-1&lt;Y&lt;3)\\).</li> <li>Find \\(P(X&gt;4 |Y&lt;2)\\).</li> </ol> Answer <ol> <li>\\(P(X&gt;2)=1-\\Phi\\left(\\frac{1}{3}\\right) \\approx 0.6306\\)</li> <li>\\(P(-1&lt;Y&lt;3)=\\Phi\\left(\\frac{1}{3}\\right)-\\Phi(-1) \\approx 0.4719 \\).</li> <li>\\(P(X&gt;4 \\mid Y&lt;2)=2\\left(1-\\Phi\\left(\\frac{1}{3}\\right)\\right) \\approx 0.7389 .\\)</li> </ol>"},{"location":"04_Multivariate_Random_Variables/#exercise-5-exam-20143-not-a-c","title":"Exercise 5 (Exam 2014.3 (not a-c))","text":"<p>A central database server receives, on the average, 25 requests per second from its clients. Assuming that requests received by a database follow a Poisson distribution</p> <ol> <li>What is the probability that the server will receive no requests in a 10-millisecond interval?</li> <li>What is the probability that the server will receive more than 2 requests in a 10-millisecond interval?</li> <li>What is the probability that the server will receive between 2 and 4 (both included) requests in a 20-millisecond interval?</li> </ol> <p>Let T be the time in seconds between requests.</p> <ol> <li>What is the probability that less than or equal to 10 milliseconds will elapse between job requests?</li> <li>What is the probability that more than 100 milliseconds will elapse between requests?</li> </ol> Answer <ol> <li>\\(P(X=0) = 0.7788\\)</li> <li>\\(P(X&gt;2) = 0.0022\\)</li> <li>\\(P(2 \\leq X \\leq 4) = 0.09\\)</li> <li>\\(P(T \\leq 0.01) = 0.2212\\)</li> <li>\\(P(T &gt; 0.1) = 0.0821\\)</li> </ol>"},{"location":"04_Multivariate_Random_Variables/#exercise-6-only-a-d","title":"Exercise 6 (only a-d)","text":"<p>Consider the set of points in the set \\(C\\):</p> \\[ C = \\{(x, y) \\mid x, y \\in \\mathbb{Z}, x^2 + |y| \\leq 2\\}. \\] <p>Suppose that we pick a point \\((X, Y)\\) from this set completely at random.</p> <ol> <li> <p>What probability does each point have of being chosen?</p> </li> <li> <p>Find the joint and marginal PMFs of \\(X\\) and \\(Y\\).</p> </li> <li> <p>Find the conditional PMF of \\(X\\) given \\(Y = 1\\).</p> </li> <li> <p>Are \\(X\\) and \\(Y\\) independent?</p> </li> <li> <p>Find \\(E[XY^2]\\).</p> </li> <li> <p>Find \\(E[X \\mid Y = 1]\\).</p> </li> <li> <p>Find \\(\\operatorname{Var}(X \\mid Y = 1)\\).</p> </li> <li> <p>Find \\(E[X \\mid |Y| \\leq 1]\\).</p> </li> <li> <p>Find \\(E[X^2 \\mid |Y| \\leq 1]\\).</p> </li> </ol> Answer <ol> <li> <p>1/11</p> </li> <li> <p>Find the joint and marginal PMFs of \\(X\\) and \\(Y\\).</p> \\[ \\begin{aligned} &amp; P_{X Y}(x, y)=\\left\\{\\begin{array}{cc} \\frac{1}{11} &amp; (x, y) \\in C \\\\ 0 &amp; \\text { otherwise } \\end{array}\\right. \\\\ &amp; P_Y(-2)=P_{X Y}(0,-2)=\\frac{1}{11} \\\\ &amp; P_Y(-1)=P_{X Y}(0,-1)+P_{X Y}(-1,-1)+P_{X Y}(1,-1)=\\frac{3}{11} \\\\ &amp; P_Y(0)=P_{X Y}(0,0)+P_{X Y}(1,0)+P_{X Y}(-1,0)=\\frac{3}{11} \\\\ &amp; P_Y(1)=P_{X Y}(0,1)+P_{X Y}(-1,1)+P_{X Y}(1,1)=\\frac{3}{11} \\\\ &amp; P_Y(2)=P_{X Y}(0,2)=\\frac{1}{11} \\\\ &amp; P_X(i)=\\left\\{\\begin{array}{cc} \\frac{3}{11} &amp; \\text { for } i=-1,1 \\\\ \\frac{5}{11} &amp; \\text { for } i=0 \\\\ 0 &amp; \\text { otherwise } \\end{array}\\right. \\end{aligned} \\] </li> <li> <p>Find the conditional PMF of \\(X\\) given \\(Y = 1\\).</p> \\[ \\begin{aligned} P_{X \\mid Y}(i \\mid 1) &amp; =\\frac{P_{X Y}(i, 1)}{P_Y(1)} \\\\ &amp; =\\frac{\\frac{1}{11}}{\\frac{3}{11}}=\\frac{1}{3}, \\quad \\text { for } i=-1,0,1 . \\end{aligned} \\] </li> <li> <p>No</p> </li> <li> <p>\\(E[XY^2]=0\\).</p> </li> <li> <p>\\(E[X \\mid Y = 1]=0\\).</p> </li> <li> <p>\\(\\operatorname{Var}(X \\mid Y = 1)=2/3\\).</p> </li> <li> <p>\\(E[X \\mid |Y| \\leq 1]=0\\).</p> </li> <li> <p>\\(E[X^2 \\mid |Y| \\leq 1]=2/3\\).</p> </li> </ol>"},{"location":"05_MVR_part_2/","title":"05 Multivariate Random Variables Part 2","text":"Multivariate Random Variables Part 2"},{"location":"05_MVR_part_2/#session-preparation","title":"Session Preparation:","text":"<p>ASPE: </p> <p>Solve the exercises from session 4 before class.</p>"},{"location":"05_MVR_part_2/#session-material","title":"Session Material","text":"<p>Recap Exercises</p> <p>Session material</p> <p>Session notes</p> <p>Session from 20/21:</p> <p>(Same as for session 4)</p>"},{"location":"05_MVR_part_2/#session-description","title":"Session Description","text":"<p>Multivariate random variables are a collection of random variables that are correlated with each other. The most important elements of multivariate random variables include their mean vector, covariance matrix, and joint probability density function. The mean vector represents the average value of each variable, while the covariance matrix reflects the degree of correlation and variability among the variables. The joint probability density function specifies the probability of obtaining a particular combination of values for the variables. Understanding the key elements of multivariate random variables is crucial for performing statistical analyses, making predictions, and making decisions based on data.</p>"},{"location":"05_MVR_part_2/#key-concepts","title":"Key Concepts","text":"<ul> <li>Joint Probability Distributions</li> <li>Conditional Probability Distributions</li> <li>Conditional Expectation</li> <li>Covariance and Correlation</li> </ul>"},{"location":"05_MVR_part_2/#exercises","title":"Exercises","text":""},{"location":"05_MVR_part_2/#exercise-1-only-e-i","title":"Exercise 1 (only e-i)","text":"<p>Consider the set of points in the set \\(C\\):</p> \\[ C = \\{(x, y) \\mid x, y \\in \\mathbb{Z}, x^2 + |y| \\leq 2\\}. \\] <p>Suppose that we pick a point \\((X, Y)\\) from this set completely at random.</p> <ol> <li> <p>What probability does each point have of being chosen?</p> </li> <li> <p>Find the joint and marginal PMFs of \\(X\\) and \\(Y\\).</p> </li> <li> <p>Find the conditional PMF of \\(X\\) given \\(Y = 1\\).</p> </li> <li> <p>Are \\(X\\) and \\(Y\\) independent?</p> </li> <li> <p>Find \\(E[XY^2]\\).</p> </li> <li> <p>Find \\(E[X \\mid Y = 1]\\).</p> </li> <li> <p>Find \\(\\operatorname{Var}(X \\mid Y = 1)\\).</p> </li> <li> <p>Find \\(E[X \\mid |Y| \\leq 1]\\).</p> </li> <li> <p>Find \\(E[X^2 \\mid |Y| \\leq 1]\\).</p> </li> </ol> Answer <ol> <li> <p>1/11</p> </li> <li> <p>Find the joint and marginal PMFs of \\(X\\) and \\(Y\\).</p> \\[ \\begin{aligned} &amp; P_{X Y}(x, y)=\\left\\{\\begin{array}{cc} \\frac{1}{11} &amp; (x, y) \\in C \\\\ 0 &amp; \\text { otherwise } \\end{array}\\right. \\\\ &amp; P_Y(-2)=P_{X Y}(0,-2)=\\frac{1}{11} \\\\ &amp; P_Y(-1)=P_{X Y}(0,-1)+P_{X Y}(-1,-1)+P_{X Y}(1,-1)=\\frac{3}{11} \\\\ &amp; P_Y(0)=P_{X Y}(0,0)+P_{X Y}(1,0)+P_{X Y}(-1,0)=\\frac{3}{11} \\\\ &amp; P_Y(1)=P_{X Y}(0,1)+P_{X Y}(-1,1)+P_{X Y}(1,1)=\\frac{3}{11} \\\\ &amp; P_Y(2)=P_{X Y}(0,2)=\\frac{1}{11} \\\\ &amp; P_X(i)=\\left\\{\\begin{array}{cc} \\frac{3}{11} &amp; \\text { for } i=-1,1 \\\\ \\frac{5}{11} &amp; \\text { for } i=0 \\\\ 0 &amp; \\text { otherwise } \\end{array}\\right. \\end{aligned} \\] </li> <li> <p>Find the conditional PMF of \\(X\\) given \\(Y = 1\\).</p> \\[ \\begin{aligned} P_{X \\mid Y}(i \\mid 1) &amp; =\\frac{P_{X Y}(i, 1)}{P_Y(1)} \\\\ &amp; =\\frac{\\frac{1}{11}}{\\frac{3}{11}}=\\frac{1}{3}, \\quad \\text { for } i=-1,0,1 . \\end{aligned} \\] </li> <li> <p>No</p> </li> <li> <p>\\(E[XY^2]=0\\).</p> </li> <li> <p>\\(E[X \\mid Y = 1]=0\\).</p> </li> <li> <p>\\(\\operatorname{Var}(X \\mid Y = 1)=2/3\\).</p> </li> <li> <p>\\(E[X \\mid |Y| \\leq 1]=0\\).</p> </li> <li> <p>\\(E[X^2 \\mid |Y| \\leq 1]=2/3\\).</p> </li> </ol>"},{"location":"05_MVR_part_2/#exercise-2","title":"Exercise 2","text":"<p>Consider the following PDF:</p> \\[ f_{Y \\mid X}(y) = x \\cdot e^{-xy} \\qquad \\text{for } y &gt; 0 \\] <ol> <li> <p>Find \\(P(Y &lt; 2 \\mid X = 2)\\)</p> </li> <li> <p>Find \\(E(Y \\mid X = 2)\\)</p> </li> </ol> Answer <ol> <li> <p>\\(P(Y &lt; 2 \\mid X = 2) = 1 - e^{-4} \\approx 0.98\\)</p> </li> <li> <p>\\(E(Y \\mid X = 2) = \\frac{1}{2}\\)</p> </li> </ol>"},{"location":"05_MVR_part_2/#exercise-3","title":"Exercise 3","text":"<p>Consider two random variables \\(X\\) and \\(Y\\) with joint PMF given by:</p> \\[ P_{X Y}(k, l) = \\frac{1}{2^{k+l}}, \\quad \\text{for } k, l = 1, 2, 3, \\ldots \\] <p>Find \\(P\\left(X^2 + Y^2 \\leq 10\\right)\\).</p> Answer <p>\\(P\\left(X^2 + Y^2 \\leq 10\\right) = \\frac{11}{16}\\)</p>"},{"location":"05_MVR_part_2/#exercise-4","title":"Exercise 4","text":"<p>Let \\(X\\) and \\(Y\\) be two jointly continuous random variables with joint PDF:</p> \\[ f_{XY}(x, y) = \\begin{cases} \\frac{1}{2} e^{-x} + \\frac{cy}{(1+x)^2}, &amp; 0 \\leq x, \\quad 0 \\leq y \\leq 1, \\\\ 0, &amp; \\text{otherwise}. \\end{cases} \\] <ol> <li> <p>Find the constant \\(c\\).</p> </li> <li> <p>Find \\(P(0 \\leq X \\leq 1, 0 \\leq Y \\leq \\frac{1}{2})\\).</p> </li> <li> <p>Find \\(P(0 \\leq X \\leq 1)\\).</p> </li> </ol> Answer <ol> <li> <p>\\(c = 1\\)</p> </li> <li> <p>\\(P(0 \\leq X \\leq 1, 0 \\leq Y \\leq \\frac{1}{2}) = \\frac{5}{16}-\\frac{1}{4 e}\\)</p> </li> <li> <p>\\(P(0 \\leq X \\leq 1) = \\frac{3}{4}-\\frac{1}{2 e}\\)</p> </li> </ol>"},{"location":"05_MVR_part_2/#exercise-5","title":"Exercise 5","text":"<p>Let \\(X\\) be a continuous random variable with PDF</p> \\[ f_X(x)= \\begin{cases}\\frac{5}{32} x^4 &amp; 0 \\leq x \\leq 2 \\\\ 0 &amp; \\text { otherwise }\\end{cases} \\] <p>and let \\(Y=X^2\\).</p> <ol> <li>Find CDF of \\(Y\\).</li> <li>Find PDF of \\(Y\\).</li> <li>Find \\(E Y\\).</li> </ol> Answer <ol> <li> \\[F_Y(y)=\\left\\{\\begin{array}{lc} 0 &amp; \\text { for } y&lt;0 \\\\ \\frac{1}{32} y^2 \\sqrt{y} &amp; \\text { for } 0 \\leq y \\leq 4 \\\\ 1 &amp; \\text { for } y&gt;4 \\end{array}\\right.\\] </li> <li> \\[ f_Y(y)=F_Y^{\\prime}(y)= \\begin{cases}\\frac{5}{64} y \\sqrt{y} &amp; \\text { for } 0 \\leq y \\leq 4 \\\\ 0 &amp; \\text { otherwise }\\end{cases}\\] </li> <li> \\[ E Y=\\frac{20}{7} \\] </li> </ol>"},{"location":"05_MVR_part_2/#exercise-6","title":"Exercise 6","text":"<p>Consider two random variables \\(X\\) and \\(Y\\) with joint PMF given in the Table</p> \\(Y=0\\) \\(Y=1\\) \\(Y=2\\) \\(X=0\\) \\(\\frac{1}{6}\\) \\(\\frac{1}{4}\\) \\(\\frac{1}{8}\\) \\(X=1\\) \\(\\frac{1}{8}\\) \\(\\frac{1}{6}\\) \\(\\frac{1}{6}\\) <ol> <li>Find \\(\\operatorname{Cov}(X, Y)\\)</li> <li>Find \\(\\rho(X, Y)\\)</li> </ol> Answer <ol> <li>\\(\\operatorname{Cov}(X, Y)=\\frac{1}{24}\\)</li> <li>\\(\\rho(X, Y)\\approx 0.11\\)</li> </ol>"},{"location":"05_MVR_part_2/#exercise-7","title":"Exercise 7","text":"<p>Let \\(X\\) and \\(Y\\) be two independent \\(N(0,1)\\) random variables and</p> \\[ \\begin{aligned} &amp; Z=11-X+X^2 Y \\\\ &amp; W=3-Y \\end{aligned} \\] <p>Find \\(\\operatorname{Cov}(Z, W)\\).</p> Answer \\[\\operatorname{Cov}(Z, W)=-1\\]"},{"location":"05_MVR_part_2/#exercise-8","title":"Exercise 8","text":"<p>Let \\(X\\) denote the stochastic variable with the following PDF:</p> \\[ f_X(x)= \\begin{cases}\\frac{3}{8} x^2 &amp; 0&lt;x&lt;2 \\\\ 0 &amp; \\text { otherwise }\\end{cases} \\] <ol> <li>Find \\(P(X&gt;3 / 4)\\) and \\(P(X&lt;3 / 4)\\).</li> <li>Find \\(E[(X+2) / 3]\\) and \\(E\\left[X^2\\right]\\)</li> <li> <p>Let \\(Z=e^{2 X}\\) and find the probability density function of \\(Z\\) for all \\(z \\in \\mathbb{R}\\).</p> <p>Let \\(Y\\) denote the stochastic variable that is independent to \\(X\\) and has the distribution as \\(X\\), i.e. \\(Y\\) has the following PDF:</p> \\[ f_Y(y)= \\begin{cases}\\frac{3}{8} y^2 &amp; 0&lt;y&lt;2 \\\\ 0 &amp; \\text { otherwise }\\end{cases} \\] </li> <li> <p>Find \\(\\operatorname{Cov}(2 X+3 Y, X-4 Y+9)\\).</p> </li> <li>Find \\(P(X \\cdot Y&lt;1)\\).</li> </ol> Answer <ol> <li>\\(\\approx 0.9473\\) and \\(\\approx 0.0527\\)</li> <li>\\(\\approx 1.667\\) and \\(\\approx 2.4\\)</li> <li>\\(f_Z(y)=\\left\\{\\begin{array}{lc}\\frac{3}{64} \\cdot z^{-1} \\ln z &amp; 1&lt;z&lt;e^4 \\\\ 0 &amp; \\text { else }\\end{array}\\right.\\)</li> <li>\\(-3/2\\)</li> <li>\\(\\approx 0.08\\)</li> </ol>"},{"location":"06_Statistical_Intervals/","title":"06 Point Estimation, Sampling, and Statistical Intervals","text":"06 Point Estimation, Sampling and Statistical Intervals"},{"location":"06_Statistical_Intervals/#session-preparation","title":"Session Preparation:","text":"<p>ASPE: 7 (not 7.3.4 and 7.4.3) + 8 (not 8.6)</p> <p>Solve the exercises from session 5 before class.</p>"},{"location":"06_Statistical_Intervals/#session-material","title":"Session Material","text":"<p>Recap notes</p> <p>Session Notes</p> <p>Session material</p> <p>Sessions from 20/21:</p>"},{"location":"06_Statistical_Intervals/#session-description","title":"Session Description","text":"<p>You will most likely experience that the next 2\u20133 topics are a bit less complex than the previous three topics.</p> <p>Point estimation and sampling are important concepts in statistics. Point estimation involves using a statistic, such as the sample mean or proportion, to estimate an unknown population parameter. The goal is to find the value of the statistic that is most likely to be the true value of the parameter. Sampling, on the other hand, involves selecting a subset of individuals from a larger population and using their data to make inferences about the entire population. The key to effective sampling is ensuring that the sample is representative of the population and that the sample size is large enough to accurately estimate the population parameter of interest. Together, point estimation and sampling provide a framework for making accurate and reliable statistical inferences.</p> <p>Statistical intervals are a way of expressing the uncertainty associated with a statistical estimate. They provide a range of values within which the true value of a population parameter or a future observation is likely to fall, based on a sample of data. Confidence intervals estimate the value of a population parameter with a measure of uncertainty, while prediction intervals provide a range of values for a future observation, taking into account both the uncertainty associated with estimating the population parameter and the variability associated with predicting individual observations. Statistical intervals are commonly used in various fields to estimate population parameters or future outcomes with a measure of precision and reliability.</p>"},{"location":"06_Statistical_Intervals/#key-concepts","title":"Key Concepts","text":"<ul> <li>Sampling Distribution</li> <li>Central Limit Theorem</li> <li>Standard Error</li> <li>CI for mean</li> <li>CI for proportion</li> <li>CI for variance</li> <li>Tolerance and prediction interval</li> </ul>"},{"location":"06_Statistical_Intervals/#exercises","title":"Exercises","text":"<p>Full solutions to the book exercises can be found in the general resource folder</p> <p>Note, sometimes we use '\\(=\\)' instead of '\\(\\approx\\)' when we state probabilities with a given decimal precision.</p>"},{"location":"06_Statistical_Intervals/#exercise-1-book-817","title":"Exercise 1 (Book 8.1.7)","text":"<p>A manufacturer produces piston rings for an automobile engine. It is known that ring diameter is normally distributed with \\(\\sigma=0.001\\) millimeters. A random sample of 15 rings has a mean diameter of \\(\\bar{x}=74.036\\) millimeters.</p> <ol> <li>Construct a \\(99 \\%\\) two-sided confidence interval on the mean piston ring diameter.</li> <li>Construct a \\(99 \\%\\) lower-confidence bound on the mean piston ring diameter. Compare the lower bound of this confidence interval with the one in part (a).</li> </ol> Answer <ol> <li> <p>\\(99 \\%\\) Two-sided CI on the true \\(m\\) ean piston ring diam eter For \\(\\alpha=0.01, z_{\\alpha / 2}=20.005=2.58\\), and \\(\\bar{x}=74.036, \\sigma=0.001, n=15\\)</p> \\[ \\begin{gathered} \\bar{x}-z_{0005}\\left(\\frac{\\sigma}{\\sqrt{n}}\\right) \\leq \\mu \\leq \\bar{x}+z_{0.00 s}\\left(\\frac{\\sigma}{\\sqrt{n}}\\right) \\\\ 74.036-2.58\\left(\\frac{0.001}{\\sqrt{15}}\\right) \\leq \\mu \\leq 74.036+2.58\\left(\\frac{0.001}{\\sqrt{15}}\\right) \\\\ 74.0353 \\leq \\mu \\leq 74.0367 \\end{gathered} \\] </li> <li> <p>\\(99 \\%\\) One-sided CI on the true \\(m\\) ean piston ring diam eter For \\(\\alpha=0.01, z_a=z_{0.01}=2.33\\) and \\(\\bar{x}=74.036, \\sigma=0.001, n=15\\)</p> \\[ \\begin{aligned} &amp; x-z_{0.01} \\frac{\\sigma}{\\sqrt{n}} \\leq \\mu \\\\ &amp; 74.036-2.33\\left(\\frac{0.001}{\\sqrt{15}}\\right) \\leq \\mu \\\\ &amp; 74.03574 \\leq \\mu \\end{aligned} \\] </li> </ol>"},{"location":"06_Statistical_Intervals/#exercise-2-book-818","title":"Exercise 2 (Book 8.1.8)","text":"<p>A civil engineer is analyzing the compressive strength of concrete. Compressive strength is normally distributed with \\(\\sigma^2=1000(\\mathrm{psi})^2\\). A random sample of 12 specimens has a mean compressive strength of \\(\\bar{x}=3250\\) psi.</p> <ol> <li>Construct a \\(95 \\%\\) two-sided confidence interval on mean compressive strength.</li> <li>Construct a \\(99 \\%\\) two-sided confidence interval on mean compressive strength. Compare the width of this confidence interval with the width of the one found in part (a).</li> </ol> Answer <ol> <li> <p>\\(95 \\%\\) two sided CI on the \\(m\\) ean com pressive strength</p> \\[ \\begin{aligned} &amp; z_{\\alpha / 2}=z_{0.025}=1.96, \\text { and } \\bar{x}=3250, \\sigma^2=1000, n=12 \\\\ &amp; \\overline{\\bar{x}}-z_{0.025}\\left(\\frac{\\sigma}{\\sqrt{n}}\\right) \\leq \\mu \\leq \\bar{x}+z_{0.025}\\left(\\frac{\\sigma}{\\sqrt{n}}\\right) \\\\ &amp; 3250-1.96\\left(\\frac{31.62}{\\sqrt{12}}\\right) \\leq \\mu \\leq 3250+1.96\\left(\\frac{31.62}{\\sqrt{12}}\\right) \\\\ &amp; 3250-17.89 \\leq \\mu \\leq 3250+17.89 \\\\ &amp; 3232.11 \\leq \\mu \\leq 3267.89 \\end{aligned} \\] </li> <li> <p>\\(99 \\%\\) Two-sided CI on the true \\(m\\) ean com pressive strength</p> \\[ \\begin{aligned} z_{\\alpha / 2}= &amp; z_{0.005}= \\\\ &amp; 2.58 \\\\ \\bar{x} &amp; -z_{0.005}\\left(\\frac{\\sigma}{\\sqrt{n}}\\right) \\leq \\mu \\leq \\bar{x}+z_{0.005}\\left(\\frac{\\sigma}{\\sqrt{n}}\\right) \\end{aligned} \\] </li> </ol>"},{"location":"06_Statistical_Intervals/#exercise-3-book-8210","title":"Exercise 3 (Book 8.2.10)","text":"<p>An article in Computers &amp; Electrical Engineering [\"Parallel Simulation of Cellular Neural Networks\" (1996, Vol. 22, pp. 61-84)] considered the speedup of cellular neural networks (CNNs) for a parallel general-purpose computing architecture based on six transputers in different areas. The data follow:</p> 3.775302 3.350679 4.217981 4.030324 4.639692 4.139665 4.395575 4.824257 4.268119 4.584193 4.930027 4.315973 4.600101 <ol> <li>Is there evidence to support the assumption that speedup of CNN is normally distributed? Include a graphical display in your answer.</li> <li>Construct a \\(95 \\%\\) two-sided confidence interval on the mean speedup.</li> <li>Construct a \\(95 \\%\\) lower confidence bound on the mean speedup.</li> </ol> Answer <ol> <li>The data appear to be normally distributed based on examination of the normal probability plot below.      </li> <li> <p>\\(95 \\%\\) confidence interval on mean speed-up</p> \\[ \\begin{aligned} &amp; n=13 \\quad \\bar{x}=4.313 \\quad s=0.4328 \\quad t_{0.025,12}=2.179 \\\\ &amp; \\bar{x}-t_{0.025,12}\\left(\\frac{s}{\\sqrt{n}}\\right) \\leq \\mu \\leq \\bar{x}+t_{0.025,12}\\left(\\frac{s}{\\sqrt{n}}\\right) \\\\ &amp; 4.313-2.179\\left(\\frac{0.4328}{\\sqrt{13}}\\right) \\leq \\mu \\leq 4.313+2.179\\left(\\frac{0.4328}{\\sqrt{13}}\\right) \\\\ &amp; 4.051 \\leq \\mu \\leq 4.575 \\end{aligned} \\] </li> <li> <p>\\(95 \\%\\) lower confidence bound on mean speed-up</p> \\[\\begin{aligned} &amp; n=13 \\quad \\bar{x}=4.313 \\quad s=0.4328 \\quad t_{0.05,12}=1.782 \\\\ &amp; \\bar{x}-t_{0.05,12}\\left(\\frac{s}{\\sqrt{n}}\\right) \\leq \\mu \\\\ &amp; 4.313-1.782\\left(\\frac{0.4328}{\\sqrt{13}}\\right) \\leq \\mu \\\\ &amp; 4.099 \\leq \\mu \\end{aligned}\\] </li> </ol>"},{"location":"06_Statistical_Intervals/#exercise-4-book-835","title":"Exercise 4 (Book 8.3.5)","text":"<p>An article in Technometrics [\"Two-Way Random Effects Analyses and Gauge R\\&amp;R Studies\" (1999, Vol. 41(3), pp. 202-211)] studied the capability of a gauge by measuring the weight of paper. The data for repeated measurements of one sheet of paper are in the following table. Construct a \\(95 \\%\\) one-sided upper confidence interval for the standard deviation of these measurements. Check the assumption of normality of the data and comment on the assumptions for the confidence interval.</p> Observations 3.481 3.448 3.485 3.475 3.472 3.477 3.472 3.464 3.472 3.470 3.470 3.470 3.477 3.473 3.474 Answer <p>\\(95 \\%\\) confidence interval for \\(\\sigma\\)</p> \\[ \\begin{aligned} n=15 \\quad s=0.00831 \\\\ \\chi_{1-\\alpha, n-1}^2 &amp; =\\chi_{0.95,14}^2=6.53 \\\\ \\sigma^2 &amp; \\leq \\frac{14(0.00831)^2}{6.53} \\\\ \\sigma^2 &amp; \\leq 0.000148 \\\\ \\sigma &amp; \\leq 0.0122 \\end{aligned} \\] <p>The data do not appear to be normally distributed based on an examination of the normal probability plot below. Therefore, the \\(95 \\%\\) confidence interval for \\(\\sigma\\) is not valid.</p>"},{"location":"06_Statistical_Intervals/#exercise-5-book-841","title":"Exercise 5 (Book 8.4.1)","text":"<p>The 2004 presidential election exit polls from the critical state of Ohio provided the following results. The exit polls had 2020 respondents, 768 of whom were college graduates. Of the college graduates, 412 voted for George Bush.</p> <ol> <li>Calculate a \\(95 \\%\\) confidence interval for the proportion of college graduates in Ohio who voted for George Bush.</li> <li>Calculate a \\(95 \\%\\) lower confidence bound for the proportion of college graduates in Ohio who voted for George Bush.</li> </ol> Answer <ol> <li> <p>\\(95 \\%\\) confidence interval for the proportion of college graduates in Ohio that voted for George Bush.</p> \\[ \\begin{gathered} \\hat{p}=\\frac{412}{768}=0.536 \\quad n=768 z_{\\alpha / 2}=1.96 \\\\ \\hat{p}-z_{\\alpha / 2} \\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n}} \\leq p \\leq \\hat{p}+z_{\\alpha / 2} \\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n}} \\\\ 0.536-1.96 \\sqrt{\\frac{0.536(0.464)}{768}} \\leq p \\leq 0.536+1.96 \\sqrt{\\frac{0.536(0.464)}{768}} \\\\ 0.501 \\leq p \\leq 0.571 \\end{gathered} \\] </li> <li> <p>\\(95 \\%\\) lower confidence bound on the proportion of college graduates in Ohio that voted for George Bush.</p> \\[ \\begin{aligned} \\hat{p}-z_\\alpha \\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n}} &amp; \\leq p \\\\ 0.536-1.645 \\sqrt{\\frac{0.536(0.464)}{768}} &amp; \\leq p \\\\ 0.506 &amp; \\leq p \\end{aligned} \\] </li> </ol>"},{"location":"06_Statistical_Intervals/#exercise-6-book-728","title":"Exercise 6 (Book 7.2.8)","text":"<p>Scientists at the Hopkins Memorial Forest in western Massachusetts have been collecting meteorological and environmental data in the forest data for more than 100 years. In the past few years, sulfate content in water samples from Birch Brook has averaged \\(7.48 \\mathrm{mg} / \\mathrm{L}\\) with a standard deviation of \\(1.60 \\mathrm{mg} / \\mathrm{L}\\).</p> <ol> <li>What is the standard error of the sulfate in a collection of 10 water samples?</li> <li>If 10 students measure the sulfate in their samples, what is the probability that their average sulfate will be between 6.49 and \\(8.47 \\mathrm{mg} / \\mathrm{L}\\) ?</li> <li>What do you need to assume for the probability calculated in (b) to be accurate?</li> </ol> Answer <ol> <li>\\(SE = 0.51\\)</li> <li>\\(P(6.49 &lt; \\bar{X} &lt; 8.47) = 0.95\\)</li> <li>The samples are independent. And that the population is normally distributed, or the sample size is large.</li> </ol>"},{"location":"06_Statistical_Intervals/#exercise-7-book-7210","title":"Exercise 7 (Book 7.2.10)","text":"<p>Researchers in the Hopkins Forest (see Exercise 7.2.8) also count the number of maple trees (genus acer) in plots throughout the forest. The following is a histogram of the number of live maples in 1002 plots sampled over the past 20 years. The average number of maples per plot was 19.86 trees with a standard deviation of 23.65 trees.</p> <ol> <li>If we took the mean of a sample of eight plots, what would be the standard error of the mean?</li> <li>Using the central limit theorem, what is the probability that the mean of the eight would be within 1 standard error of the mean?</li> <li>Why might you think that the probability that you calculated in (b) might not be very accurate?</li> </ol> Answer <ol> <li>\\(SE = 8.36\\)</li> <li>\\(0.68\\)</li> <li>The central limit theorem applies when the sample size \\(n\\) is large. Here \\(n = 8\\) may be too small because the distribution of the counts of maple trees is quite skewed (which you can see in the histogram in the solutions from the book).</li> </ol>"},{"location":"06_Statistical_Intervals/#exercise-8","title":"Exercise 8","text":"<p>The number of accidents in a certain city is modeled by a Poisson random variable with average rate of 10 accidents per day. Suppose that the number of accidents in different days are independent. Use the central limit theorem to find the probability that there will be more than 3800 accidents in a certain year. Assume that there are 365 days in a year.</p> Answer <p>\\(P(Y \\geq 3800) \\approx 0.0065\\)</p>"},{"location":"07_Hypothesis_Testing/","title":"07 Hypothesis Testing","text":"07 Hypothesis Testing"},{"location":"07_Hypothesis_Testing/#material","title":"Material:","text":"<p>ASPE: 9.1-9.3 + 9.5 + 9.8 + 10.1-10.4 + 10.6</p> <p>Notes recap</p> <p>Session notes</p> <p>Session material</p> <p>Session from 20/21: </p>"},{"location":"07_Hypothesis_Testing/#session-description","title":"Session Description","text":"<p>Hypothesis testing is a statistical method used to evaluate whether a certain hypothesis about a population parameter is supported by the data. The key elements of hypothesis testing include the formulation of a null hypothesis and an alternative hypothesis, the selection of an appropriate test statistic, the determination of a significance level or alpha value, the calculation of a p-value, and the comparison of the p-value to the significance level to decide whether to reject or fail to reject the null hypothesis. The significance level is a pre-determined threshold that represents the maximum probability of observing the data if the null hypothesis is true, and the p-value is the probability of observing the data, or more extreme data, if the null hypothesis is true. Hypothesis testing is widely used in many fields to make inferences about population parameters based on sample data, and it is an essential tool for scientific research and decision-making.</p>"},{"location":"07_Hypothesis_Testing/#key-concepts","title":"Key Concepts","text":"<ul> <li>Basics of hypothesis testing</li> <li>Type I and II errors</li> <li>P-values and critical values and test statistic</li> <li>Tests on mean and proportion</li> <li>One and two tailed tests</li> <li>Paired t-test</li> <li>Contingency table tests (next time in recap)</li> </ul>"},{"location":"07_Hypothesis_Testing/#exercises","title":"Exercises","text":""},{"location":"07_Hypothesis_Testing/#exercise-1-book-938","title":"Exercise 1 (Book 9.3.8)","text":"<p>Cloud seeding has been studied for many decades as a weather modification procedure (for an interesting study of this subject, see the article in Technometrics, \"A Bayesian Analysis of a Multiplicative Treatment Effect in Weather Modification,\" 1975 , Vol. 17, pp. 161-166). The rainfall in acre-feet from 20 clouds that were selected at random and seeded with silver nitrate follows: \\(18.0,30.7,19.8,27.1,22.3,18.8,31.8,23.4\\), \\(21.2,27.9,31.9,27.1,25.0,24.7,26.9,21.8,29.2,34.8,26.7\\), and 31.6.</p> <ol> <li>Can you support a claim that mean rainfall from seeded clouds exceeds 25 acre-feet? Use \\(\\alpha=0.01\\). Find the \\(P\\)-value.</li> <li>Check that rainfall is normally distributed.</li> <li>Compute the power of the test if the true mean rainfall is 27 acre-feet.</li> <li>What sample size would be required to detect a true mean rainfall of 27.5 acre-feet if you wanted the power of the test to be at least 0.9 ?</li> <li>Explain how the question in part (a) could be answered by constructing a one-sided confidence bound on the mean diameter.</li> </ol> Answer <ol> <li> <p>1) The parameter of interest is the true mean rainfall, \\(\\mu\\).</p> <p>2) \\(H_0: \\mu = 25\\) </p> <p>3) \\(H_1: \\mu &gt; 25\\).</p> <p>4) \\(\\mathrm{t}_0=\\frac{\\bar{x}-\\mu}{s / \\sqrt{n}}\\)</p> <p>5) Reject \\(\\mathrm{H}_0\\) if \\(\\mathrm{t}_0&gt;\\mathrm{t}_{\\alpha, \\mathrm{n}-1}\\) where \\(\\alpha=0.01\\) and \\(\\mathrm{t}_{0.01,19}=2.539\\) for \\(\\mathrm{n}=20\\)</p> <p>6) \\(\\overline{\\mathrm{x}}=26.04 \\mathrm{~s}=4.78 \\mathrm{n}=20\\)</p> \\[ \\mathrm{t}_0=\\frac{26.04-25}{4.78 / \\sqrt{20}}=0.97 \\] <p>7) Because \\(0.97&lt;2.539\\) fail to reject the null hypothesis. There is insufficient evidence to conclude that the true mean rainfall is greater than 25 acre-feet at \\(\\alpha=0.01\\). The \\(0.10&lt;\\mathrm{P}\\)-value \\(&lt;0.25\\).</p> </li> <li> <p>The data on the normal probability plot falls along a line. Therefore, the normality assumption is reasonable.</p> <p> </p> </li> <li> <p>\\(d=\\frac{\\delta}{\\sigma}=\\frac{\\left|\\mu-\\mu_0\\right|}{\\sigma}=\\frac{|27-25|}{4.78}=0.42\\)</p> <p>Using the OC curve, Chart VII h) for \\(\\alpha=0.01, \\mathrm{~d}=0.42\\), and \\(\\mathrm{n}=20\\), obtain \\(\\beta \\cong 0.7\\) and power of \\(1-0.7=\\) 0.3 .</p> </li> <li> <p>\\(d=\\frac{\\delta}{\\sigma}=\\frac{\\left|\\mu-\\mu_0\\right|}{\\sigma}=\\frac{|27.5-25|}{4.78}=0.52\\)</p> <p>Using the OC curve, Chart VII h) for \\(\\alpha=0.01, \\mathrm{~d}=0.52\\), and \\(\\beta \\cong 0.1\\) (Power=0.9), \\(\\mathrm{n}=75\\) </p> </li> <li> <p>\\(99 \\%\\) lower confidence bound on the mean diameter</p> \\[ \\begin{aligned} &amp; \\bar{x}-t_{0.01,19}\\left(\\frac{s}{\\sqrt{n}}\\right) \\leq \\mu \\\\ &amp; 26.04-2.539\\left(\\frac{4.78}{\\sqrt{20}}\\right) \\leq \\mu \\\\ &amp; 23.326 \\leq \\mu \\end{aligned} \\] <p>Because the lower limit of the CI is less than 25 there is insufficient evidence to conclude that the true mean rainfall is greater than 25 acre-feet at \\(\\alpha=0.01\\).</p> </li> </ol>"},{"location":"07_Hypothesis_Testing/#exercise-2-book-939","title":"Exercise 2 (Book 9.3.9)","text":"<p>A 1992 article in the Journal of the American Medical Association (\"A Critical Appraisal of 98.6 Degrees F, the Upper Limit of the Normal Body Temperature, and Other Legacies of Carl Reinhold August Wunderlich\") reported body temperature, gender, and heart rate for a number of subjects. The body temperatures for 25 female subjects follow: \\(97.8,97.2\\), \\(97.4,97.6,97.8,97.9,98.0,98.0,98.0,98.1,98.2,98.3,98.3\\), \\(98.4,98.4,98.4,98.5,98.6,98.6,98.7,98.8,98.8,98.9,98.9\\), and 99.0.</p> <ol> <li>Test the hypothesis \\(H_0: \\mu=98.6\\) versus \\(H_1: \\mu \\neq 98.6\\), using \\(\\alpha=0.05\\). Find the \\(P\\)-value.</li> <li>Check the assumption that female body temperature is normally distributed.</li> <li>Compute the power of the test if the true mean female body temperature is as low as 98.0 .</li> <li>What sample size would be required to detect a true mean female body temperature as low as 98.2 if you wanted the power of the test to be at least 0.9 ?</li> <li>Explain how the question in part (a) could be answered by constructing a two-sided confidence interval on the mean female body temperature.</li> </ol> Answer <ol> <li> <p>1) The parameter of interest is the true mean female body temperature, \\(\\mu\\).</p> <p>2) \\(H_0: \\mu = 98.6\\)</p> <p>3) \\(H_1: \\mu \\neq 98.6\\).</p> <p>4) \\(t_0=\\frac{\\bar{x}-\\mu}{s / \\sqrt{n}}\\)</p> <p>5) Reject \\(\\mathrm{H}_0\\) if \\(\\left|\\mathrm{t}_0\\right| \\geq \\mathrm{t}_{\\alpha / 2, \\mathrm{n}-1} \\quad\\) where \\(\\alpha=0.05\\) and \\(\\mathrm{t}_{\\alpha / 2, \\mathrm{n}-1}=2.064\\) for \\(\\mathrm{n}=25\\)</p> <p>6) \\(\\bar{x}=98.264, \\mathrm{~s}=0.4821, \\mathrm{n}=25\\)</p> \\[ t_0=\\frac{98.264-98.6}{0.4821 / \\sqrt{25}}=-3.48 \\] <p>7) Because \\(3.48&gt;2.064\\), reject the null hypothesis. Conclude that the true mean female body temperature differs from \\(98.6^{\\circ} \\mathrm{F}\\) at \\(\\alpha=0.05\\).</p> \\[ P \\text {-value }=2(0.001)=0.002 \\] </li> <li> <p>The data on the normal probability plot falls along a line. The normality assumption is reasonable.</p> <p> </p> </li> <li> <p>\\(d=\\frac{\\delta}{\\sigma}=\\frac{\\left|\\mu-\\mu_0\\right|}{\\sigma}=\\frac{|98-98.6|}{0.4821}=1.24\\)</p> <p>Using the OC curve, Chart VIIe for \\(\\alpha=0.05, \\mathrm{~d}=1.24\\), and \\(\\mathrm{n}=25\\), obtain \\(\\beta \\cong 0\\) and power of \\(1-0 \\cong 1\\)</p> </li> <li> <p>\\(d=\\frac{\\delta}{\\sigma}=\\frac{\\left|\\mu-\\mu_0\\right|}{\\sigma}=\\frac{|98.2-98.6|}{0.4821}=0.83\\)</p> <p>Using the OC curve, Chart VIIe for \\(\\alpha=0.05, \\mathrm{~d}=0.83\\), and \\(\\beta \\cong 0.1\\) (Power=0.9), \\(\\mathrm{n}=20\\)</p> </li> <li> <p>\\(95 \\%\\) two sided confidence interval</p> \\[ \\begin{aligned} \\bar{x}-t_{0.025,24}\\left(\\frac{s}{\\sqrt{n}}\\right) &amp; \\leq \\mu \\leq \\bar{x}+t_{0.025,24}\\left(\\frac{s}{\\sqrt{n}}\\right) \\\\ 98.264-2.064\\left(\\frac{0.4821}{\\sqrt{25}}\\right) &amp; \\leq \\mu \\leq 98.264+2.064\\left(\\frac{0.4821}{\\sqrt{25}}\\right) \\\\ 98.065 &amp; \\leq \\mu \\leq 98.463 \\end{aligned} \\] <p>We conclude that the mean female body temperature differs from 98.6 at \\(\\alpha=0.05\\) because the value is not included inside the confidence interval.</p> </li> </ol>"},{"location":"07_Hypothesis_Testing/#exercise-3-book-953","title":"Exercise 3 (Book 9.5.3)","text":"<p>An article in the British Medical Journal [\"Comparison of Treatment of Renal Calculi by Operative Surgery, Percutaneous Nephrolithotomy, and Extra-Corporeal Shock Wave Lithotripsy\" (1986, Vol. 292, pp. 879-882)] repeated that percutaneous nephrolithotomy (PN) had a success rate in removing kidney stones of 289 of 350 patients. The traditional method was \\(78 \\%\\) effective.</p> <ol> <li>Is there evidence that the success rate for PN is greater than the historical success rate? Find the \\(P\\)-value.</li> <li>Explain how the question in part (a) could be answered with a confidence interval.</li> </ol> Answer <ol> <li> <p>1) The parameter of interest is the true success rate</p> <p>2) \\(\\mathrm{H}_0: p=0.78\\)</p> <p>3) \\(\\mathrm{H}_1: p&gt;0.78\\)</p> <p>4) \\(z_0=\\frac{x-n p_0}{\\sqrt{n p_0\\left(1-p_0\\right)}}\\) or \\(z_0=\\frac{\\hat{p}-p_0}{\\sqrt{\\frac{p_0\\left(1-p_0\\right)}{n}}}\\); Either approach will yield the same conclusion</p> <p>5) Reject \\(H_0\\) if \\(\\mathrm{z}_0&gt;\\mathrm{Z}_\\alpha\\). Since the value for \\(\\alpha\\) is not given. We assume \\(\\alpha=0.05\\) and \\(\\mathrm{z}_\\alpha=\\mathrm{z}_{0.05}=1.65\\)</p> <p>6) </p> <p>\\(x=289\\) </p> <p>\\(n=350\\) </p> <p>\\(\\hat{p}=\\frac{289}{350} \\cong 0.83\\)</p> \\[ z_0=\\frac{x-n p_0}{\\sqrt{n p_0\\left(1-p_0\\right)}}=\\frac{289-350(0.78)}{\\sqrt{350(0.78)(0.22)}}=2.06 \\] <p>7) Because \\(2.06&gt;1.65\\), reject the null hypothesis and conclude the true success rate is greater than 0.78 at \\(\\alpha=0.05\\).</p> \\[ \\text { P-value }=1-0.9803=0.0197 \\] </li> <li> <p>The \\(95 \\%\\) lower confidence interval:</p> \\[ \\begin{array}{r} \\hat{p}-z_\\alpha \\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n}} \\leq p \\\\ .83-1.65 \\sqrt{\\frac{0.83(0.17)}{350}} \\leq p \\\\ 0.7969 \\leq p \\end{array} \\] <p>Because the hypothesized value is not in the confidence interval \\((0.78&lt;0.7969)\\), reject the null hypothesis.</p> </li> </ol>"},{"location":"07_Hypothesis_Testing/#exercise-4-book-954","title":"Exercise 4 (Book 9.5.4)","text":"<p>An article in Fortune (September 21, 1992) claimed that nearly one-half of all engineers continue academic studies beyond the B.S. degree, ultimately receiving either an M.S. or a Ph.D. degree. Data from an article in Engineering Horizons (Spring 1990) indicated that 117 of 484 new engineering graduates were planning graduate study.</p> <ol> <li>Are the data from Engineering Horizons consistent with the claim reported by Fortune? Use \\(\\alpha=0.05\\) in reaching your conclusions. Find the \\(P\\)-value for this test.</li> <li>Discuss how you could have answered the question in part (a) by constructing a two-sided confidence interval on \\(p\\).</li> </ol> Answer <ol> <li> <p>1) The parameter of interest is the true proportion of engineering students planning graduate studies</p> <p>2) \\(\\mathrm{H}_0: \\mathrm{p}=0.50\\)</p> <p>3) \\(\\mathrm{H}_1: \\mathrm{p} \\neq 0.50\\)</p> <p>4) \\(z_0=\\frac{x-n p_0}{\\sqrt{n p_0\\left(1-p_0\\right)}}\\) or \\(z_0=\\frac{\\hat{p}-p_0}{\\sqrt{\\frac{p_0\\left(1-p_0\\right)}{n}}}\\); Either approach will yield the same conclusion</p> <p>5) Reject \\(\\mathrm{H}_0\\) if \\(\\mathrm{z}_0&lt;-\\mathrm{z}_{\\alpha / 2}\\) where \\(\\alpha=0.05\\) and \\(-\\mathrm{z}_{\\alpha / 2}=-\\mathrm{z}_{0.025}=-1.96\\) or \\(\\mathrm{z}_0&gt;\\mathrm{z}_{\\alpha / 2}\\) where \\(\\alpha=0.05\\) and \\(\\mathrm{z}_{\\alpha / 2}=\\) \\(\\mathrm{z}_{0.025}=1.96\\)</p> <p>6) \\(\\mathrm{x}=117 \\mathrm{n}=484\\)</p> \\[ \\begin{aligned} &amp; \\hat{p}=\\frac{117}{484}=0.2417 \\\\ &amp; z_0=\\frac{x-n p_0}{\\sqrt{n p_0\\left(1-p_0\\right)}}=\\frac{117-484(0.5)}{\\sqrt{484(0.5)(0.5)}}=-11.36 \\end{aligned} \\] <p>7) Because \\(-11.36&gt;-1.65\\) reject the null hypothesis and conclude that the true proportion of engineering students planning graduate studies differs from 0.5 , at \\(\\alpha=0.05\\).</p> \\[ \\text { P-value }=2[1-\\Phi(11.36)] \\cong 0 \\] </li> <li> <p>\\(\\hat{p}=\\frac{117}{484}=0.2417 \\approx 0.242\\)</p> \\[ \\begin{aligned} \\hat{p}-z_{\\alpha / 2} \\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n}} &amp; \\leq p \\leq \\hat{p}+z_{\\alpha / 2} \\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n}} \\\\ 0.242-1.96 \\sqrt{\\frac{0.242(0.758)}{484}} &amp; \\leq p \\leq 0.242-1.96 \\sqrt{\\frac{0.242(0.758)}{484}} \\\\ 0.204 &amp; \\leq p \\leq 0.280 \\end{aligned} \\] <p>Because the \\(95 \\%\\) confidence interval does not contain the value 0.5 we conclude that the true proportion of engineering students planning graduate studies differs from 0.5.</p> </li> </ol>"},{"location":"07_Hypothesis_Testing/#exercise-5-exam-20142c","title":"Exercise 5 (Exam 2014.2.c)","text":"<p>An IT company receives its printed circuit boards from two different suppliers, 1 and 2. Records show that 5%  of the circuit boards from supplier 1 and 3% of the circuit boards from supplier 2 are defective. 60% of the  company\u2019s current circuit boards come from supplier 2, and the remaining from supplier 1. The company  usually keeps a stock of 2000 circuit boards.</p> <ol> <li>Is there sufficient evidence to support the claim that the rate of defectives depends very significantly  on supplier?</li> </ol> Answer <ol> <li> <p>\\(\\mathrm{H}_0\\) : Rate of defectives are independent of supplier</p> <p>\\(\\mathrm{H}_1\\) : Rate of defectives are dependent of supplier</p> <p>Level of significance \\(=0,01\\)</p> <p>P-value \\(= 0,0298\\)</p> <p>We fail to reject and conclude that we do not have sufficient evidence to support the claim that rate of defectives and suppliers are not very significantly independent .We would, however, be able to conclude this with alpha \\(=0,05\\)</p> </li> </ol>"},{"location":"07_Hypothesis_Testing/#exercise-6-exam-20153","title":"Exercise 6 (Exam 2015.3)","text":"<p>Different screens and their hue bias were tested and the result is displayed in the following table:</p> Blueish Reddish Greenish Display 1 46 82 72 Display 2 42 38 20 Display 3 52 40 8 <p>Is there sufficient evidence to conclude that screens and hue bias depend significantly?Design an appropriate  test to answer this question.</p> Answer <p>\\(H_0\\) : Screens and hue bias are independent</p> <p>\\(H_1\\) : Screens and hue bias are dependent</p> <p>From the template, we obtain a p-value \\(= 0.0000\\). From this we reject the null hypothesis and conclude that screens and hue bias are dependent.</p>"},{"location":"07_Hypothesis_Testing/#exercise-7-exam-20154","title":"Exercise 7 (Exam 2015.4)","text":"<p>Two different machines, \\(A\\) and \\(B\\), which are used to measure blood pressure, are tested on 12 different patients such that each patient has his/her blood pressure measured by both machines. The results for the systolic blood pressure are displayed in the table below:</p> Patient 1 2 3 4 5 6 7 8 9 10 11 12 Machine  A 119 130 141 123 149 156 134 108 123 138 119 156 Machine  B 112 126 145 112 138 156 130 112 112 119 112 152 <ol> <li>Determine the mean, standard deviation and interquartile range for both sets of data</li> <li>Is it possible to conclude with statistical significance that the two machines give different measurement? Design an appropriate test to answer this question.</li> <li>Explain what the P -value obtained in b) actually means.</li> </ol> Answer <ol> <li> Machine A Machine B 119 112 130 126 141 145 123 112 149 138 156 156 134 130 108 112 123 112 138 119 119 112 156 152 Mean 133 127,16667 St. Dev. 15,462565 16,813595 IQR 21 27,75 </li> <li> <p>\\(H_0\\) : Mean machine A is equal to mean of machine B</p> <p>\\(H_1\\) : Mean machine A is not equal to mean of machine B</p> <p></p> <p>We use a t-test since the samples are small. Also, the F-test shows that we are unable to reject  different variances and thus assume equal variance. We obtain a p-value \\(= 0,0117\\). From this we  reject the null hypothesis and conclude that the machines are significantly different.</p> </li> <li> <p>The p-value indicates the probability of obtaining the samples given that the null hypothesis is true, i.e. under the assumption that the two machines yield similar measurements, the probability of obtaining the results from assignment a) is \\(0,0117\\).</p> </li> </ol>"},{"location":"07_Hypothesis_Testing/#exercise-8-exam-20164","title":"Exercise 8 (Exam 2016.4)","text":"<p>An industrial safety program was recently instituted in the computer chip industry. The average weekly loss (averaged over 1 month) in labor-hours due to accidents in 10 similar plants both before and after the program are as follows:</p> Plant Before After 1 30.5 23 2 18.5 21 3 24.5 22 4 32 28.5 5 16 14.5 6 15 15.5 7 23.5 24.5 8 25.5 21 9 28 23.5 10 18 16.5 <ol> <li>Determine whether the safety program has had a significant effect on reducing labor-hours due to accidents in the 10 plants.</li> <li>Setup a \\(95 \\%\\) confidence interval on the average difference and state how this interval could have been used to answer question a.</li> <li>Is there evidence to support the claim that the program has had an effect at the \\(1 \\%\\) level of significance?</li> </ol> Answer <ol> <li> <pre><code>Before = [30.5, 18.5, 24.5, 32, 16, 15, 23.5, 25.5, 28, 18]\nAfter = [23, 21, 22, 28.5, 14.5, 15.5, 24.5, 21, 23.5, 16.5]\n\ndf = pd.DataFrame({'Before': Before,\n                'After': After})\ndf['Difference'] = df['Before']- df['After']\nmeandiff = np.mean(df['Difference'])\n</code></pre> <p>We check for normality of the differences</p> <pre><code>stats.probplot(df['Difference'], plot=plt)\nplt.ylabel('Difference in Labor-hours')\nplt.show()\nprint('Skewness = ' + repr(round(stats.skew(df['Difference']),4)))\nprint('Kurtosis = ' + repr(round(stats.kurtosis(df['Difference']),4)))\nfig, ax = plt.subplots()\ndf['Difference'].plot.kde(ax=ax, legend=False, title='Distribution');\n</code></pre> <p></p> <p>Skewness = 0.1328</p> <p>Kurtosis = -0.7163</p> <p></p> <p>Plotting</p> <pre><code>n1 = len(df['Before'])\nSE1 = stats.sem(df['Before'])\nmean1 = np.mean(df['Before'])\n\nn2 = len(df['After'])\nSE2 = stats.sem(df['After'])\nmean2 = np.mean(df['After'])\n\nx1 = np.linspace(mean1-4*SE1, mean1+4*SE1, 1000)\nx2 = np.linspace(mean2-4*SE2, mean2+4*SE2, 1000)\n\ny1 = stats.t.pdf(x1, n1-1, mean1, SE1)\ny2 = stats.t.pdf(x2, n2-1, mean2, SE2)\n\nplt.plot(x1,y1, color='red')\nplt.plot(x2,y2, color='blue')\n\nplt.show()\n</code></pre> <p></p> <pre><code>val = stats.ttest_rel(df['Before'], df['After'])\n\nalpha = 0.05\nstat = abs(round(val[0],2))\npvalue = round(val[1], 4)/2\ncrit = abs(round(stats.t.ppf(alpha,n1-1),2))\nstat\n</code></pre> <p>2.27</p> <p>if pvalue &lt; alpha:         print(\"Reject since \" + repr(pvalue) + ' &lt; ' + repr(alpha))     else:         print(\"Fail to reject since \" + repr(pvalue) + ' &gt; ' + repr(alpha))</p> <p>a) Reject since 0.02485 &lt; 0.05</p> </li> <li> <p>same p-value different alpha, so no.</p> </li> </ol>"},{"location":"07_Hypothesis_Testing/#exercise-9-exam-20175","title":"Exercise 9 (Exam 2017.5)","text":"<p>A recent study among 254 computer science graduates from Aarhus University was made in order to determine how successful the former students were in their current employment. 98 of these students had taken a course in linear algebra and of these 92 were classified as \"successful\" in their current employment. 136 of the students who had not taken a course in linear algebra were classified as \"successful\" in their current employment.</p> <ol> <li>Is the evidence to support the claim that computer science graduates who had taken a linear algebra course were more successful in their current employment than those who had not taken such a course?</li> <li>Explain the meaning of the p-value obtained in question (a), i.e. what does this probability refer to?</li> </ol> Answer <pre><code>alg = 98\nalgs = 92\nnonalgs = 136\nnonalg = 254-alg\n</code></pre> <ol> <li> <p>Since we have two proportions, we can use test of difference between proportions:</p> <pre><code>val = sm.stats.proportions_ztest([algs, nonalgs], [alg, nonalg], value = None, alternative = 'larger')\nstat = abs(round(val[0],2))\npvalue = round(val[1],4)\n\nalpha = 0.05\ncrit = stats.norm.isf(alpha/2)\n\nif pvalue &lt; alpha:\n    print(\"Reject since \" + repr(pvalue) + ' &lt; ' + repr(alpha))\nelse:\n    print(\"Fail to reject since \" + repr(pvalue) + ' &gt; ' + repr(alpha))\n</code></pre> <p>Reject since 0.0432 &lt; 0.05</p> <pre><code>import numpy as np\nfrom scipy.stats import norm\nfrom IPython.display import display, Markdown\n\n# Calculate the pooled proportion\npooled_p = (algs + nonalgs) / (alg + nonalg)\n\n# Calculate the standard error\nstd_error = np.sqrt(pooled_p * (1 - pooled_p) * (1/alg + 1/nonalg))\n\n# Calculate the z-score\nz_score = (algs/alg - nonalgs/nonalg) / std_error\n\n# Determine the p-value for the larger alternative\np_value = norm.sf(z_score)  # sf is survival function, which is 1-cdf\n\n# Set significance level\nalpha = 0.05\n\n# Display the results\ndisplay(Markdown(f\"### Z-Test Results for Two Proportions\"))\ndisplay(Markdown(f\"**Z-Score:** {z_score:.2f}\"))\ndisplay(Markdown(f\"**P-Value:** {p_value:.4f}\"))\ndisplay(Markdown(f\"**Significance Level (Alpha):** {alpha}\"))\n\n# Decision based on p-value\nif p_value &lt; alpha:\n    display(Markdown(\"**Conclusion:** Reject the null hypothesis since p-value &lt; alpha.\"))\nelse:\n    display(Markdown(\"**Conclusion:** Fail to reject the null hypothesis since p-value &gt; alpha.\"))\n</code></pre> <p>Z-Test Results for Two Proportions</p> <p>Z-Score: 1.71</p> <p>P-Value: 0.0432</p> <p>Significance Level (Alpha): 0.05</p> <p>Conclusion: Reject the null hypothesis since p-value &lt; alpha.</p> <pre><code>val[0]\n</code></pre> <p>1.7143021919557946</p> </li> <li> <p>see other answers elsewhere</p> </li> </ol>"},{"location":"07_Hypothesis_Testing/#exercise-10-reexam-20184","title":"Exercise 10 (Reexam 2018.4)","text":"<p>Two producers of batteries measure the longevity of 30 batteries of the same type, which were randomly chosen from a larger batch of such batteries. The lifetime (in hundreds of hours) is displayed \"Batteries.xlsx\".</p> <ol> <li>Check the dataset for outliers and replace any outliers with the mean lifetime of the producer in question. Use this cleaned dataset in the following questions.</li> <li>Determine estimates for the quartiles, average lifetime, standard deviation and variance of each producer's battery</li> <li>Setup \\(95 \\%\\) confidence intervals for each mean battery lifetime from the two producers, and accompany the intervals with plots that display the rejection region.</li> <li>Is it reasonable to conclude that the lifetime of the two producer's battery follow a normal distribution? Explain using plots and discussing skewness and kurtosis.</li> <li>Setup a \\(95 \\%\\) confidence interval for the difference between the two producer's battery, and accompany the intervals with plots that display the rejection region.</li> <li>Is there significant evidence to support the claim that the mean lifetime of the batteries from the two producers differ from one another?</li> </ol> Answer <ol> <li> <pre><code>df = pd.read_excel(\n    'Batteries.xlsx'\n)\ndf.head()\n</code></pre> Producer 1 Producer 2 0 2.1162 1.1259 1 2.5135 3.1725 2 1.8137 2.4492 3 0.8075 3.7766 4 1.5554 4.4673 <pre><code>q3, q1 = np.percentile(df['Producer 1'], [75,25])\niqr = q3 - q1\nupper = q3+1.5*iqr\nlower = q1 - 1.5*iqr\naverage = df.loc[(df['Producer 1'] &lt; upper) &amp; (df['Producer 1'] &gt; lower)  , 'Producer 1'].mean()\ndf['Producer 1'] = np.where((df['Producer 1'] &gt; upper) | (df['Producer 1'] &lt; lower), average, df['Producer 1'])\n\nq3, q1 = np.percentile(df['Producer 2'], [75,25])\niqr = q3 - q1\nupper = q3+1.5*iqr\nlower = q1 - 1.5*iqr\naverage = df.loc[(df['Producer 2'] &lt; upper) &amp; (df['Producer 2'] &gt; lower)  , 'Producer 2'].mean()\ndf['Producer 2'] = np.where((df['Producer 2'] &gt; upper) | (df['Producer 2'] &lt; lower), average, df['Producer 2'])\n</code></pre> </li> <li> <pre><code>df1 = df['Producer 1']\ndf2 = df['Producer 2']\n\nprint('Producer 1: ')\nprint('q1 = ', round(df1.quantile(0.25), 4))\nprint('q2 = ', round(df1.quantile(0.5), 4))\nprint('q3 = ', round(df1.quantile(0.75), 4))\nprint('q4 = ', round(df1.quantile(1), 4))\nprint('average = ', round(df1.mean(), 4))\nprint('std = ', round(df1.std(), 4))\nprint('std = ', round(df1.var(), 4))\nprint(' ')\nprint('Producer 2: ')\nprint('q1 = ', round(df2.quantile(0.25), 4))\nprint('q2 = ', round(df2.quantile(0.5), 4))\nprint('q3 = ', round(df2.quantile(0.75), 4))\nprint('q4 = ', round(df2.quantile(1), 4))\nprint('average = ', round(df2.mean(), 4))\nprint('std = ', round(df2.std(), 4))\nprint('std = ', round(df2.var(), 4))\n</code></pre> <p>Producer 1: </p> <p>q1 =  1.1888</p> <p>q2 =  1.9196</p> <p>q3 =  2.4074</p> <p>q4 =  3.637</p> <p>average =  1.9029</p> <p>std =  0.9109</p> <p>std =  0.8298</p> <p>Producer 2: </p> <p>q1 =  2.0375</p> <p>q2 =  2.5158</p> <p>q3 =  3.0069</p> <p>q4 =  4.4673</p> <p>average =  2.4776</p> <p>std =  0.9124</p> <p>std =  0.8325</p> </li> <li> <p>Using t.interval</p> <pre><code>from scipy import stats\nn = len(df1)\nmean = np.mean(df1)\nSE = stats.sem(df1)\nLevel = 0.95\n\nCI = stats.t.interval(Level, n-1, loc=mean, scale=SE)\n\nprint('An ' + repr(Level*100) + ' % upper confidence interval for the sample mean is ['\n    + repr(round(CI[0],2)) + '; ' + repr(round(CI[1],2)) + ']')\n</code></pre> <p>An 95.0 % upper confidence interval for the sample mean is [1.56; 2.24]</p> <pre><code>import numpy as np\nimport scipy.stats as stats\nimport matplotlib.pyplot as plt\n\n# Using the formula\ndata = df1\n\n# Calculate the mean and standard deviation of the data\nmean = np.mean(data)\nstd_dev = np.std(data, ddof=1)  # ddof=1 gives an unbiased estimator of the population std dev\n\n# Calculate the standard error of the mean\nstd_error = std_dev / np.sqrt(len(data))\n\n# Set the significance level and degrees of freedom for the t-distribution\nalpha = 0.05  # 95% confidence level\ndof = len(data) - 1\n\n# Calculate the critical t-value for the two-tailed t-test\nt_crit = stats.t.ppf(1 - alpha/2, dof)\n\n# Calculate the confidence interval for the mean\nlower = mean - t_crit * std_error\nupper = mean + t_crit * std_error\n\n# Print the confidence interval\nprint(\"95% Confidence Interval mean Producer 1: [{:.2f}, {:.2f}]\".format(lower, upper))\n\n# Plot the t-distribution with the rejection region shaded\nx = np.linspace(mean-4*std_error, mean+4*std_error, 1000)\ny = stats.t.pdf(x,dof, mean, std_error)\nplt.plot(x, y, 'k', linewidth=2)\nshade = np.linspace(lower, upper, 300)\nplt.fill_between(shade, stats.t.pdf(shade, dof, mean, std_error), alpha=0.5)\nplt.axvline(x=lower, linestyle='--', color='k')\nplt.axvline(x=upper, linestyle='--', color='k')\nplt.title(\"t-Distribution with 95% Confidence Interval \\n for the mean of batteries from producer 1\")\nplt.xlabel(\"t-value\")\nplt.ylabel(\"Probability density\")\nplt.show()\n\n# Using the formula\ndata = df2\n\n# Calculate the mean and standard deviation of the data\nmean = np.mean(data)\nstd_dev = np.std(data, ddof=1)  # ddof=1 gives an unbiased estimator of the population std dev\n\n# Calculate the standard error of the mean\nstd_error = std_dev / np.sqrt(len(data))\n\n# Set the significance level and degrees of freedom for the t-distribution\nalpha = 0.05  # 95% confidence level\ndof = len(data) - 1\n\n# Calculate the critical t-value for the two-tailed t-test\nt_crit = stats.t.ppf(1 - alpha/2, dof)\n\n# Calculate the confidence interval for the mean\nlower = mean - t_crit * std_error\nupper = mean + t_crit * std_error\n\n# Print the confidence interval\nprint(\"95% Confidence Interval mean Producer 2: [{:.2f}, {:.2f}]\".format(lower, upper))\n\n# Plot the t-distribution with the rejection region shaded\nx = np.linspace(mean-4*std_error, mean+4*std_error, 1000)\ny = stats.t.pdf(x,dof, mean, std_error)\nplt.plot(x, y, 'k', linewidth=2)\nshade = np.linspace(lower, upper, 300)\nplt.fill_between(shade, stats.t.pdf(shade, dof, mean, std_error), alpha=0.5)\nplt.axvline(x=lower, linestyle='--', color='k')\nplt.axvline(x=upper, linestyle='--', color='k')\nplt.title(\"t-Distribution with 95% Confidence Interval \\n for the mean of batteries from producer 2\")\nplt.xlabel(\"t-value\")\nplt.ylabel(\"Probability density\")\nplt.show()\n</code></pre> <p>95% Confidence Interval mean Producer 1: [1.56, 2.24]</p> <p></p> <p>95% Confidence Interval mean Producer 2: [2.14, 2.82]</p> <p></p> </li> <li> <pre><code>stats.probplot(df1, plot=plt)\nplt.ylabel('Producer 1')\nplt.show()\nprint('Skewness = ' + repr(round(stats.skew(df1),4)))\nprint('Kurtosis = ' + repr(round(stats.kurtosis(df1),4)))\nfig, ax = plt.subplots()\ndf1.plot.kde(ax=ax, legend=False, title='Distribution of mean of Producer 1');\n</code></pre> <p></p> <p>Skewness = 0.1134</p> <p>Kurtosis = -0.4326</p> <p></p> <pre><code>stats.probplot(df2, plot=plt)\nplt.ylabel('Producer 2')\nplt.show()\nprint('Skewness = ' + repr(round(stats.skew(df2),4)))\nprint('Kurtosis = ' + repr(round(stats.kurtosis(df2),4)))\nfig, ax = plt.subplots()\ndf2.plot.kde(ax=ax, legend=False, title='Distribution of mean of Producer 2');\n</code></pre> <p></p> <p>Skewness = -0.1821</p> <p>Kurtosis = -0.19</p> <p></p> </li> <li> <pre><code>import numpy as np\nimport scipy.stats as stats\nimport matplotlib.pyplot as plt\n\n# Generate some sample data for two independent samples (replace this with your own data)\ndata1 = df1\ndata2 = df2\n\n# Calculate the mean and standard deviation of the data\nmean1 = np.mean(data1)\nmean2 = np.mean(data2)\nstd_dev1 = np.std(data1, ddof=1)  # ddof=1 gives an unbiased estimator of the population std dev\nstd_dev2 = np.std(data2, ddof=1)\n\n# Calculate the standard error of the difference in means\nstd_error = np.sqrt((std_dev1 ** 2 / len(data1)) + (std_dev2 ** 2 / len(data2)))\n\n# Set the significance level and degrees of freedom for the t-distribution\nalpha = 0.05  # 95% confidence level\ndf = len(data1) + len(data2) - 2\n\n# Calculate the critical t-value for the two-tailed t-test\nt_crit = stats.t.ppf(1 - alpha/2, df)\n\n# Calculate the confidence interval for the difference in means\ndiff = mean1 - mean2\nlower = diff - t_crit * std_error\nupper = diff + t_crit * std_error\n\n# Print the confidence interval\nprint(\"95% Confidence Interval for the Difference in Means: [{:.2f}, {:.2f}]\".format(lower, upper))\n\n# Plot the t-distribution with the rejection region shaded\nx = np.linspace(-4, 4, 1000)\ny = stats.t.pdf(x, df)\nplt.plot(x, y, 'k', linewidth=2)\nshade1 = np.linspace(-t_crit, t_crit, 300)\nplt.fill_between(shade1, stats.t.pdf(shade1, df), alpha=0.5)\nplt.axvline(x=t_crit, linestyle='--', color='k')\nplt.axvline(x=-t_crit, linestyle='--', color='k')\nplt.title(\"t-Distribution with 95% Confidence Interval for the Difference in Means\")\nplt.xlabel(\"t-value\")\nplt.ylabel(\"Probability density\")\nplt.show()\n</code></pre> <p>95% Confidence Interval for the Difference in Means: [-1.05, -0.10]</p> <p></p> </li> <li> <pre><code>import numpy as np\nimport scipy.stats as stats\nimport matplotlib.pyplot as plt\n\n# Generate some sample data for two independent samples (replace this with your own data)\ndata1 = df1\ndata2 = df2\n\n# Calculate the mean and standard deviation of the data\nmean1 = np.mean(data1)\nmean2 = np.mean(data2)\nstd_dev1 = np.std(data1, ddof=1)  # ddof=1 gives an unbiased estimator of the population std dev\nstd_dev2 = np.std(data2, ddof=1)\n\n# Set the significance level\nalpha = 0.05  # 95% confidence level\n\n# Perform a two-sample t-test with equal variances\nt_stat, p_value = stats.ttest_ind(data1, data2, equal_var=True)\n\n# Calculate the critical t-value for the two-tailed t-test\nt_crit = stats.t.ppf(1 - alpha/2, len(data1) + len(data2) - 2)\n\n# Print the results of the hypothesis test\nif p_value &lt; alpha:\n    print(\"Reject since \", round(p_value, 4), ' &lt; ', alpha)\nelse:\n    print(\"Fail to reject since \", round(p_value, 4) , '\\u2265' , alpha)\n\n# Plot the t-distribution with the rejection region shaded\nx = np.linspace(-4, 4, 1000)\ny = stats.t.pdf(x, len(data1) + len(data2) - 2)\nplt.plot(x, y, 'k', linewidth=2)\nshade1 = np.linspace(-t_crit, t_crit, 300)\nshade2 = np.linspace(t_crit, 4, 300)\nplt.fill_between(shade1, stats.t.pdf(shade1, len(data1) + len(data2) - 2), alpha=0.5)\nplt.fill_between(shade2, stats.t.pdf(shade2, len(data1) + len(data2) - 2), alpha=0.5)\nplt.axvline(x=t_crit, linestyle='--', color='k')\nplt.axvline(x=-t_crit, linestyle='--', color='k')\n\n# Add an arrow pointing to the position on the x-axis where the p-value lies\nif p_value &lt; alpha/2:\n    plt.annotate(\"p = {:.4f}\".format(p_value), xy=(t_stat, 0.1), xytext=(t_stat + 1, 0.3),\n                arrowprops=dict(facecolor='green', shrink=0.05))\nelif p_value &gt; 1 - alpha/2:\n    plt.annotate(\"p = {:.4f}\".format(p_value), xy=(t_stat, 0.1), xytext=(t_stat - 1, 0.3),\n                arrowprops=dict(facecolor='green', shrink=0.05))\nelse:\n    plt.annotate(\"p = {:.4f}\".format(p_value), xy=(t_stat, 0.1), xytext=(t_stat, 0.3),\n                arrowprops=dict(facecolor='green', shrink=0.05))\n\nplt.title(\"t-Distribution with Hypothesis Test Results\")\nplt.xlabel(\"t-value\")\nplt.ylabel(\"Probability density\")\nplt.show()\n</code></pre> <p>Reject since  0.0177  &lt;  0.05</p> <p></p> </li> </ol>"},{"location":"08_Regression/","title":"08 Regression","text":"08 Regression"},{"location":"08_Regression/#material","title":"Material:","text":"<p>ASPE: 11 (not 11.9)</p> <p>Recap notes</p> <p>Session notes</p> <p>Session material</p> <p>Session from 20/21: SMP 8</p>"},{"location":"08_Regression/#topics","title":"Topics","text":"<p>Linear regression is a statistical method used to model the relationship between a dependent variable and one or more independent variables. The key elements of linear regression include the dependent variable, independent variable(s), regression coefficients, intercept, and residual error. The regression coefficients represent the change in the dependent variable associated with a one-unit change in the independent variable, while the intercept represents the expected value of the dependent variable when all independent variables are equal to zero. The residual error is the difference between the observed values of the dependent variable and the values predicted by the regression model. The goal of linear regression is to find the best-fitting line that minimizes the sum of the squared residual errors. Linear regression is a widely used method in various fields to make predictions or estimate the strength and direction of relationships between variables.</p> <ul> <li>Least Squares Estimates</li> <li>Regression Equation</li> <li>Correlation</li> <li>Coefficient of determination</li> <li>Prediction</li> <li>Residual Analysis</li> </ul> <p>I've added a page with all the useful formulas for calculating the parameters as well as the performance metrics, \\(r\\) and \\(r^2\\)</p>"},{"location":"08_Regression/#problems-to-be-worked-on-inafter-class","title":"Problems to be worked on in/after class:","text":"<p>If nothing is noted, assume it is \u201cExam\u201d. If it is the reexam, it will be stated.</p> <ul> <li>2020.4 (not f), 2020.5, 2020.6, 2020.7, Reexam 2018.4, Reexam 2018.5, Reexam 2018.6, 2018.6, 2017.4, 2017.5, 2017.6</li> </ul>"},{"location":"08_Regression/Calculating%20metrics/","title":"Calculating Metrics in Simple Linear Regression","text":""},{"location":"08_Regression/Calculating%20metrics/#the-slope-and-intercept","title":"The Slope (and intercept)","text":"<p>In simple linear regression, the slope parameter (often denoted as \\(\\beta_1\\)) represents the relationship between the independent variable (X) and the dependent variable (Y). The slope indicates how much the dependent variable is expected to increase (or decrease) for a one-unit increase in the independent variable. There are several ways to compute this slope, and here are some of the key methods:</p>"},{"location":"08_Regression/Calculating%20metrics/#least-squares-estimation","title":"Least Squares Estimation:","text":"<p>The most common method for calculating the slope in simple linear regression is the least squares estimation. The formula for the slope (\\(\\beta_1\\)) using this method is:</p> <p>$$\\boxed{    \\beta_1 = \\frac{\\sum_{i=1}^n (x_i - \\overline{x})(y_i - \\overline{y})}{\\sum_{i=1}^n (x_i - \\overline{x})^2}}    $$</p> <p>In this expression: - \\(\\sum_{i=1}^n (x_i - \\overline{x})(y_i - \\overline{y})\\) is the sum of the products of the deviations of \\(x\\) and \\(y\\) from their respective means. This term captures the covariance between \\(x\\) and \\(y\\), indicating how much \\(x\\) and \\(y\\) vary together from their mean values (though excluding \\(\\frac{1}{n-1}\\)). This term is often denoted \\(S_{xy}\\). - \\(\\overline{x}\\) and \\(\\overline{y}\\) are the means of \\(x\\) and \\(y\\), respectively. These are calculated as \\(\\overline{x} = \\frac{1}{n} \\sum_{i=1}^n x_i\\) and \\(\\overline{y} = \\frac{1}{n} \\sum_{i=1}^n y_i\\), where \\(n\\) is the number of observations. - \\(\\sum_{i=1}^n (x_i - \\overline{x})^2\\) represents the sum of the squares of the deviations of \\(x\\) from its mean. This term is a measure of the total variance in \\(x\\) and helps normalize the covariance in the numerator. This term is often denoted \\(S_{xy}\\). - \\(n\\) is the number of observations, indicating the total number of data points in the dataset.</p>"},{"location":"08_Regression/Calculating%20metrics/#sum-of-products","title":"Sum of Products","text":"<p>The fundamental expression for the slope is the one stated above. But we can also use the sum of products which is demonstrated here.</p> <p>Derivation of \\((S_{xy})\\)</p> <p>The regular form for the sum of products of deviations for \\(x\\) and \\(y\\) is: $$ S_{xy} = \\sum_{i=1}^n (x_i - \\overline{x})(y_i - \\overline{y}) $$</p> <p>Expanding this sum: $$ S_{xy} = \\sum_{i=1}^n (x_i y_i - x_i \\overline{y} - y_i \\overline{x} + \\overline{x} \\overline{y}) $$</p> <p>Simplifying this by distributing the summation: $$ S_{xy} = \\sum_{i=1}^n x_i y_i - \\sum_{i=1}^n x_i \\overline{y} - \\sum_{i=1}^n y_i \\overline{x} + n \\overline{x} \\overline{y} $$</p> <p>Notice that $\\sum_{i=1}^n x_i \\overline{y} $ can be rewritten because \\(\\overline{y}\\) is a constant: $$ \\sum_{i=1}^n x_i \\overline{y} = \\overline{y} \\sum_{i=1}^n x_i $$ And similarly for \\(\\sum_{i=1}^n y_i \\overline{x}\\): $$ \\sum_{i=1}^n y_i \\overline{x} = \\overline{x} \\sum_{i=1}^n y_i $$</p> <p>Since \\(\\sum_{i=1}^n x_i = n \\overline{x}\\) and \\(\\sum_{i=1}^n y_i = n \\overline{y}\\), the terms simplify to:  $$ S_{xy} = \\sum_{i=1}^n x_i y_i - n \\overline{x} \\overline{y} $$</p> <p>Derivation of \\(S_{xx}\\)</p> <p>The regular form for the sum of squares of deviations for $ x $ is: $$ S_{xx} = \\sum_{i=1}^n (x_i - \\overline{x})^2 $$</p> <p>Expanding this sum: $$ S_{xx} = \\sum_{i=1}^n (x_i^2 - 2x_i \\overline{x} + \\overline{x}^2) $$</p> <p>Simplifying this by distributing the summation: $$ S_{xx} = \\sum_{i=1}^n x_i^2 - 2\\overline{x} \\sum_{i=1}^n x_i + n\\overline{x}^2 $$</p> <p>Since \\(\\sum_{i=1}^n x_i = n\\overline{x}\\): $$ S_{xx} = \\sum_{i=1}^n x_i^2 - 2n\\overline{x}^2 + n\\overline{x}^2 $$</p> <p>Combining the terms results in:  $$ S_{xx} = \\sum_{i=1}^n x_i^2 - n\\overline{x}^2 $$</p> <p>These derivations provide a clear mathematical pathway from the traditional definitions of $ S_{xy} $ and $ S_{xx} $ to the forms that are easily implemented in a python script for instance, and also means we can also formulate the slope as:</p> <p>$$\\boxed{ \\beta_1 = \\frac{S_{xy}}{S_{xx}} = \\frac{\\sum_{i=1}^n x_i y_i - n \\overline{x} \\overline{y}}{\\sum_{i=1}^n x_i^2 - n\\overline{x}^2}} $$</p>"},{"location":"08_Regression/Calculating%20metrics/#breakdown-using-individual-sum-terms","title":"Breakdown Using Individual Sum Terms","text":"<p>Another way to express this is by explicitly calculating the sums:</p> \\[\\boxed{ \\beta_1=\\frac{n \\sum\\left(x_i y_i\\right)-\\sum x_i \\sum y_i}{n \\sum\\left(x_i^2\\right)-\\left(\\sum x_i\\right)^2}} \\] <p>In this expression: - \\(n\\) is the number of observations., - \\(\\sum\\left(x_i y_i\\right)\\) is the sum of the products of corresponding \\(x\\) and \\(y\\) values, - \\(\\sum x_i\\) and \\(\\sum y_i\\) are the sums of \\(x\\) and \\(y\\) values, respectively, - \\(\\sum\\left(x_i^2\\right)\\) is the sum of the squares of \\(x\\) values.</p>"},{"location":"08_Regression/Calculating%20metrics/#covariance-and-variance-method","title":"Covariance and Variance Method:","text":"<p>This is essentially a rearrangement of the least squares formula, emphasizing the use of covariance and variance:    $$\\boxed{    \\beta_1 = \\frac{\\text{Cov}(X, Y)}{\\text{Var}(X)}}    $$    where: - \\(\\text{Cov}(X, Y) = \\frac{\\sum_{i=1}^n (x_i - \\overline{x})(y_i - \\overline{y})}{n-1}\\) (assuming a sample covariance) - \\(\\text{Var}(X) = \\frac{\\sum_{i=1}^n (x_i - \\overline{x})^2}{n-1}\\) (also assuming sample variance)</p>"},{"location":"08_Regression/Calculating%20metrics/#matrix-algebra-using-normal-equation","title":"Matrix Algebra (Using Normal Equation):","text":"<p>When dealing with linear regression in matrix terms, the slope can be calculated using the normal equation:    $$ \\boxed{    \\beta = (X^T X)^{-1} X^T Y}    $$    Here, \\(X\\) is the matrix of input features (including a column of ones for the intercept if it's included in the model), and \\(Y\\) is the vector of output values, and \\(\\beta\\) is a vector that will contain all the coefficients.</p>"},{"location":"08_Regression/Calculating%20metrics/#gradient-descent","title":"Gradient Descent:","text":"<p>Though not a formula in the traditional sense, gradient descent is an algorithmic approach used to find the minimum of the cost function (typically mean squared error) in regression. The update rule in each iteration for \\(\\beta_1\\) would be:    $$\\boxed{    \\beta_1^{(new)} = \\beta_1^{(old)} - \\alpha \\frac{\\partial}{\\partial \\beta_1} MSE}    $$    where \\(\\alpha\\) is the learning rate and \\(\\frac{\\partial}{\\partial \\beta_1} MSE\\) is the derivative of the mean squared error with respect to \\(\\beta_1\\).</p>"},{"location":"08_Regression/Calculating%20metrics/#regression-line-intercept-inclusion","title":"Regression Line Intercept Inclusion","text":"<p>We will also explain how the slope relates to the intercept in the regression equation, presented here as part of the full regression formula:</p> \\[ y = \\beta_0 + \\beta_1 x \\] <p>where $$ \\beta_1 = \\frac{\\sum_{i=1}^n (x_i - \\overline{x})(y_i - \\overline{y})}{\\sum_{i=1}^n (x_i - \\overline{x})^2} $$ (or one of the alternatives from above) and $$\\boxed{ \\beta_0 = \\overline{y} - \\beta_1 \\overline{x}} $$</p>"},{"location":"08_Regression/Calculating%20metrics/#correlation-coefficient-r-and-correlation-of-determination-r2","title":"Correlation Coefficient (\\(r\\)) and Correlation of Determination (\\(r^2\\))","text":"<p>This section will present different formulations of \\(r\\) or \\(r^2\\). Depending on the formulation, one or the other is shown.</p>"},{"location":"08_Regression/Calculating%20metrics/#pearson-correlation-coefficient-r","title":"Pearson Correlation Coefficient (\\(r\\))","text":"<p>The Pearson correlation coefficient (\\(r\\)) measures the linear correlation between two variables, \\(x\\) and \\(y\\). It is defined as the ratio of the covariance of the variables to the product of their standard deviations. Mathematically, it's expressed as:</p> \\[\\boxed{ r = \\frac{\\sum_{i=1}^n (x_i - \\overline{x})(y_i - \\overline{y})}{\\sqrt{\\sum_{i=1}^n (x_i - \\overline{x})^2 \\sum_{i=1}^n (y_i - \\overline{y})^2}} = \\frac{S_{x y}}{\\sqrt{S_{x x} \\cdot S_{y y}}}} \\] <p>Here, \\(\\overline{x}\\) and \\(\\overline{y}\\) are the means of \\(x\\) and \\(y\\), respectively. This formula essentially scales the covariance between \\(x\\) and \\(y\\) by the product of their standard deviations, ensuring that \\(r\\) is dimensionless and ranges between -1 and +1. Also note</p>"},{"location":"08_Regression/Calculating%20metrics/#coefficient-of-determination-r2","title":"Coefficient of Determination (\\(r^2\\))","text":"<p>The coefficient of determination, known as \\(r^2\\), is the square of the Pearson correlation coefficient. It represents the proportion of the variance in the dependent variable that is predictable from the independent variable(s). It is calculated simply by squaring \\(r\\):</p> \\[\\boxed{ r^2 = \\left(\\frac{\\sum_{i=1}^n (x_i - \\overline{x})(y_i - \\overline{y})}{\\sqrt{\\sum_{i=1}^n (x_i - \\overline{x})^2 \\sum_{i=1}^n (y_i - \\overline{y})^2}}\\right)^2} \\] <p>This value ranges from 0 to 1, where 0 indicates no correlation and 1 indicates perfect correlation.</p>"},{"location":"08_Regression/Calculating%20metrics/#alternate-formulas-for-r-and-r2-in-the-context-of-regression","title":"Alternate Formulas for \\(r\\) and \\(r^2\\) in the Context of Regression","text":"<p>In the context of simple linear regression, where you have calculated the slope (\\(\\beta_1\\)) and the intercept (\\(\\beta_0\\)), \\(r\\) and \\(r^2\\) can also be calculated directly from the regression output:</p>"},{"location":"08_Regression/Calculating%20metrics/#using-standard-deviations-and-slope","title":"Using Standard Deviations and Slope:","text":"<p>$$\\boxed{   r = \\beta_1 \\frac{s_x}{s_y}}   $$   where \\(s_x\\) and \\(s_y\\) are the standard deviations of \\(x\\) and \\(y\\), respectively, and \\(\\beta_1\\) is the slope of the regression line. This formula derives from the relationship that the slope of the regression line in standardized units is the correlation coefficient. Note, \\(s_x = \\sqrt{S_{xx}}\\) and Note, \\(s_y = \\sqrt{S_{yy}}\\), in both cases omitting \\(\\frac{1}{n-1}\\).</p>"},{"location":"08_Regression/Calculating%20metrics/#from-the-sum-of-squares","title":"From the Sum of Squares:","text":"<p>$$\\boxed{   r^2 = \\frac{SSR}{SST} = 1-\\frac{SSE}{SST}}   $$</p> <p>In regression analysis, the total sum of squares (SST), the regression sum of squares (SSR), and the sum of squares of errors (SSE) are important quantities for measuring the variability in the data and the performance of the regression model.</p> <ul> <li> <p>Total Sum of Squares (SST)</p> <p>The Total Sum of Squares measures the total variability of the dataset relative to the mean. It is calculated as: $$ \\text{SST} = \\sum_{i=1}^n (y_i - \\overline{y})^2 $$ where \\(y_i\\) are the observed values and \\(\\overline{y}\\) is the mean of the \\(y\\) values.</p> </li> <li> <p>Regression Sum of Squares (SSR)</p> <p>The Regression Sum of Squares measures how much of the total variability in the dependent variable can be explained by the independent variable(s) in the model. It is calculated as: $$ \\text{SSR} = \\sum_{i=1}^n (\\hat{y}_i - \\overline{y})^2 $$ where \\(\\hat{y}_i\\) are the predicted values from the regression model.</p> </li> <li> <p>Sum of Squares of Errors (SSE)</p> <p>The Sum of Squares of Errors measures the variability of the model errors (residuals). It is calculated as: $$ \\text{SSE} = \\sum_{i=1}^n (y_i - \\hat{y}_i)^2 $$ where \\(y_i\\) are the observed values and \\(\\hat{y}_i\\) are the predicted values from the regression model.</p> </li> </ul> <p>These three components are related by the identity:    $$    \\text{SST} = \\text{SSR} + \\text{SSE}    $$    This identity shows that the total variability in the dataset (\\(\\text{SST}\\)) can be decomposed into the variability explained by the regression model (\\(\\text{SSR}\\)) and the variability that is not explained by the model (\\(\\text{SSE}\\)).</p> <p>Each of these formulas provides insight into different aspects of the regression analysis, such as the effectiveness of the model in explaining the variation in the data and the amount of error in the predictions.</p>"},{"location":"08_Regression/Calculating%20metrics/#from-the-z-scores","title":"From the \\(z\\)-scores:","text":"<p>The formula for calculating the Pearson correlation coefficient using standardized scores is:</p> \\[\\boxed{ r = \\frac{\\sum (z_x \\cdot z_y)}{n-1}} \\] <p>where: - \\(z_x = \\frac{x - \\overline{x}}{s_x}\\) and \\(z_y = \\frac{y - \\overline{y}}{s_y}\\) are the standardized scores of \\(x\\) and \\(y\\).  - \\(\\overline{x}\\) and \\(\\overline{y}\\) are the means of \\(x\\) and \\(y\\), respectively. - \\(s_x\\) and \\(s_y\\) are the standard deviations of \\(x\\) and \\(y\\), respectively. - The numerator, \\(\\sum (z_x \\cdot z_y)\\), represents the sum of the products of these standardized scores, effectively capturing the covariance of \\(x\\) and \\(y\\). - The denominator, \\(n-1\\), corrects for the bias in variance estimation from a sample, making the calculation an unbiased estimator of the population correlation coefficient.</p> <p>This approach normalizes both variables to have zero mean and unit variance, simplifying the interpretation of the correlation coefficient as it directly measures the degree of linear relationship between the standardized versions of the original variables.</p>"},{"location":"08_Regression/Calculating%20metrics/#breakdown-using-individual-sum-terms_1","title":"Breakdown Using Individual Sum Terms:","text":"<p>$$\\boxed{   r = \\frac{n \\cdot \\sum (x_i y_i) - \\sum x_i \\cdot \\sum y_i}{\\sqrt{n \\cdot \\sum x_i^2 - (\\sum x_i)^2} \\cdot \\sqrt{n \\cdot y_i^2 - (\\sum y_i)^2}}}   $$</p> <p>where:   - $ \\sum (x_i y_i) $ is the sum of the products of corresponding $ x $ and $ y $ values.   - $ \\sum x_i $ and $ \\sum y_i $ are the sums of all $ x $ values and $ y $ values, respectively.   - $ \\sum x_i^2 $ and $ \\sum y_i^2 $ are the sums of the squares of all $ x $ and $ y $ values, respectively.   - The term $ n $ is the number of data points.</p> <p>The denominator involves the square roots of the products of $ n $ and the sum of squares of $ x $ and $ y $, minus the square of the sum of $ x $ and $ y $ values, all scaled by $ n $. This structure follows the formula for the standard deviation, scaled to the sample size to adjust for bias, fitting the denominator of the correlation coefficient formula. This formula effectively measures the strength and direction of a linear relationship between two variables.</p>"},{"location":"08_Regression/Calculating%20metrics/#example-exam-2020-asignment-7","title":"Example: Exam 2020, Asignment 7:","text":"<p>Problem:</p> <p>A professor in the School of Engineering in a university polled a dozen colleagues about the number of professional meetings they attended in the past five years \\((x)\\) and the number of papers they submitted to refereed journals \\((y)\\) during the same period. The summary data are given as follows: $$ \\begin{aligned} n &amp; =12, \\quad \\bar{x}=4, \\quad \\bar{y}=12 \\ \\sum_{i=1}^n x_i^2 &amp; =232, \\quad \\sum_{i=1}^n x_i y_i=318 \\end{aligned} $$</p> <p>Fit a simple linear regression model between \\(x\\) and \\(y\\) by finding out the estimates of intercept and slope. Hint: Use the Least Squares Estimates formula from the book.</p> <p>Solution:</p> <p>Given the values, we can use one of the variations provided earlier:</p> \\[ \\beta_1 = \\frac{\\sum_{i=1}^n x_i y_i - n \\overline{x} \\overline{y}}{\\sum_{i=1}^n x_i^2 - n \\overline{x}^2} \\] <p>Let's plug in the values:</p> <ul> <li>\\(n = 12\\)</li> <li>\\(\\overline{x} = 4\\)</li> <li>\\(\\overline{y} = 12\\)</li> <li>\\(\\sum_{i=1}^n x_i^2 = 232\\)</li> <li>\\(\\sum_{i=1}^n x_i y_i = 318\\)</li> </ul> <p>Calculating \\(\\beta_1\\):</p> \\[ \\beta_1 = \\frac{318 - 12 \\times 4 \\times 12}{232 - 12 \\times 4^2} \\] <p>In the solution, the following formula, also presented above, is used:</p> \\[ \\beta_1=\\frac{n \\sum\\left(x_i y_i\\right)-\\sum x_i \\sum y_i}{n \\sum\\left(x_i^2\\right)-\\left(\\sum x_i\\right)^2} \\] <p>Plugging these values into the formula: $$ \\beta_1=\\frac{(12)(318)-[(12)(4)][(12)(12)]}{(12)(232)-[(12)(4)]^2} $$</p> <p>Once we have \\(\\beta_1\\), we can calculate the intercept \\(\\beta_0\\) using the formula:</p> \\[ \\beta_0 = \\overline{y} - \\beta_1 \\overline{x} \\] <p>We'll compute \\(\\beta_1\\) first and then use it to find \\(\\beta_0\\).</p> <p>Using the provided data, the estimated parameters for your linear regression model are:</p> <ul> <li>Slope (\\(\\beta_1\\)): \\(-6.45\\)</li> <li>Intercept (\\(\\beta_0\\)): \\(37.8\\)</li> </ul> <p>Thus, the fitted linear regression model can be expressed as: $$ y = 37.8 - 6.45x $$ This equation predicts the value of \\(y\\) based on the value of \\(x\\), with the model suggesting that \\(y\\) decreases by approximately 6.45 units for every one unit increase in \\(x\\).</p>"},{"location":"08_Regression/Test/","title":"Calculating Metrics in Simple Linear Regression","text":""},{"location":"08_Regression/Test/#the-slope-and-intercept","title":"The Slope (and intercept)","text":"<p>In simple linear regression, the slope parameter (often denoted as \\(\\beta_1\\)) represents the relationship between the independent variable (X) and the dependent variable (Y). The slope indicates how much the dependent variable is expected to increase (or decrease) for a one-unit increase in the independent variable. There are several ways to compute this slope, and here are some of the key methods:</p>"},{"location":"08_Regression/Test/#least-squares-estimation","title":"Least Squares Estimation:","text":"<p>The most common method for calculating the slope in simple linear regression is the least squares estimation. The formula for the slope (\\(\\beta_1\\)) using this method is:</p> \\[\\beta_1=\\frac{\\sum_{i=1}^n\\left(x_i-\\bar{x}\\right)\\left(y_i-\\bar{y}\\right)}{\\sum_{i=1}^n\\left(x_i-\\bar{x}\\right)^2}\\] <p>In this expression:</p> <p>\\(\\sum_{i=1}^n (x_i - \\overline{x})(y_i - \\overline{y})\\) is the sum of the products of the deviations of \\(x\\) and \\(y\\) from their respective means. This term captures the covariance between \\(x\\) and \\(y\\), indicating how much \\(x\\) and \\(y\\) vary together from their mean values (though excluding \\(\\frac{1}{n-1}\\)). This term is often denoted \\(S_{xy}\\).</p> <p>\\(\\overline{x}\\) and \\(\\overline{y}\\) are the means of \\(x\\) and \\(y\\), respectively. These are calculated as \\(\\overline{x} = \\frac{1}{n} \\sum_{i=1}^n x_i\\) and </p> <p>\\(\\overline{y} = \\frac{1}{n} \\sum_{i=1}^n y_i\\), where \\(n\\) is the number of observations.</p> <p>\\(\\sum_{i=1}^n (x_i - \\overline{x})^2\\) represents the sum of the squares of the deviations of \\(x\\) from its mean. This term is a measure of the total variance in \\(x\\) and helps normalize the covariance in the numerator. This term is often denoted \\(S_{xy}\\).</p> <p>\\(n\\) is the number of observations, indicating the total number of data points in the dataset.</p>"},{"location":"08_Regression/Test/#sum-of-products","title":"Sum of Products","text":"<p>The fundamental expression for the slope is the one stated above. But we can also use the sum of products which is demonstrated here.</p> <p>Derivation of \\((S_{xy})\\)</p> <p>The regular form for the sum of products of deviations for \\(x\\) and \\(y\\) is: \\(\\(S_{xy} = \\sum_{i=1}^n (x_i - \\overline{x})(y_i - \\overline{y})\\)\\)</p> <p>Expanding this sum: \\(\\(S_{xy} = \\sum_{i=1}^n (x_i y_i - x_i \\overline{y} - y_i \\overline{x} + \\overline{x} \\overline{y})\\)\\)</p> <p>Simplifying this by distributing the summation: \\(\\(S_{xy} = \\sum_{i=1}^n x_i y_i - \\sum_{i=1}^n x_i \\overline{y} - \\sum_{i=1}^n y_i \\overline{x} + n \\overline{x} \\overline{y}\\)\\)</p> <p>Notice that $\\sum_{i=1}^n x_i \\overline{y} $ can be rewritten because \\(\\overline{y}\\) is a constant: \\(\\(\\sum_{i=1}^n x_i \\overline{y} = \\overline{y} \\sum_{i=1}^n x_i\\)\\) And similarly for \\(\\sum_{i=1}^n y_i \\overline{x}\\): \\(\\(\\sum_{i=1}^n y_i \\overline{x} = \\overline{x} \\sum_{i=1}^n y_i\\)\\)</p> <p>Since \\(\\sum_{i=1}^n x_i = n \\overline{x}\\) and \\(\\sum_{i=1}^n y_i = n \\overline{y}\\), the terms simplify to: \\(\\(S_{xy} = \\sum_{i=1}^n x_i y_i - n \\overline{x} \\overline{y}\\)\\)</p> <p>Derivation of \\(S_{xx}\\)</p> <p>The regular form for the sum of squares of deviations for $ x $ is: \\(\\(S_{xx} = \\sum_{i=1}^n (x_i - \\overline{x})^2\\)\\)</p> <p>Expanding this sum: \\(\\(S_{xx} = \\sum_{i=1}^n (x_i^2 - 2x_i \\overline{x} + \\overline{x}^2)\\)\\)</p> <p>Simplifying this by distributing the summation: \\(\\(S_{xx} = \\sum_{i=1}^n x_i^2 - 2\\overline{x} \\sum_{i=1}^n x_i + n\\overline{x}^2\\)\\)</p> <p>Since \\(\\sum_{i=1}^n x_i = n\\overline{x}\\): \\(\\(S_{xx} = \\sum_{i=1}^n x_i^2 - 2n\\overline{x}^2 + n\\overline{x}^2\\)\\)</p> <p>Combining the terms results in: \\(\\(S_{xx} = \\sum_{i=1}^n x_i^2 - n\\overline{x}^2\\)\\)</p> <p>These derivations provide a clear mathematical pathway from the traditional definitions of $ S_{xy} $ and $ S_{xx} $ to the forms that are easily implemented in a python script for instance, and also means we can also formulate the slope as:</p> \\[\\boxed{\\beta_1 = \\frac{S_{xy}}{S_{xx}} = \\frac{\\sum_{i=1}^n x_i y_i - n \\overline{x} \\overline{y}}{\\sum_{i=1}^n x_i^2 - n\\overline{x}^2}}\\]"},{"location":"08_Regression/Test/#breakdown-using-individual-sum-terms","title":"Breakdown Using Individual Sum Terms","text":"<p>Another way to express this is by explicitly calculating the sums:</p> \\[\\boxed{\\beta_1=\\frac{n \\sum\\left(x_i y_i\\right)-\\sum x_i \\sum y_i}{n \\sum\\left(x_i^2\\right)-\\left(\\sum x_i\\right)^2}}\\] <p>In this expression: - \\(n\\) is the number of observations., - \\(\\sum\\left(x_i y_i\\right)\\) is the sum of the products of corresponding \\(x\\) and \\(y\\) values, - \\(\\sum x_i\\) and \\(\\sum y_i\\) are the sums of \\(x\\) and \\(y\\) values, respectively, - \\(\\sum\\left(x_i^2\\right)\\) is the sum of the squares of \\(x\\) values.</p>"},{"location":"08_Regression/Test/#covariance-and-variance-method","title":"Covariance and Variance Method:","text":"<p>This is essentially a rearrangement of the least squares formula, emphasizing the use of covariance and variance:    \\(\\(\\boxed{\\beta_1 = \\frac{\\text{Cov}(X, Y)}{\\text{Var}(X)}}\\)\\)    where: - \\(\\text{Cov}(X, Y) = \\frac{\\sum_{i=1}^n (x_i - \\overline{x})(y_i - \\overline{y})}{n-1}\\) (assuming a sample covariance) - \\(\\text{Var}(X) = \\frac{\\sum_{i=1}^n (x_i - \\overline{x})^2}{n-1}\\) (also assuming sample variance)</p>"},{"location":"08_Regression/Test/#matrix-algebra-using-normal-equation","title":"Matrix Algebra (Using Normal Equation):","text":"<p>When dealing with linear regression in matrix terms, the slope can be calculated using the normal equation:    $$ \\boxed{\\beta = (X^T X)^{-1} X^T Y}$$    Here, \\(X\\) is the matrix of input features (including a column of ones for the intercept if it's included in the model), and \\(Y\\) is the vector of output values, and \\(\\beta\\) is a vector that will contain all the coefficients.</p>"},{"location":"08_Regression/Test/#gradient-descent","title":"Gradient Descent:","text":"<p>Though not a formula in the traditional sense, gradient descent is an algorithmic approach used to find the minimum of the cost function (typically mean squared error) in regression. The update rule in each iteration for \\(\\beta_1\\) would be:    \\(\\(\\boxed{\\beta_1^{(new)} = \\beta_1^{(old)} - \\alpha \\frac{\\partial}{\\partial \\beta_1} MSE}\\)\\)    where \\(\\alpha\\) is the learning rate and \\(\\frac{\\partial}{\\partial \\beta_1} MSE\\) is the derivative of the mean squared error with respect to \\(\\beta_1\\).</p>"},{"location":"08_Regression/Test/#regression-line-intercept-inclusion","title":"Regression Line Intercept Inclusion","text":"<p>We will also explain how the slope relates to the intercept in the regression equation, presented here as part of the full regression formula:</p> \\[y = \\beta_0 + \\beta_1 x\\] <p>where \\(\\(\\beta_1 = \\frac{\\sum_{i=1}^n (x_i - \\overline{x})(y_i - \\overline{y})}{\\sum_{i=1}^n (x_i - \\overline{x})^2}\\)\\) (or one of the alternatives from above) and \\(\\(\\boxed{\\beta_0 = \\overline{y} - \\beta_1 \\overline{x}}\\)\\)</p>"},{"location":"08_Regression/Test/#correlation-coefficient-r-and-correlation-of-determination-r2","title":"Correlation Coefficient (\\(r\\)) and Correlation of Determination (\\(r^2\\))","text":"<p>This section will present different formulations of \\(r\\) or \\(r^2\\). Depending on the formulation, one or the other is shown.</p>"},{"location":"08_Regression/Test/#pearson-correlation-coefficient-r","title":"Pearson Correlation Coefficient (\\(r\\))","text":"<p>The Pearson correlation coefficient (\\(r\\)) measures the linear correlation between two variables, \\(x\\) and \\(y\\). It is defined as the ratio of the covariance of the variables to the product of their standard deviations. Mathematically, it's expressed as:</p> \\[\\boxed{r = \\frac{\\sum_{i=1}^n (x_i - \\overline{x})(y_i - \\overline{y})}{\\sqrt{\\sum_{i=1}^n (x_i - \\overline{x})^2 \\sum_{i=1}^n (y_i - \\overline{y})^2}} = \\frac{S_{x y}}{\\sqrt{S_{x x} \\cdot S_{y y}}}}\\] <p>Here, \\(\\overline{x}\\) and \\(\\overline{y}\\) are the means of \\(x\\) and \\(y\\), respectively. This formula essentially scales the covariance between \\(x\\) and \\(y\\) by the product of their standard deviations, ensuring that \\(r\\) is dimensionless and ranges between -1 and +1. Also note</p>"},{"location":"08_Regression/Test/#coefficient-of-determination-r2","title":"Coefficient of Determination (\\(r^2\\))","text":"<p>The coefficient of determination, known as \\(r^2\\), is the square of the Pearson correlation coefficient. It represents the proportion of the variance in the dependent variable that is predictable from the independent variable(s). It is calculated simply by squaring \\(r\\):</p> \\[\\boxed{r^2 = \\left(\\frac{\\sum_{i=1}^n (x_i - \\overline{x})(y_i - \\overline{y})}{\\sqrt{\\sum_{i=1}^n (x_i - \\overline{x})^2 \\sum_{i=1}^n (y_i - \\overline{y})^2}}\\right)^2}\\] <p>This value ranges from 0 to 1, where 0 indicates no correlation and 1 indicates perfect correlation.</p>"},{"location":"08_Regression/Test/#alternate-formulas-for-r-and-r2-in-the-context-of-regression","title":"Alternate Formulas for \\(r\\) and \\(r^2\\) in the Context of Regression","text":"<p>In the context of simple linear regression, where you have calculated the slope (\\(\\beta_1\\)) and the intercept (\\(\\beta_0\\)), \\(r\\) and \\(r^2\\) can also be calculated directly from the regression output:</p>"},{"location":"08_Regression/Test/#using-standard-deviations-and-slope","title":"Using Standard Deviations and Slope:","text":"<p>\\(\\(\\boxed{r = \\beta_1 \\frac{s_x}{s_y}}\\)\\)   where \\(s_x\\) and \\(s_y\\) are the standard deviations of \\(x\\) and \\(y\\), respectively, and \\(\\beta_1\\) is the slope of the regression line. This formula derives from the relationship that the slope of the regression line in standardized units is the correlation coefficient. Note, \\(s_x = \\sqrt{S_{xx}}\\) and Note, \\(s_y = \\sqrt{S_{yy}}\\), in both cases omitting \\(\\frac{1}{n-1}\\).</p>"},{"location":"08_Regression/Test/#from-the-sum-of-squares","title":"From the Sum of Squares:","text":"<p>\\(\\(\\boxed{r^2 = \\frac{SSR}{SST} = 1-\\frac{SSE}{SST}}\\)\\)</p> <p>In regression analysis, the total sum of squares (SST), the regression sum of squares (SSR), and the sum of squares of errors (SSE) are important quantities for measuring the variability in the data and the performance of the regression model.</p> <ul> <li> <p>Total Sum of Squares (SST)</p> <p>The Total Sum of Squares measures the total variability of the dataset relative to the mean. It is calculated as: \\(\\(\\text{SST} = \\sum_{i=1}^n (y_i - \\overline{y})^2\\)\\) where \\(y_i\\) are the observed values and \\(\\overline{y}\\) is the mean of the \\(y\\) values.</p> </li> <li> <p>Regression Sum of Squares (SSR)</p> <p>The Regression Sum of Squares measures how much of the total variability in the dependent variable can be explained by the independent variable(s) in the model. It is calculated as: \\(\\(\\text{SSR} = \\sum_{i=1}^n (\\hat{y}_i - \\overline{y})^2\\)\\) where \\(\\hat{y}_i\\) are the predicted values from the regression model.</p> </li> <li> <p>Sum of Squares of Errors (SSE)</p> <p>The Sum of Squares of Errors measures the variability of the model errors (residuals). It is calculated as: \\(\\(\\text{SSE} = \\sum_{i=1}^n (y_i - \\hat{y}_i)^2\\)\\) where \\(y_i\\) are the observed values and \\(\\hat{y}_i\\) are the predicted values from the regression model.</p> </li> </ul> <p>These three components are related by the identity:    \\(\\(\\text{SST} = \\text{SSR} + \\text{SSE}\\)\\)    This identity shows that the total variability in the dataset (\\(\\text{SST}\\)) can be decomposed into the variability explained by the regression model (\\(\\text{SSR}\\)) and the variability that is not explained by the model (\\(\\text{SSE}\\)).</p> <p>Each of these formulas provides insight into different aspects of the regression analysis, such as the effectiveness of the model in explaining the variation in the data and the amount of error in the predictions.</p>"},{"location":"08_Regression/Test/#from-the-z-scores","title":"From the \\(z\\)-scores:","text":"<p>The formula for calculating the Pearson correlation coefficient using standardized scores is:</p> \\[\\boxed{r = \\frac{\\sum (z_x \\cdot z_y)}{n-1}}\\] <p>where: - \\(z_x = \\frac{x - \\overline{x}}{s_x}\\) and \\(z_y = \\frac{y - \\overline{y}}{s_y}\\) are the standardized scores of \\(x\\) and \\(y\\).  - \\(\\overline{x}\\) and \\(\\overline{y}\\) are the means of \\(x\\) and \\(y\\), respectively. - \\(s_x\\) and \\(s_y\\) are the standard deviations of \\(x\\) and \\(y\\), respectively. - The numerator, \\(\\sum (z_x \\cdot z_y)\\), represents the sum of the products of these standardized scores, effectively capturing the covariance of \\(x\\) and \\(y\\). - The denominator, \\(n-1\\), corrects for the bias in variance estimation from a sample, making the calculation an unbiased estimator of the population correlation coefficient.</p> <p>This approach normalizes both variables to have zero mean and unit variance, simplifying the interpretation of the correlation coefficient as it directly measures the degree of linear relationship between the standardized versions of the original variables.</p>"},{"location":"08_Regression/Test/#breakdown-using-individual-sum-terms_1","title":"Breakdown Using Individual Sum Terms:","text":"<p>\\(\\(\\boxed{r = \\frac{n \\cdot \\sum (x_i y_i) - \\sum x_i \\cdot \\sum y_i}{\\sqrt{n \\cdot \\sum x_i^2 - (\\sum x_i)^2} \\cdot \\sqrt{n \\cdot y_i^2 - (\\sum y_i)^2}}}\\)\\)</p> <p>where:   - $ \\sum (x_i y_i) $ is the sum of the products of corresponding $ x $ and $ y $ values.   - $ \\sum x_i $ and $ \\sum y_i $ are the sums of all $ x $ values and $ y $ values, respectively.   - $ \\sum x_i^2 $ and $ \\sum y_i^2 $ are the sums of the squares of all $ x $ and $ y $ values, respectively.   - The term $ n $ is the number of data points.</p> <p>The denominator involves the square roots of the products of $ n $ and the sum of squares of $ x $ and $ y $, minus the square of the sum of $ x $ and $ y $ values, all scaled by $ n $. This structure follows the formula for the standard deviation, scaled to the sample size to adjust for bias, fitting the denominator of the correlation coefficient formula. This formula effectively measures the strength and direction of a linear relationship between two variables.</p>"},{"location":"08_Regression/Test/#example-exam-2020-asignment-7","title":"Example: Exam 2020, Asignment 7:","text":"<p>Problem:</p> <p>A professor in the School of Engineering in a university polled a dozen colleagues about the number of professional meetings they attended in the past five years \\((x)\\) and the number of papers they submitted to refereed journals \\((y)\\) during the same period. The summary data are given as follows: \\(\\(\\begin{aligned} n &amp; =12, \\quad \\bar{x}=4, \\quad \\bar{y}=12 \\\\ \\sum_{i=1}^n x_i^2 &amp; =232, \\quad \\sum_{i=1}^n x_i y_i=318 \\end{aligned}\\)\\)</p> <p>Fit a simple linear regression model between \\(x\\) and \\(y\\) by finding out the estimates of intercept and slope. Hint: Use the Least Squares Estimates formula from the book.</p> Click here to see the solution <p>Given the values, we can use one of the variations provided earlier:  $$\\beta_1 = \\frac{\\sum_{i=1}^n x_i y_i - n \\overline{x} \\overline{y}}{\\sum_{i=1}^n x_i^2 - n \\overline{x}^2}$$  Let's plug in the values:  - $n = 12$ - $\\overline{x} = 4$ - $\\overline{y} = 12$ - $\\sum_{i=1}^n x_i^2 = 232$ - $\\sum_{i=1}^n x_i y_i = 318$  Calculating $\\beta_1$:  $$\\beta_1 = \\frac{318 - 12 \\times 4 \\times 12}{232 - 12 \\times 4^2}$$  In the solution, the following formula, also presented above, is used:  $$\\beta_1=\\frac{n \\sum\\left(x_i y_i\\right)-\\sum x_i \\sum y_i}{n \\sum\\left(x_i^2\\right)-\\left(\\sum x_i\\right)^2}$$  Plugging these values into the formula: $$\\beta_1=\\frac{(12)(318)-[(12)(4)][(12)(12)]}{(12)(232)-[(12)(4)]^2}$$   Once we have $\\beta_1$, we can calculate the intercept $\\beta_0$ using the formula:  $$\\beta_0 = \\overline{y} - \\beta_1 \\overline{x}$$  We'll compute $\\beta_1$ first and then use it to find $\\beta_0$.  Using the provided data, the estimated parameters for your linear regression model are:  - Slope ($\\beta_1$): $-6.45$ - Intercept ($\\beta_0$): $37.8$  Thus, the fitted linear regression model can be expressed as: $$y = 37.8 - 6.45x$$ This equation predicts the value of $y$ based on the value of $x$, with the model suggesting that $y$ decreases by approximately 6.45 units for every one unit increase in $x$.</p>"},{"location":"09_Introduction_to_Stochastic_Processes/","title":"09 Introduction to Stochastic Processes","text":"09 Introduction to Stochastic Processes"},{"location":"09_Introduction_to_Stochastic_Processes/#material","title":"Material:","text":"<p>Markov Chains Ch. 1 (the rest is not in the syllabus)</p> <p>Matrix Algebra (optional)</p> <p>Recap Regression</p> <p>Session notes</p> <p>Session material</p> <p>Session from 20/21: SMP 9</p>"},{"location":"09_Introduction_to_Stochastic_Processes/#topics","title":"Topics","text":"<p>The topics of this and next week require a bit of knowledge of matrices and matrix algebra. I recommend reading \u201cMatrix Algebra\u201d which is the chapter we use from the Linear Algebra course. If you already passed the Linear Algebra course (i.e. you are on your 7<sup>th</sup> semester), you will probably not need to worry about this prerequisite.</p> <p>Stochastic processes are mathematical models used to describe the evolution of systems that involve randomness. The most important elements of stochastic processes are their underlying probability distributions and the properties of their randomness, such as stationarity, independence, and Markovianity. The probability distribution of a stochastic process describes the likelihood of different possible outcomes at any given time, while the properties of randomness determine how the outcomes are related to each other over time. Stochastic processes can be classified into discrete-time or continuous-time, and they can be used to model a wide range of phenomena, including financial markets, stock prices, traffic flow, weather patterns, and biological systems.</p> <ul> <li>What is a random/stochastic process (as opposed to a random variable)?</li> <li>Poisson process</li> <li>Random walk</li> <li>Markov chains</li> </ul> <p>The first two items are not directly covered in the literature and will be based on what I go through during class.</p>"},{"location":"09_Introduction_to_Stochastic_Processes/#problems-to-be-worked-on-inafter-class","title":"Problems to be worked on in/after class:","text":"<p>None specifically, but do some Wiseflow exercises</p>"},{"location":"10_Markov_Chains/","title":"10 Markov Chains","text":"10 Markov Chains <p>Material:</p> <p>Recap notes</p> <p>Session notes</p> <p>Session material</p> <p>Session from 20/21: SMP 10</p>"},{"location":"10_Markov_Chains/#topics","title":"Topics","text":"<p>Markov chains are a mathematical framework used to model systems that change over time, such as the weather or the stock market. The key feature of a Markov chain is that it assumes that the future state of the system depends only on its current state, and not on any previous states. This is known as the Markov property. Markov chains are defined by a set of states, a transition matrix that describes the probabilities of moving from one state to another, and an initial state. The long-term behavior of a Markov chain can be analyzed using techniques such as finding the stationary distribution or calculating expected values. Markov chains are used in a wide range of applications, including computer science, physics, finance, and biology, among others.</p> <ul> <li>Markov property: The assumption that the future state of a system depends only on its current state, and not on any previous states.</li> <li>State: A possible condition or configuration of the system being modeled.</li> <li>Transition matrix: A matrix that describes the probabilities of moving from one state to another.</li> <li>Stationary distribution: The long-term distribution of states that a Markov chain approaches over time.</li> <li>Expected value: The average value that a variable takes over many iterations of the Markov chain.</li> </ul>"},{"location":"10_Markov_Chains/#problems-to-be-worked-on-in-class","title":"Problems to be worked on in class:","text":"<p>Do Problems 10 and the Wiseflow exam cases covering the final topics.</p>"},{"location":"11_Recap_and_Exercises_Markov_Chains/","title":"11 Recap and Exercises","text":"11 Recap and Exercises Markov Chains <p>Material:</p> <p>Session notes</p> <p>Session exercises - Problems 10</p> <p>Session material</p>"},{"location":"11_Recap_and_Exercises_Markov_Chains/#topics","title":"Topics","text":"<p>Recap and exercises in last weeks topic.</p>"},{"location":"11_Recap_and_Exercises_Markov_Chains/#problems-to-be-worked-on-in-class","title":"Problems to be worked on in class:","text":"<p>Do Problems the Wiseflow exam cases covering the final topics as well as previous exams in Wiseflow.</p>"},{"location":"Sessions/","title":"Sessions","text":"<p>Click on a session to the left to access a plan of a specific session and additional resources for that session.</p> Session Date Topic 00 Important Recap 01 4 Feb 12:45 \u2013 16:05 Introduction + Recap Probability + Stochastic Variables 02 11 Feb 12:45 \u2013 16:05 Discrete Random Variables 03 18 Feb 12:45 \u2013 16:05 Continuous Random Variables 04 25 Feb 12:45 \u2013 16:05 Normal and Exponential Distributions and Multivariate Random Variables 05 4 Mar 12:45 \u2013 16:05 Multivariate Random Variables Part 2 06 11 Mar 12:45 \u2013 16:05 Point Estimation, Sampling and Statistical Intervals 07 25 Mar 12:45 \u2013 16:05 Hypothesis Testing 08 1 Apr 12:45 \u2013 16:05 Regression 09 8 Apr 12:45 \u2013 16:05 Introduction to Stochastic Processes 10 22 Apr 12:45 \u2013 16:05 Markov Chains 11 29 Apr 12:45 \u2013 16:05 Recap and Exercises Markov Chains"},{"location":"blog/","title":"Blog","text":""},{"location":"pages/exam/","title":"Exam","text":"Exam"},{"location":"pages/exam/#exam-prerequisites","title":"Exam prerequisites:","text":"<p>None</p>"},{"location":"pages/exam/#exam-type","title":"Exam type","text":"<p>The exam has two parts:</p> <ul> <li>The first part is a Flowlock exam in Wiseflow.</li> <li>The second part is a Wiseflow exam without Flowlock. The second part must be completed in the Jupyter Notebook environment and the answers must be submitted in Wiseflow.</li> </ul> <p>Part 1 has a duration of 3 hours and part 2 has a duration of 1 hour. The exam has a total duration of 4 hours.  The student will not be able to access the second part before the first part is concluded. Part 1 weighs 75% and Part 2 weighs 25% in the final grade.</p>"},{"location":"pages/exam/#tools-allowed","title":"Tools allowed","text":"<p>In the first part the students are allowed to use any notes, books, and/or other written/printed material and will have access to PDF files on their laptop.</p> <p>The students may bring their own calculator.</p> <p>In the second part all supplementary materials and aids are allowed, e.g., using a computer as a reference work.</p> <p>It is not allowed, however, to use AI-tools such as Copilot, ChatGPT, Bing, etc. Communication of any sort is not allowed during the exam and will lead to expulsion of all involved parties from the exam.</p>"},{"location":"pages/exam/#re-exam","title":"Re-exam","text":"<p>Re-exams may be oral.</p>"},{"location":"pages/faq/","title":"FAQ","text":"FAQ"},{"location":"pages/faq/#general-information","title":"General information","text":"Is there a FAQ for the course? <p>Yes, you are looking at it! This FAQ is designed to answer some of the most common questions about the course. If you have a question that is not answered here, please feel free to contact the course responsible, Richard Brooks</p> What is the course about? <p>The course covers an introduction to probability theory and statistics. In depth description can be found in the course description or by going the description of each session in the Sessions menu.</p> How is the course related to the study program? <p>The course mostly relates to the study program by providing a foundation for understanding and applying probability theory and statistics in the context of engineering, especially in the field of data science and machine learning.</p> What are the prerequisites for the course? <p>In the menu to the left, you can find the prerequisites for the course under the \"Prerequisites\" section. The course is designed to be self-contained, but it is recommended that students have a basic understanding of the topics listed.</p> Who should take this course? <p>The course is intended for students who are interested in learning about probability theory and statistics and how to apply them in the context of engineering. It is very useful for students who are interested in data science and machine learning. It is a complex course, and you should only take it if you are willing to put in the effort to learn the material. The course is mandatory for some Master's programs.</p> Is attendance mandatory? <p>Attendance is not mandatory, but it is highly recommended. The course is complex, and it is important to keep up with the material. If you are unable to attend a session, you should make sure to catch up on the material, e.g. by watching the recording of the 2021 session.</p>"},{"location":"pages/faq/#who-to-contact","title":"Who to contact?","text":"Who should I contact if I have questions about the course content? <p>You can contact the course responsible, Richard Brooks, if you have questions about the course content.</p> Who should I contact if I have questions about the exam? <p>You should always contact the Study Service if you have questions about the exam.</p> Who should I contact if I have questions about the schedule? <p>You can contact our scheduler if you have questions about the schedule.</p> Who should I contact if I have scheduling conflicts? <p>You can contact our scheduler if you have questions about scheduling conflicts.</p> Who should I contact if I want to know whether this course is mandatory for a Master's program or if it satisfies a specific requirement? <p>You can contact the Study Councillor.</p>"},{"location":"pages/faq/#exam-and-assessment","title":"Exam and assessment","text":"What type of exam will conclude the course <p>Please see the \"Exam\" section in the menu to the left for detailed information about the exam.</p> When will the exam and re-exam be held? <p>The exam is usually held in June and the re-exam in August. The exact dates will be published in the exam plan in MyVia. Feel free to contact the Study Service for more information.</p> What is the grading scale for the course? <p>The grading scale for the course is the 7-point grading scale.</p> How is the final grade calculated? <p>The final grade is calculated based on the exam. The exam has two parts: a Flowlock exam in Wiseflow and a Wiseflow exam without Flowlock. Part 1 weighs 75% and Part 2 weighs 25% in the final grade. Please see the \"Exam\" section in the menu to the left for more information.</p> What is the re-exam procedure? <p>Re-exams may be oral. Please see the \"Exam\" section in the menu to the left for more information.</p> What happens if I fail the exam? <p>If you fail the exam, you will have the opportunity to take a re-exam. Please see the \"Exam\" section in the menu to the left for more information.</p> What happens if I fail the re-exam? <p>If you fail the re-exam, you will have to wait until the course is held again to retake the exam. In special cases, we may be able to offer you an oral re-exam. Please see the \"Exam\" section in the menu to the left for more information.</p> How many percentage points do I need to pass the exam? <p>The exam is graded on a 7-point grading scale. To pass the exam, you need a grade of 02 or higher. In order to obtain a 02, you need to score at least 50% of the total points on the exam. This score may vary from year to year, but is never higher than 50%.</p>"},{"location":"pages/faq/#resources","title":"Resources","text":"Is the course book mandatory? <p>The course book is not mandatory, but I do recommend finding some resources to help you understand the material. The course book is a good resource, but there are many other resources available online. I recommend Probability Course as a good resource.</p> Is Python mandatory? <p>Python is mandatory for the course. You will need to use Python to complete the assignments and the exam. If you are not familiar with Python, I recommend finding some resources to help you learn the basics.</p> Is Jupyter Notebook mandatory? <p>Jupyter Notebook is mandatory for the course. You will need to use Jupyter Notebook to complete the assignments and the exam. You can install a Plugin in VSCode to run Jupyter Notebooks.</p> Is the course material available online? <p>Yes, the course material is available online. You can find all material by navigating the menu to the left.</p> Is there a recommended study plan? <p>Yes, I recommend following the study plan outlined in the course material. You can find the study plan in the course material by navigating the menu to the left.</p> Where do I find material such as old exam cases, solutions, and other resources? <p>You can find all material by navigating the menu to the left, see \"General Resources SMP\".</p> Are there any additional resources available? <p>Yes, there are many additional resources available online. I recommend checking out the resources listed in the course material. You can find the resources by navigating the menu to the left.</p> What is the Wiseflow code? <p>The Wiseflow code for the course is 0000. However, at the exam you will be given specific codes.</p>"}]}