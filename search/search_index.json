{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"<p> Stochastic Modelling and Processes - Spring 2025 <p>Repository for SMP1-S25 at VIA.</p> <p>Checkout the homepage!</p> </p> <p> </p>"},{"location":"#course-information","title":"Course information","text":"<ul> <li>Course responsible: Associate Professor Richard Brooks, rib@via.dk</li> <li>5 ECTS (European Credit Transfer System), corresponding to 130 hours of work</li> <li>11 sessions, each with a duration of 4 lessons, starting in week 6</li> <li>Bachelor level course - the course is academically challenging working on problems independently.</li> <li>Grade: 7-step scale</li> <li>Type of assessment: 4-hour written exam (see exam description in the menu to the left)</li> <li>Recommended prerequisites: In \"Sessions\" in the left menu, a dedicated entry is made for prerequisites.</li> </ul>"},{"location":"#lectures-and-course-organization","title":"Lectures and course organization","text":"<p>The course is scheduled to start in week 6 and will be held on Tuesdays from 12:45 to 16:05 in room C04.16. In general, each session is made up of four activities:</p> <ol> <li>At the beginning of each session, there will be a short recap of the previous session.</li> <li>We then go through the exercises from the previous session.</li> <li>We will go through the theory of the current session.</li> <li>After classes, and before the next session, you will have to solve exercises from the current session.</li> </ol> <p>This then loops back to (1) at the beginning of the next session.</p> <p>There are no mandatory assignments, but it is highly recommended work on the exercises for each session. No instruction is provided for the exercises so you will have to work on them on your own or form study groups.</p>"},{"location":"#course-content-and-learning-objectives","title":"Course content and learning objectives","text":"<p>Stochastic Modelling and Processes is the art of making sense of randomness in the world around us. We examine probability theory, finding the tools to describe and analyse random systems mathematically. You'll learn about random variables \u2014 their mean, variance, and the distributions that define them \u2014 and learn how these concepts power everything from decision-making to machine learning.</p> <p>Learning Objectives</p> <ul> <li>Probability: Understand the fundamental concepts of probability theory, including experiments, sample spaces, independence, conditional probability, and Bayes' theorem. Learn to approach random systems methodically using probabilistic reasoning.</li> <li>Random Variables: Describe and analyse random systems through random variables. Understand their characteristics, including mean, variance, standard deviation, and commonly used distributions like normal, binomial, and Poisson.</li> <li>Point Estimation: Learn techniques to estimate population parameters from sample data and evaluate the quality and reliability of these estimates.</li> <li>Statistical Intervals: Construct and interpret confidence intervals for population parameters. Learn to assess the precision of estimates and their implications for statistical inference.</li> <li>Hypothesis Testing: Explore the principles of hypothesis testing. Learn to formulate null and alternative hypotheses, compute and interpret p-values, and make informed decisions based on statistical evidence.</li> <li>Regression Analysis: Investigate relationships between variables using regression models. Understand how to fit, interpret, and assess the quality of regression models for real-world data.</li> <li>Stochastic Processes: Model and analyse systems that evolve over time using stochastic processes, including applications of Markov Chains for dynamic systems.</li> <li>Python for Statistical Modelling: Gain hands-on experience with Python for data analysis, simulating random variables, conducting statistical tests, and visualizing statistical data to reinforce theoretical understanding.</li> <li>Critique and Evaluate Statistical Models: Develop the competence to critically assess statistical models and results. Identify sources of error, critique experimental designs, and propose improvements for better reliability.</li> </ul> <p>But it's not just about theory. You'll get hands-on with Python, simulating randomness, running statistical tests, and exploring applications of stochastic models. By the end, you\u2019ll not only understand how to model uncertainty but also how to use it to make informed predictions and decisions.</p>"},{"location":"#resources","title":"Resources","text":"<p>ASPE: Montgomery, D.C. &amp; Runger, G.C.. Applied Statistics and Probability for Engineers, 7<sup>th</sup> edition. All references are to chapters or exercises (found in the end of the book). Solutions to all exercises from the book are uploaded. You need to retrieve a copy however you usually retrieve books.</p> <p>Non-session specific resources such as the exercises from the book, solutions, old exam cases, etc. can be found her:</p> <p>General Resources SMP</p> <p>The Wiseflow code for all flows that are used during the course is always 0000. This is not the code for the actual exam in June, though.</p> <p>The course is loosely built up around H. Pishro-Nik's https://www.probabilitycourse.com/</p> <p>I have compiled and uploaded all session from January 2021 to youtube. The link below will take you to a playlist containing all 10 sessions (theory only)</p> <p>Stochastic Modelling 2021 \u2013 All sessions</p> <p>Make sure you install a working version of Jupyter Notebook and Python version 3.7 or higher. The easiest way to install Python and Jupyter is using Anaconda Distribution. You can choose whichever framework you want to work in as long as it can handle Jupyter Notebooks. Installing VS Code with a Jupyter Notebook extension seems to be a popular choice.</p>"},{"location":"#historical-notes","title":"Historical Notes","text":"<p>Stichastic Modelling and Processing was first offered in 2014 and has been scheduled 1-2 times per year since then. The course responsible is Richard Brooks (RIB) and has been the only lecturer teaching the course.</p> <p>Grade Distribution 2024 (ordinary exam only)</p> Grade Count 12 1 10 8 7 12 4 5 02 3 00 2 -3 3"},{"location":"00_Important_Recap/","title":"00 Prerequisties","text":"Important Math Recap"},{"location":"00_Important_Recap/#material-for-recap","title":"Material for recap","text":"<p>Session material</p>"},{"location":"00_Important_Recap/#topics-to-recap","title":"Topics to recap","text":"<p>Most of the topics can be found in our course Mathematics for Software Engineers (MSE). I have written a book for that course and it covers the topics quite well. The reference below are to the slides found in the material above as well as the book chapters that also correspond to the MSE course sessions.</p>"},{"location":"00_Important_Recap/#boolean-algebra","title":"Boolean Algebra:","text":"<ul> <li>Ch. 4</li> <li>Similar to sets, so all rules also apply for sets</li> <li>Addition is same as union, multiplication the same as intersection and negation same as complement</li> <li>Important: Slide 12 about identities</li> </ul>"},{"location":"00_Important_Recap/#sets","title":"Sets","text":"<ul> <li>Ch. 5</li> <li>Basic understanding of sets</li> <li>Important: Equivalence slide 29</li> </ul>"},{"location":"00_Important_Recap/#combinatorics","title":"Combinatorics","text":"<ul> <li>Ch. 5</li> <li>All rules are important, and I assume you know them</li> <li>The most used one is combinations on slide 12</li> <li>Important: Formulas Slide 12</li> </ul>"},{"location":"00_Important_Recap/#probability-1-2-23-probability-2-slide-3","title":"Probability 1 + 2 (2.3 = Probability 2 slide 3)","text":"<ul> <li>Ch. 5-6</li> <li>All rules of probability</li> <li>Important: Union 1.13, Conditional 2.2, Independence 2.3, Intersection 2.6, Law of Total Probability 2.8, Bayes\u2019 Theorem 2.10, Contingency Table 2.12, Joint Probability 2.14</li> </ul>"},{"location":"00_Important_Recap/#sequences-and-summation","title":"Sequences and Summation:","text":"<ul> <li>Appendix A</li> <li>The important part is Series from slide 19 onwards, not so much sequences (slides 1-18)</li> <li>Convergence slide 23</li> <li>Closed form formulae for series slide 24</li> <li>Useful summations and closed form slide 25</li> <li>Changing limits slide 26</li> </ul>"},{"location":"00_Important_Recap/#matrix-algebra","title":"Matrix Algebra:","text":"<ul> <li>Ch. 7-9</li> <li>Basic understanding of matrices</li> <li>Using matrices for solving systems of equations</li> <li>Inverse matrices</li> <li>Matrix exponentiation</li> </ul> <p>In Lesson 3, you will need to brush up on integrals. It seems that Khan Academy has some nice tutorials on integrals that you may want to check out:  Connecting the First and Second Fundamental Theorems of Calculus,  Antiderivative of x + 1,  and  Reverse Power Rule for Definite Integrals.</p>"},{"location":"01_Introduction_%2B_Recap_Probability_%2B_Stochastic_Variables/","title":"01 Introduction to Probability and Random Variables","text":"Introduction + Probability + Stochastic Variables"},{"location":"01_Introduction_%2B_Recap_Probability_%2B_Stochastic_Variables/#session-preparation","title":"Session Preparation:","text":"<p>ASPE: 1-2</p> <p>There are no exercises to be solved before class, since it is the first class. However, it is recommended to go through the material and make sure you understand the concepts.</p> <p>Also, check out the prerequisites for the course.</p>"},{"location":"01_Introduction_%2B_Recap_Probability_%2B_Stochastic_Variables/#session-material","title":"Session Material","text":"<p>Session Notes</p> <p>Session material</p> <p>Make sure you are acquainted with common Series, Approximations, and Identities</p> <p>Session from 20/21:</p>"},{"location":"01_Introduction_%2B_Recap_Probability_%2B_Stochastic_Variables/#session-description","title":"Session Description","text":"<p>In this session, we will look at the foundational principles of statistics and probability theory, starting with an understanding of why these fields are essential for analysing data and making predictions. We will discuss the distinction between samples and populations, along with key measures and scales of measurement. The session will introduce random experiments and the foundational concepts of probabilities.</p> <p>Building on this, we will review key concepts in probability, including types of probability, conditional probability, and conditional independence. Finally, we introduce the concept of a random variable.</p>"},{"location":"01_Introduction_%2B_Recap_Probability_%2B_Stochastic_Variables/#key-concepts","title":"Key Concepts","text":"<ul> <li>Importance of Statistics and Probability Theory</li> <li>Samples vs. Populations</li> <li>Measures and Scales of Measurement</li> <li>Random Experiments and Probabilities</li> <li>Types of Probability</li> <li>Conditional Probability</li> <li>Conditional Independence</li> <li>Expectation and Variance</li> <li>Independent Random Variables</li> <li>Functions of Random Variables</li> </ul>"},{"location":"01_Introduction_%2B_Recap_Probability_%2B_Stochastic_Variables/#exercises","title":"Exercises","text":"<p>Full solutions to the Exam case exercises (8-10) can be found in the general resource folder</p>"},{"location":"01_Introduction_%2B_Recap_Probability_%2B_Stochastic_Variables/#exercise-1","title":"Exercise 1","text":"<p>Heart failures are due to either natural occurrences (87%) or outside factors (13%). Outside factors are related to induced substances (73%) or foreign objects (27%). Natural occurrences are caused by arterial blockage (56%), disease (27%), and infection (e.g., staph infection) (17%).</p> <ol> <li> <p>Determine the probability that a failure is due to an induced substance.</p> </li> <li> <p>Determine the probability that a failure is due to disease or infection.</p> </li> </ol> Answer <ol> <li> <p>\\(P(\\text{induced substance}) = 0.13 \\times 0.73 = 0.0949\\)</p> </li> <li> <p>\\(P(\\text{disease or infection}) = 0.87\\times (0.27+0.17) = 0.3828\\)</p> </li> </ol>"},{"location":"01_Introduction_%2B_Recap_Probability_%2B_Stochastic_Variables/#exercise-2","title":"Exercise 2","text":"<p>Computer keyboard failures are due to faulty electrical connects (12%) or mechanical defects (88%). Mechanical defects are related to loose keys (27%) or improper assembly (73%). Electrical connect defects are caused by defective wires (35%), improper connections (13%), or poorly welded wires (52%).</p> <ol> <li> <p>Find the probability that a failure is due to loose keys.</p> </li> <li> <p>Find the probability that a failure is due to improperly connected or poorly welded wires.</p> </li> </ol> Answer <ol> <li> <p>\\(P(\\text{loose keys}) = 0.88 \\times 0.27 = 0.2376\\)</p> </li> <li> <p>\\(P(\\text{improperly connected or poorly welded wires}) = 0.12 \\times (0.13 + 0.52) = 0.078\\)</p> </li> </ol>"},{"location":"01_Introduction_%2B_Recap_Probability_%2B_Stochastic_Variables/#exercise-3","title":"Exercise 3","text":"<p>Two teams \\(A\\) and \\(B\\) play a football match, and we are interested in the winner. The sample space can be defined as:  </p> \\[ S = \\{a, b, d\\} \\] <p>where \\(a\\) shows the outcome that \\(A\\) wins, \\(b\\) shows the outcome that \\(B\\) wins, and \\(d\\) shows the outcome that they draw. Suppose that we know that:</p> <ul> <li>The probability that \\(A\\) wins is \\(P(a) = P(\\{a\\}) = 0.5\\).  </li> <li>The probability of a draw is \\(P(d) = P(\\{d\\}) = 0.25\\).</li> </ul> <p>Based on this,</p> <ol> <li> <p>Find the probability that \\(B\\) wins.</p> </li> <li> <p>Find the probability that \\(B\\) wins or a draw occurs.</p> </li> </ol> Answer <ol> <li> <p>\\(P(b) = 1 - P(a) - P(d) = 1 - 0.5 - 0.25 = 0.25\\)</p> </li> <li> <p>\\(P(b \\cup d) = P(b) + P(d) = 0.25 + 0.25 = 0.5\\)</p> </li> </ol>"},{"location":"01_Introduction_%2B_Recap_Probability_%2B_Stochastic_Variables/#exercise-4","title":"Exercise 4","text":"<p>Let \\(A\\) and \\(B\\) be two events such that:  </p> \\[     P(A) = 0.4, \\quad P(B) = 0.7, \\quad P(A \\cup B) = 0.9 \\] <ol> <li> <p>Find \\(P(A \\cap B)\\).</p> </li> <li> <p>Find \\(P(A^c \\cap B)\\).</p> </li> <li> <p>Find \\(P(A - B)\\).</p> </li> <li> <p>Find \\(P(A^c - B)\\).</p> </li> <li> <p>Find \\(P(A^c \\cup B)\\).</p> </li> <li> <p>Find \\(P(A \\cap (B \\cup A^c))\\).</p> </li> </ol> Answer <ol> <li> <p>\\(P(A \\cap B) = P(A) + P(B) - P(A \\cup B) = 0.4 + 0.7 - 0.9 = 0.2\\)</p> </li> <li> <p>\\(P(A^c \\cap B) = P(B) - P(A \\cap B) = 0.7 - 0.2 = 0.5\\)</p> </li> <li> <p>\\(P(A - B) = P(A) - P(A \\cap B) = 0.4 - 0.2 = 0.2\\)</p> </li> <li> <p>\\(P(A^c - B) = 1 - P(A \\cup B) = 1 - 0.9 = 0.1\\)</p> </li> <li> <p>\\(P(A^c \\cup B) = 1 - P(A - B) = 1 - 0.2 = 0.8\\)</p> </li> <li> <p>\\(P(A \\cap (B \\cup A^c)) = P(A \\cap B) = 0.2\\)</p> </li> </ol>"},{"location":"01_Introduction_%2B_Recap_Probability_%2B_Stochastic_Variables/#exercise-5","title":"Exercise 5","text":"<p>Consider a random experiment with a sample space: </p> \\[ S = \\{1, 2, 3, \\cdots\\}. \\] <p>Suppose that we know:  </p> \\[ P(k) = P(\\{k\\}) = \\frac{c}{3^k} \\quad \\textrm{for} \\quad k = 1, 2, \\cdots \\] <p>where \\(c\\) is a constant number.</p> <ol> <li> <p>Find \\(c\\).</p> </li> <li> <p>Find \\(P(\\{2, 4, 6\\})\\).</p> </li> <li> <p>Find \\(P(\\{3, 4, 5, \\cdots\\})\\).</p> </li> </ol> Answer <ol> <li> <p>To find \\(c\\), use the fact that the sum of all probabilities must equal 1:</p> \\[ \\sum_{k=1}^\\infty P(k) = \\sum_{k=1}^\\infty \\frac{c}{3^k} = 1. \\] <p>This is a geometric series with the first term \\(\\frac{c}{3}\\) and ratio \\(\\frac{1}{3}\\):</p> \\[ \\sum_{k=1}^\\infty \\frac{c}{3^k} = \\frac{c}{3} \\cdot \\frac{1}{1 - \\frac{1}{3}} = \\frac{c}{3} \\cdot \\frac{3}{2} = \\frac{c}{2}.$ \\] <p>Therefore, \\(\\frac{c}{2} = 1 \\implies c = 2\\).</p> </li> <li> <p>\\(P(\\{2, 4, 6\\})\\):</p> \\[ P(\\{2, 4, 6\\}) = P(2) + P(4) + P(6) = \\frac{2}{3^2} + \\frac{2}{3^4} + \\frac{2}{3^6}. \\] <p>Compute each term:</p> \\[ P(\\{2, 4, 6\\}) = \\frac{2}{9} + \\frac{2}{81} + \\frac{2}{729} = \\frac{162 + 18 + 2}{729} = \\frac{182}{729} \\approx 0.25. \\] </li> <li> <p>\\(P(\\{3, 4, 5, \\cdots\\})\\):</p> \\[ P(\\{3, 4, 5, \\cdots\\}) = \\sum_{k=3}^\\infty P(k) = \\sum_{k=3}^\\infty \\frac{2}{3^k}. \\] <p>This is a geometric series starting at \\(k=3\\) with the first term \\(\\frac{2}{3^3} = \\frac{2}{27}\\) and ratio \\(\\frac{1}{3}\\):</p> \\[ P(\\{3, 4, 5, \\cdots\\}) = \\frac{\\frac{2}{27}}{1 - \\frac{1}{3}} = \\frac{\\frac{2}{27}}{\\frac{2}{3}} = \\frac{2}{27} \\cdot \\frac{3}{2} = \\frac{1}{9}. \\] </li> </ol>"},{"location":"01_Introduction_%2B_Recap_Probability_%2B_Stochastic_Variables/#exercise-6","title":"Exercise 6","text":"<p>Let \\(T\\) be the time needed (in hours) to complete a job at a certain factory. By using the historical data, we know that:</p> \\[ P(T \\leq t) =  \\begin{cases}  \\frac{1}{16}t^2 &amp; \\text{for } 0 \\leq t \\leq 4, \\\\ 1 &amp; \\text{for } t &gt; 4. \\end{cases} \\] <ol> <li> <p>Find the probability that the job is completed in less than one hour, i.e., find \\(P(T \\leq 1)\\).</p> </li> <li> <p>Find the probability that the job needs more than 2 hours.</p> </li> <li> <p>Find the probability that \\(1 \\leq T \\leq 3\\).</p> </li> </ol> Answer <ol> <li> <p>Using the given formula for \\(P(T \\leq t)\\) when \\(0 \\leq t \\leq 4\\):</p> \\[ P(T \\leq 1) = \\frac{1}{16}(1)^2 = \\frac{1}{16}. \\] </li> <li> <p>Using the complement rule:</p> \\[ P(T &gt; 2) = 1 - P(T \\leq 2). \\] <p>Compute \\(P(T \\leq 2)\\) using the given formula:</p> \\[ P(T \\leq 2) = \\frac{1}{16}(2)^2 = \\frac{4}{16} = \\frac{1}{4}. \\] <p>Therefore:</p> \\[ P(T &gt; 2) = 1 - \\frac{1}{4} = \\frac{3}{4}. \\] </li> <li> <p>Using the subtraction rule:</p> \\[ P(1 \\leq T \\leq 3) = P(T \\leq 3) - P(T \\leq 1). \\] <p>Compute \\(P(T \\leq 3)\\):</p> \\[ P(T \\leq 3) = \\frac{1}{16}(3)^2 = \\frac{9}{16}. \\] <p>Compute \\(P(T \\leq 1)\\) (already found in part (a)):</p> \\[ P(T \\leq 1) = \\frac{1}{16}. \\] <p>Therefore:</p> \\[ P(1 \\leq T \\leq 3) = \\frac{9}{16} - \\frac{1}{16} = \\frac{8}{16} = \\frac{1}{2}. \\] </li> </ol>"},{"location":"01_Introduction_%2B_Recap_Probability_%2B_Stochastic_Variables/#exercise-7","title":"Exercise 7","text":"<p>You choose a point \\((A,B)\\) uniformly at random in the unit square \\(\\{(x,y):0 \\leq x,y \\leq 1\\}\\).</p> <p>What is the probability that the equation</p> \\[ \\begin{align*}     AX^2+X+B=0 \\end{align*} \\] <p>has real solutions?</p> Answer <p>\\(\\frac{1}{4}+\\frac{1}{4} \\ln 4 \\approx 0.5966\\)</p> <p>Also, see more elaborate solution here</p>"},{"location":"01_Introduction_%2B_Recap_Probability_%2B_Stochastic_Variables/#exercise-8-exam-20142-ab","title":"Exercise 8 (Exam 2014.2 (a+b))","text":"<p>An IT company receives its printed circuit boards from two different suppliers, 1 and 2. Records show that 5% of the circuit boards from supplier 1 and 3% of the circuit boards from supplier 2 are defective. 60% of the company\u2019s current circuit boards come from supplier 2, and the remaining from supplier 1. The company usually keeps a stock of 2000 circuit boards. </p> <ol> <li>Based on this information, construct a contingency table of the company\u2019s circuit board stock. Place supplier in the columns and defective/non-defective in the rows.</li> <li>If a randomly chosen circuit board from the company\u2019s stock is chosen and turns out to be defective, what is the probability that the circuit board is from supplier 1?</li> </ol> Answer <ol> <li> <p>The contingency table is as follows:</p> Supplier 1 Supplier 2 Total Defectives 40 36 76 Non-Defectives 760 1164 1924 Total 800 1200 2000 </li> <li> <p>The probability that a circuit board is from supplier 1 given that it is defective is:</p> \\[ P(\\text{Supplier 1} | \\text{Defective}) = \\frac{P(\\text{Supplier 1} \\cap \\text{Defective})}{P(\\text{Defective})} = \\frac{40/2000}{76/2000} = \\frac{40}{76} \\approx 0.5263. \\] </li> </ol>"},{"location":"01_Introduction_%2B_Recap_Probability_%2B_Stochastic_Variables/#exercise-9-exam-20152","title":"Exercise 9 (Exam 2015.2)","text":"<p>A batch of 1000 hard drives from three suppliers were tested. 2% of the hard drives from Toshiba and 2% of the hard drives from Seagate were defective, and in the entire batch there were 3% defectives in total. In the batch, 50% were Western Digital hard drives and 30% were Toshibas.</p> <ol> <li>Based on this information, create a 3 x 2 contingency table of the hard drives.</li> <li>What is the probability that a defective product came from Seagate?</li> <li>What is the probability of randomly selecting a Western Digital hard drive from the entire batch?</li> </ol> Answer <ol> <li> <p>The contingency table is as follows:</p> Supplier Defective Non-Defective Total Toshiba (30%) 6 294 300 Seagate (20%) 4 196 200 Western Digital (50%) 20 480 500 Total 30 970 1000 </li> <li> <p>The probability that a defective product came from Seagate is:</p> \\[ P(\\text{Seagate} | \\text{Defective}) = \\frac{P(\\text{Seagate} \\cap \\text{Defective})}{P(\\text{Defective})} = \\frac{4/1000}{30/1000} = \\frac{4}{30} = \\frac{2}{15} \\approx 0.1333. \\] </li> <li> <p>The probability of randomly selecting a Western Digital hard drive from the entire batch is:</p> \\[ P(\\text{Western Digital}) = \\frac{500}{1000} = 0.5. \\] </li> </ol>"},{"location":"01_Introduction_%2B_Recap_Probability_%2B_Stochastic_Variables/#exercise-10-exam-2016-new-test3","title":"Exercise 10 (Exam 2016 New Test.3)","text":"<p>The probability that a regularly scheduled flight departs on time is 0.83; the probability that it arrives on time is 0.82; and the probability that it departs and arrives on time is 0.78. Find the probability that a plane</p> <ol> <li>Arrives on time, given that it departed on time</li> <li>Departed on time, given that it has arrived on time</li> <li>Arrives on time, given that it did not depart on time</li> </ol> Answer <ol> <li> <p>\\(P(\\text{Arrives on time} | \\text{Departs on time}) = \\frac{P(\\text{Arrives on time} \\cap \\text{Departs on time})}{P(\\text{Departs on time})} = \\frac{0.78}{0.83} \\approx 0.9398\\)</p> </li> <li> <p>\\(P(\\text{Departs on time} | \\text{Arrives on time}) = \\frac{P(\\text{Departs on time} \\cap \\text{Arrives on time})}{P(\\text{Arrives on time})} = \\frac{0.78}{0.82} \\approx 0.9512\\)</p> </li> <li> <p>\\(P(\\text{Arrives on time} | \\text{Did not depart on time}) = \\frac{P(\\text{Arrives on time} \\cap \\text{Did not depart on time})}{P(\\text{Did not depart on time})} = \\frac{0.04}{0.17} \\approx 0.2353\\)</p> </li> </ol>"},{"location":"02_Discrete_Random_Variables/","title":"02 Discrete Random Variables","text":"Discrete Random Variables"},{"location":"02_Discrete_Random_Variables/#session-preparation","title":"Session Preparation:","text":"<p>ASPE: 3</p> <p>Solve the exercises from session 1 before class.</p>"},{"location":"02_Discrete_Random_Variables/#session-material","title":"Session Material","text":"<p>Recap and Exercises - notes</p> <p>Session notes</p> <p>Session material</p> <p>Session from 20/21:</p>"},{"location":"02_Discrete_Random_Variables/#session-description","title":"Session Description","text":"<p>In this session, we look at a variety of discrete probability distributions, laying the foundation for analysing and modelling random processes. We begin with the Bernoulli distribution, which describes experiments with two possible outcomes, and extend this to the Binomial and Geometric distributions. Building on these, we we move on to the Negative Binomial (Pascal) distribution and the Hypergeometric distribution, highlighting their applications in scenarios where sampling without replacement plays a role. </p> <p>The Poisson distribution, a model for counting events over time or space, is introduced, along with its use as an approximation for the Binomial distribution under specific conditions. Finally, we discuss key properties of these distributions, including their probability mass function (PMF) and cumulative distribution functions (CDFs), expectations, and variances.</p>"},{"location":"02_Discrete_Random_Variables/#key-concepts","title":"Key Concepts","text":"<ul> <li>Bernoulli Distribution</li> <li>Geometric Distribution</li> <li>Binomial Distribution</li> <li>Negative Binomial (Pascal) Distribution</li> <li>Hypergeometric Distribution</li> <li>Poisson Distribution</li> <li>Poisson as an Approximation for Binomial</li> <li>Probability Mass Function (PMF)</li> <li>Cumulative Distribution Function (CDF)</li> <li>Expectation and Variance</li> </ul>"},{"location":"02_Discrete_Random_Variables/#exercises","title":"Exercises","text":"<p>Full solutions to the exercises can be found in Session material.</p> <p>Note, sometimes we use '\\(=\\)' instead of '\\(\\approx\\)' when we state probabilities with a given decimal precision.</p>"},{"location":"02_Discrete_Random_Variables/#exercise-1","title":"Exercise 1","text":"<p>A computer system uses passwords that are exactly six characters and each character is one of the 26 letters (a-\u2013z) or 10 integers (0-\u20139). Suppose that 10,000 users of the system have unique passwords. A hacker randomly selects (with replacement) 100,000 passwords from the potential set, and a match to a user\u2019s password is called a hit.</p> <ol> <li>What is the distribution of the number of hits?</li> <li>What is the probability of no hits?</li> <li>What are the mean and variance of the number of hits?</li> </ol> Answer <ol> <li>The distribution of the number of hits is Binomial with \\(n = 10^5\\) and \\(p=\\frac{10^5}{36^6}\\)</li> <li>\\(P(X=0) = 0.6317\\)</li> <li>\\(\\mu = \\sigma^2 = 0.4594\\)</li> </ol>"},{"location":"02_Discrete_Random_Variables/#exercise-2","title":"Exercise 2","text":"<p>Because all airline passengers do not show up for their reserved seat, an airline sells 125 tickets for a flight that holds only 120 passengers. The probability that a passenger does not show up is 0.10, and the passengers behave independently.</p> <ol> <li>What is the probability that every passenger who shows up can take the flight?</li> <li>What is the probability that the flight departs with empty seats?</li> </ol> Answer <ol> <li>\\(p = 0.9961 \\)</li> <li>\\(p = 0.9886\\)</li> </ol>"},{"location":"02_Discrete_Random_Variables/#exercise-3","title":"Exercise 3","text":"<p>A player of a video game is confronted with a series of opponents and has an 80\\% probability of defeating each one. Success with any opponent is independent of previous encounters. Until defeated, the player continues to contest opponents.</p> <ol> <li>What is the probability mass function of the number of opponents contested in a game?</li> <li>What is the probability that a player defeats at least two opponents in a game?</li> <li>What is the expected number of opponents contested in a game?</li> <li>What is the probability that a player contests four or more opponents in a game?</li> <li>What is the expected number of game plays until a player contests four or more opponents?</li> </ol> Answer <ol> <li>\\(P(X=k) = 0.8^{k-1} \\cdot 0.2\\)</li> <li>\\(p = 0.64\\)</li> <li>\\(E[X] = 5\\)</li> <li>\\(p = 0.512\\)</li> <li>\\(E[Y] \\approx 1.9531\\)</li> </ol>"},{"location":"02_Discrete_Random_Variables/#exercise-4","title":"Exercise 4","text":"<p>Astronomers treat the number of stars in a given volume of space as a Poisson random variable. The density in the Milky Way Galaxy in the vicinity of our solar system is one star per 16 cubic light-years.</p> <ol> <li>What is the probability of no stars in 16 cubic light-years?</li> <li>What is the probability of two or more stars in 16 cubic light-years?</li> <li>How many cubic light-years of space must be studied so that the probability of one or more stars exceeds 0.95?</li> </ol> Answer <ol> <li>\\(P(X=0)=e^{-1} \\approx 0.3679\\)</li> <li>\\(P(X \\geq 2) \\approx 0.2642\\)</li> <li>At least 48 cubic light-years of space must be studied.</li> </ol>"},{"location":"02_Discrete_Random_Variables/#exercise-5","title":"Exercise 5","text":"<p>A congested computer network has a 1% chance of losing a data packet that must be resent, and packet losses are independent events. An e-mail message requires 100 packets.</p> <ol> <li>What is the distribution of the number of packets in an e-mail message that must be resent? Include the parameter values.</li> <li>What is the probability that at least one packet is resent?</li> <li>What is the probability that two or more packets are resent?</li> <li>What are the mean and standard deviation of the number of packets that are resent?</li> <li>If there are 10 messages and each contains 100 packets, what is the probability that at least one message requires that two or more packets be resent?</li> </ol> Answer <ol> <li>\\(X \\sim \\operatorname{Binomial}(n=100, p=0.01)\\)</li> <li>\\(P(X \\geq 1)=0.634\\)</li> <li>\\(P(X \\geq 2)=0.2642\\)</li> <li>\\(\\mu = 1, \\sigma = 0.995\\)</li> <li>\\(P(Y \\geq 1)=0.9535\\)</li> </ol>"},{"location":"02_Discrete_Random_Variables/#exercise-6","title":"Exercise 6","text":"<p>A manufacturer of a consumer electronics product expects 2% of units to fail during the warranty period. A sample of 500 independent units is tracked for warranty performance.</p> <ol> <li>What is the probability that none fails during the warranty period?</li> <li>What is the expected number of failures during the warranty period?</li> <li>What is the probability that more than two units fail during the warranty period?</li> </ol> Answer <ol> <li>\\(P(X=0) \\approx 0.0000\\)</li> <li>\\(E[X] = 10\\)</li> <li>\\(P(X &gt; 2) \\approx 0.9974\\)</li> </ol>"},{"location":"02_Discrete_Random_Variables/#exercise-7","title":"Exercise 7","text":"<p>The probability that a patient recovers from a rare blood disease is 0.4. If 15 people are known to have contracted this disease, what is the probability that:</p> <ol> <li> <p>At least 10 survive</p> </li> <li> <p>From 3 to 8 survive</p> </li> <li> <p>Exactly 5 survive</p> </li> <li> <p>Find the mean and variance.</p> </li> </ol> Answer <ol> <li>\\(P(X \\geq 10) \\approx 0.0338\\)</li> <li>\\(P(3 \\leq X \\leq 8) \\approx 0.8778\\)</li> <li>\\(P(X=5) \\approx 0.1859\\)</li> <li>\\(\\mu = 6, \\sigma^2 = 3.6\\)</li> </ol>"},{"location":"02_Discrete_Random_Variables/#exercise-8","title":"Exercise 8","text":"<p>A large chain retailer purchases a certain kind of electronic device from a manufacturer. The manufacturer indicates that the defective rate of the device is 3%.</p> <ol> <li> <p>The inspector of the retailer randomly picks 20 items from a shipment. What is the probability that there will be at least one defective item among them?</p> </li> <li> <p>Suppose that the retailer receives 10 shipments in a month and the inspector randomly tests 20 devices per shipment. What is the probability that there will be 3 shipments containing at least one defective device?</p> </li> </ol> Answer <ol> <li>\\(P(X \\geq 1) \\approx 0.4562\\)</li> <li>\\(P(Y=3) \\approx 0.1602\\)</li> </ol>"},{"location":"02_Discrete_Random_Variables/#exercise-9","title":"Exercise 9","text":"<p>High flows result in the closure of a causeway. From past records, the road is closed for this reason on 10 days during a 20-year period. At an adjoining village, there is concern about the closure of the causeway because it provides the only access. The villagers assume that the probability of a closure of the road for more than one day during a year is less than 0.10. Is this correct? Please show using the Poisson distribution.</p> Answer <p>The probability of a closure of the road for more than one day during a year is 0.0902.</p>"},{"location":"02_Discrete_Random_Variables/#exercise-10","title":"Exercise 10","text":"<p>A company performs inspection on shipments from suppliers in order to detect nonconforming products. Assume a lot contains 1000 items and 1% is nonconforming. Assuming that the number of nonconforming products in the sample is binomial, what sample size is needed so that the probability of choosing at least one nonconforming item in the sample is at least 0.9?</p> Answer <p>A sample size of at least 230 is needed.</p>"},{"location":"02_Discrete_Random_Variables/#exercise-11","title":"Exercise 11","text":"<p>The number of errors in a textbook follows a Poisson distribution with a mean of 0.01 error per page. What is the probability that there are three or less errors in 100 pages?</p> Answer <p>\\(P(X \\leq 3) \\approx 0.981\\)</p>"},{"location":"02_Discrete_Random_Variables/#additional-exercises","title":"Additional Exercises","text":"<pre><code>while student is \"bored\":\n    additional_exercises = [\n        \"Exam 2014.3 (a-c)\",\n        \"Exam 2016 New Test.2\",\n        \"Exam 2018.2\"\n    ]\n</code></pre>"},{"location":"03_Continuous_Random_Variables/","title":"03 Continuous Random Variables","text":"Continuous Random Variables"},{"location":"03_Continuous_Random_Variables/#session-preparation","title":"Session Preparation:","text":"<p>ASPE: 4 (not 4.8-4.11)</p> <p>Solve the exercises from session 2 before class.</p> <p>Today you will need to brush up on your basic calculus skills as this will not be recapped in depth. It seems that Khan Academy has some nice tutorials on integrals that you may want to check out:</p> <ul> <li>Tutorial 1</li> <li>Tutorial 2</li> <li>Tutorial 3</li> </ul>"},{"location":"03_Continuous_Random_Variables/#session-material","title":"Session Material","text":"<p>Recap notes</p> <p>Session notes Part 1</p> <p>Session notes Part 2</p> <p>Session material</p> <p>Session from 20/21:</p>"},{"location":"03_Continuous_Random_Variables/#session-description","title":"Session Description","text":"<p>Continuous random variables are a type of random variable that can take on an infinite number of values within a given range. The most important elements of continuous random variables are the probability density function, the cumulative distribution function, and the expected value. The probability density function provides the probability that a continuous random variable will take on a value within a given range, while the cumulative distribution function gives the probability that the variable will take on a value less than or equal to a given value. The expected value, or mean, of a continuous random variable is calculated by integrating the product of the variable and its probability density function over the entire range of possible values.</p> <p>It is also important that you think about the relationship between the discrete case and the continuous case, and how this transfers to the relationship between sums and integrals.</p>"},{"location":"03_Continuous_Random_Variables/#key-concepts","title":"Key Concepts","text":"<ul> <li>Derivatives, integrals, antiderivatives</li> <li>General properties of continuous random variables</li> <li>The uniform distribution</li> <li>The probability density function</li> <li>The cumulative distribution function</li> <li>The normal distribution</li> <li>The exponential distribution</li> </ul>"},{"location":"03_Continuous_Random_Variables/#exercises","title":"Exercises","text":"<p>Full solutions to the exercises can be found in the general resource folder</p>"},{"location":"03_Continuous_Random_Variables/#exercise-1-exam-20141","title":"Exercise 1 (Exam 2014.1)","text":"<p>Let \\(X\\) denote a continuous stochastic variable with the following probability density function:</p> <p>[ f(x) = \\begin{cases} c x^4 &amp; \\text{for } -1 \\leq x \\leq 1, \\ 0 &amp; \\text{otherwise,} \\end{cases} ] where \\(c\\) is a constant.</p> <ol> <li> <p>Show that the cumulative probability function of \\(X\\) is:</p> \\[ F(x) = \\begin{cases} 0 &amp; \\text{for } x &lt; -1, \\\\ \\frac{1}{5} c\\left(x^5 + 1\\right) &amp; \\text{for } -1 \\leq x \\leq 1, \\\\ 1 &amp; \\text{for } x &gt; 1. \\end{cases} \\] </li> <li> <p>Determine the constant \\(c\\) and restate both the probability density function and the cumulative probability function using the actual value of \\(c\\).</p> </li> <li> <p>Compute \\(P\\left(-\\frac{1}{2} &lt; X &lt; \\frac{1}{2}\\right)\\) and \\(P(X &gt; 0)\\).</p> </li> <li> <p>Find the expected value and variance of \\(X\\).</p> </li> </ol> Answer <ol> <li>Can be shown either by integrating the probability density function or by differentiating the cumulative probability function.</li> <li>\\(c = \\frac{5}{3}\\)</li> <li>\\(P\\left(-\\frac{1}{2} &lt; X &lt; \\frac{1}{2}\\right) = \\frac{1}{32} = 0.0315\\) and \\(P(X &gt; 0) = \\frac{1}{2} = 0.5\\)</li> <li>\\(E[X] = 0\\) and \\(VAR(X) = \\frac{5}{7}\\)</li> </ol>"},{"location":"03_Continuous_Random_Variables/#exercise-2-exam-20143-de","title":"Exercise 2 (Exam 2014.3 (d+e))","text":"<p>A central database server receives, on the average, 25 requests per second from its clients. Assuming that requests received by a database follow a Poisson distribution</p> <ol> <li>What is the probability that the server will receive no requests in a 10-millisecond interval?</li> <li>What is the probability that the server will receive more than 2 requests in a 10-millisecond interval?</li> <li>What is the probability that the server will receive between 2 and 4 (both included) requests in a 20-millisecond interval?</li> </ol> <p>Let T be the time in seconds between requests.</p> <ol> <li>What is the probability that less than or equal to 10 milliseconds will elapse between job requests?</li> <li>What is the probability that more than 100 milliseconds will elapse between requests?</li> </ol> Answer <ol> <li>\\(P(X=0) = 0.7788\\)</li> <li>\\(P(X&gt;2) = 0.0022\\)</li> <li>\\(P(2 \\leq X \\leq 4) = 0.09\\)</li> <li>\\(P(T \\leq 0.01) = 0.2212\\)</li> <li>\\(P(T &gt; 0.1) = 0.0821\\)</li> </ol>"},{"location":"03_Continuous_Random_Variables/#exercise-3-exam-20181","title":"Exercise 3 (Exam 2018.1)","text":"<p>Let \\(X\\) denote a continuous stochastic variable with the following density function</p> \\[ f(x)= \\begin{cases}c\\left(1-x^2\\right) &amp; \\text { for }-1&lt;x&lt;1 \\\\ 0 &amp; \\text { otherwise }\\end{cases} \\] <ol> <li>Determine the value of \\(c\\) and state the cumulative distribution function of \\(X\\).</li> <li>Determine \\(P\\left(X \\leq \\frac{1}{2}\\right)\\) and \\(P\\left(X \\leq-\\frac{1}{4}\\right)\\)</li> <li>Determine the expected value and the variance of \\(X\\).</li> </ol> Answer <p>a. \\(c = \\frac{3}{4}\\) and \\(F(x) = \\begin{cases}0 &amp; \\text { for } x&lt;-1 \\\\ \\frac{3}{4}\\left(x-\\frac{x^3}{3}\\right) + \\frac{1}{2} &amp; \\text { for }-1 \\leq x \\leq 1 \\\\ 1 &amp; \\text { for } x&gt;1\\end{cases}\\)</p> <p>b. \\(P\\left(X \\leq \\frac{1}{2}\\right) = 0.8438\\) and \\(P\\left(X \\leq-\\frac{1}{4}\\right) = 0.3164\\)</p> <p>c. \\(E[X] = 0\\) and \\(VAR(X) = 0.2\\)</p>"},{"location":"03_Continuous_Random_Variables/#exercise-4-re-exam-20181","title":"Exercise 4 (Re-exam 2018.1)","text":"<p>Compute the expected value, \\(E(X)\\), if \\(X\\) has a density function as follows:</p> <ol> <li>\\(f(x)= \\begin{cases}\\frac{1}{4} x e^{-\\frac{x}{2}} &amp; x&gt;0 \\\\ 0 &amp; \\text { otherwise }\\end{cases}\\)</li> <li> <p>\\(f(x)= \\begin{cases}5 x^{-2} &amp; x&gt;5 \\\\ 0 &amp; \\text { otherwise }\\end{cases}\\)</p> <p>The density function of \\(X\\) is given by</p> \\[ f(x)= \\begin{cases}a+b x^2 &amp; 0 \\leq x \\leq 1 \\\\ 0 &amp; \\text { otherwise }\\end{cases} \\] </li> <li> <p>If \\(E(X)=\\frac{3}{5}\\), find \\(a\\) and \\(b\\).</p> </li> </ol> Answer <ol> <li>\\(E(X) = 4\\)</li> <li>\\(E(X) = \\infty \\)</li> <li>\\(a = \\frac{3}{5}\\) and \\(b = \\frac{6}{5}\\)</li> </ol>"},{"location":"03_Continuous_Random_Variables/#exercise-5-exam-20201","title":"Exercise 5 (Exam 2020.1)","text":"<p>The length of time \\(X\\) (in hours), needed by students in the SMP course to complete the three-hour exam is a continuous random variable with the following density function:</p> \\[ f(x) = \\begin{cases} q\\left(x^2 + x\\right) &amp; \\text{if } 0 \\leq x \\leq 3, \\\\ 0 &amp; \\text{else}. \\end{cases} \\] <ol> <li> <p>Find the value of \\(q\\) that makes \\(f(x)\\) a probability density function.</p> </li> <li> <p>Find the cumulative distribution function.</p> </li> <li> <p>Find the probability that a student will complete the exam in:</p> <ul> <li>(i) Less than an hour.</li> <li>(ii) Between one and two hours.</li> <li>(iii) More than two hours.</li> <li>(iv) During the final ten minutes of the exam.</li> </ul> </li> <li> <p>Find the mean time needed to complete the three-hour SMP exam.</p> </li> <li> <p>Find the variance and standard deviation of \\(X\\).</p> </li> </ol> Answer <ol> <li>\\(q = \\frac{2}{27} \\approx 0.0741\\)</li> <li>\\(F(x) = \\begin{cases}0 &amp; \\text{if } x &lt; 0, \\\\ \\frac{2 x^3}{81}+\\frac{x^2}{27} &amp; \\text{if } 0 \\leq x \\leq 3, \\\\ 1 &amp; \\text{if } x &gt; 3.\\end{cases}\\)</li> <li>(i) \\(P(X&lt;1)=5 / 81=0.0617\\), (ii) \\(P(1&lt;X&lt;2)=23 / 81=0.284\\), (iii) \\(P(X&gt;2)=53 / 81=0.6543\\), (iv) \\(P(X&gt;17 / 6)=0.1411\\)</li> <li>\\(E[X] = 13/6 =2.1667 \\text { hours } \\)</li> <li>\\(\\operatorname{Var}(X)=0.4056\\) hours \\(^2\\) and \\(\\mathrm{SD}(X)=0.6368\\) hours</li> </ol>"},{"location":"04_Multivariate_Random_Variables/","title":"04 Multivariate Random Variables","text":"Multivariate Random Variables"},{"location":"04_Multivariate_Random_Variables/#session-preparation","title":"Session Preparation:","text":"<p>ASPE: 5 (not 5.5-5.8)</p> <p>Solve the exercises from session 3 before class.</p>"},{"location":"04_Multivariate_Random_Variables/#session-material","title":"Session Material","text":"<p>Recap Notes</p> <p>CRVs Part 2 Notes</p> <p>Session notes</p> <p>Session material</p> <p>Session from 20/21:</p>"},{"location":"04_Multivariate_Random_Variables/#session-description","title":"Session Description","text":"<p>This is arguably the most difficult of all the topics.</p> <p>Multivariate random variables are a collection of random variables that are correlated with each other. The most important elements of multivariate random variables include their mean vector, covariance matrix, and joint probability density function. The mean vector represents the average value of each variable, while the covariance matrix reflects the degree of correlation and variability among the variables. The joint probability density function specifies the probability of obtaining a particular combination of values for the variables. Understanding the key elements of multivariate random variables is crucial for performing statistical analyses, making predictions, and making decisions based on data.</p>"},{"location":"04_Multivariate_Random_Variables/#key-concepts","title":"Key Concepts","text":"<ul> <li>Joint Probability Distributions</li> <li>Conditional Probability Distributions</li> <li>Conditional Expectation</li> <li>Covariance and Correlation</li> </ul>"},{"location":"04_Multivariate_Random_Variables/#exercises","title":"Exercises","text":"<p>Full solutions to the exercises can be found in Session material.</p>"},{"location":"04_Multivariate_Random_Variables/#exercise-1","title":"Exercise 1","text":"<p>Let the simultaneous probability mass function (also called simultaneous probability density function or pdf) for the two discrete random variables \\(X\\) and \\(Y\\) be given by the table:</p> \\(y \\backslash x\\) 1 2 3 5 \\(\\frac{1}{12}\\) 0 0 6 \\(\\frac{2}{12}\\) 0 \\(\\frac{2}{12}\\) 7 \\(\\frac{2}{12}\\) \\(\\frac{1}{12}\\) \\(\\frac{2}{12}\\) 8 0 \\(\\frac{2}{12}\\) 0 <ol> <li> <p>Find the marginal PMFs of \\(X\\) and \\(Y\\).</p> </li> <li> <p>Find \\(E[X]\\), \\(E[Y]\\), and \\(E[XY]\\).</p> </li> <li> <p>Specify whether \\(X\\) and \\(Y\\) are independent.</p> </li> <li> <p>Find \\(f_{X \\mid Y}(x \\mid y=6)\\).</p> </li> </ol> Answer <ol> <li> <p>The marginal PMFs of \\(X\\) and \\(Y\\) are:</p> \\[ f_X(x) =  \\begin{cases} \\frac{5}{12} &amp; \\text{for } x=1, \\\\ \\frac{1}{4} &amp; \\text{for } x=2, \\\\ \\frac{1}{3} &amp; \\text{for } x=3, \\\\ 0 &amp; \\text{otherwise,} \\end{cases} \\] \\[ f_Y(y) =  \\begin{cases} \\frac{5}{12} &amp; \\text{for } y=5, \\\\ \\frac{4}{12} &amp; \\text{for } y=6, \\\\ \\frac{5}{12} &amp; \\text{for } y=7, \\\\ \\frac{2}{12} &amp; \\text{for } y=8, \\\\ 0 &amp; \\text{otherwise.} \\end{cases} \\] </li> <li> <p>\\(\\mathrm{EX}=1.92, \\mathrm{EY}=6.67, \\mathrm{E}[\\mathrm{XY}]=12.92\\)</p> </li> <li> <p>Not</p> </li> <li> <p>\\(f_{X \\mid Y}(1 \\mid 6)=0.5, \\quad f_{X \\mid Y}(2 \\mid 6)=0, \\quad f_{X \\mid Y}(3 \\mid 6)=0.5\\)</p> </li> </ol>"},{"location":"04_Multivariate_Random_Variables/#exercise-2","title":"Exercise 2","text":"<p>Let the simultaneous probability mass function (also called simultaneous probability density function or pdf) for the two discrete random variables \\(X\\) and \\(Y\\) be given by the table:</p> \\(y \\backslash x\\) 4 5 7 -3 \\(k\\) 0 0 -1 \\(\\frac{2}{10}\\) 0 \\(k\\) 0 \\(\\frac{1}{10}\\) 0 \\(\\frac{4}{10}\\) 5 0 \\(k\\) 0 <ol> <li> <p>What is the value of \\(k\\)?</p> </li> <li> <p>What are the marginal PMFs?</p> </li> <li> <p>Find:</p> <p>\\(E[X] =\\)</p> <p>\\(E[Y] =\\)</p> <p>\\(E[Y \\cdot X] =\\)</p> <p>\\(E[X^2] =\\)</p> <p>\\(E[Y^2] =\\)</p> <p>\\(P(Y &lt; 0) =\\)</p> <p>\\(P(X = 5, Y &gt; 0) =\\)</p> <p>\\(P(X &lt; 6, Y &lt; 0) =\\)</p> <p>\\(\\text{Var}(X) =\\)</p> </li> </ol> Answer <ol> <li> <p>\\(k = \\frac{1}{10}\\)</p> </li> <li> <p>The marginal PMFs are:</p> \\[ \\begin{aligned} &amp; f_X(x)= \\begin{cases}\\frac{4}{5} &amp; x=4 \\\\ \\frac{1}{10} &amp; x=5 \\\\ \\frac{1}{2} &amp; x=7\\end{cases} \\\\ &amp; f_Y(y)= \\begin{cases}\\frac{1}{10} &amp; y=-3 \\\\ \\frac{3}{10} &amp; y=-1 \\\\ \\frac{1}{2} &amp; y=0 \\\\ \\frac{1}{10} &amp; y=5\\end{cases} \\end{aligned} \\] </li> <li> <p>Find:</p> <p>\\(E[X] =5.6\\)</p> <p>\\(E[Y] =-0.1\\)</p> <p>\\(E[Y \\cdot X] =-0.2\\)</p> <p>\\(E[X^2] =33.4\\)</p> <p>\\(E[Y^2] =3.7\\)</p> <p>\\(P(Y &lt; 0) =0.4\\)</p> <p>\\(P(X = 5, Y &gt; 0) =0.1\\)</p> <p>\\(P(X &lt; 6, Y &lt; 0) =0.3\\)</p> <p>\\(\\text{Var}(X) =2.04\\)</p> </li> </ol>"},{"location":"04_Multivariate_Random_Variables/#exercise-3","title":"Exercise 3","text":"<p>Consider the following PDF:</p> \\[ f_{Y \\mid X}(y) = x \\cdot e^{-xy} \\qquad \\text{for } y &gt; 0 \\] <ol> <li> <p>Find \\(P(Y &lt; 2 \\mid X = 2)\\)</p> </li> <li> <p>Find \\(E(Y \\mid X = 2)\\)</p> </li> </ol> Answer <ol> <li> <p>\\(P(Y &lt; 2 \\mid X = 2) = 1 - e^{-4} \\approx 0.98\\)</p> </li> <li> <p>\\(E(Y \\mid X = 2) = \\frac{1}{2}\\)</p> </li> </ol>"},{"location":"04_Multivariate_Random_Variables/#exercise-4","title":"Exercise 4","text":"<p>Consider two random variables \\(X\\) and \\(Y\\) with joint PMF given by:</p> \\[ P_{X Y}(k, l) = \\frac{1}{2^{k+l}}, \\quad \\text{for } k, l = 1, 2, 3, \\ldots \\] <p>Find \\(P\\left(X^2 + Y^2 \\leq 10\\right)\\).</p> Answer <p>\\(P\\left(X^2 + Y^2 \\leq 10\\right) = \\frac{11}{16}\\)</p>"},{"location":"04_Multivariate_Random_Variables/#exercise-5","title":"Exercise 5","text":"<p>Let \\(X\\) and \\(Y\\) be two jointly continuous random variables with joint PDF:</p> \\[ f_{XY}(x, y) = \\begin{cases} \\frac{1}{2} e^{-x} + \\frac{cy}{(1+x)^2}, &amp; 0 \\leq x, \\quad 0 \\leq y \\leq 1, \\\\ 0, &amp; \\text{otherwise}. \\end{cases} \\] <ol> <li> <p>Find the constant \\(c\\).</p> </li> <li> <p>Find \\(P(0 \\leq X \\leq 1, 0 \\leq Y \\leq \\frac{1}{2})\\).</p> </li> <li> <p>Find \\(P(0 \\leq X \\leq 1)\\).</p> </li> </ol> Answer <ol> <li> <p>\\(c = 1\\)</p> </li> <li> <p>\\(P(0 \\leq X \\leq 1, 0 \\leq Y \\leq \\frac{1}{2}) = \\frac{5}{16}-\\frac{1}{4 e}\\)</p> </li> <li> <p>\\(P(0 \\leq X \\leq 1) = \\frac{3}{4}-\\frac{1}{2 e}\\)</p> </li> </ol>"},{"location":"04_Multivariate_Random_Variables/#exercise-6","title":"Exercise 6","text":"<p>Let \\(X\\) and \\(Y\\) be two jointly continuous random variables with joint PDF:</p> \\[ f_{XY}(x, y) = \\begin{cases} e^{-xy}, &amp; 1 \\leq x \\leq e, \\quad y &gt; 0, \\\\ 0, &amp; \\text{otherwise}. \\end{cases} \\] <ol> <li> <p>Find the marginal PDFs, \\(f_X(x)\\) and \\(f_Y(y)\\).</p> </li> <li> <p>Write an integral to compute \\(P(0 \\leq Y \\leq 1, 1 \\leq X \\leq \\sqrt{e})\\).</p> </li> </ol> Answer <ol> <li> <p>The marginal PDFs are:</p> \\[ \\begin{aligned} &amp; f_X(x)= \\begin{cases}\\frac{1}{x} &amp; 1 \\leq x \\leq e \\\\ 0 &amp; \\text { otherwise }\\end{cases} \\\\ &amp; f_Y(y)= \\begin{cases}\\frac{1}{y}\\left(e^{-y}-e^{-e y}\\right) &amp; y&gt;0 \\\\ 0 &amp; \\text { otherwise }\\end{cases} \\end{aligned} \\] </li> <li> \\[P(0 \\leq Y \\leq 1,1 \\leq X \\leq \\sqrt{e})=\\int_1^{\\sqrt{e}} \\frac{1}{x}-\\frac{1}{x} e^{-x} d x\\] </li> </ol>"},{"location":"04_Multivariate_Random_Variables/#exercise-7","title":"Exercise 7","text":"<p>Let \\(X\\) and \\(Y\\) be two jointly continuous random variables with joint PDF:</p> \\[ f_{XY}(x, y) = \\begin{cases} \\frac{1}{4}x^2 + \\frac{1}{6}y, &amp; -1 \\leq x \\leq 1, \\quad 0 \\leq y \\leq 2, \\\\ 0, &amp; \\text{otherwise}. \\end{cases} \\] <ol> <li> <p>Find the marginal PDFs, \\(f_X(x)\\) and \\(f_Y(y)\\).</p> </li> <li> <p>Find \\(P(X &gt; 0, Y &lt; 1)\\).</p> </li> <li> <p>Find \\(P(X &gt; 0 \\text{ or } Y &lt; 1)\\).</p> </li> <li> <p>Find \\(P(X &gt; 0 \\mid Y &lt; 1)\\).</p> </li> <li> <p>Find \\(P(X + Y &gt; 0)\\).</p> </li> </ol> Answer <ol> <li> <p>The marginal PDFs, \\(f_X(x)\\) and \\(f_Y(y)\\).</p> \\[ \\begin{aligned} &amp; f_X(x)=\\left\\{\\begin{array}{lc} \\frac{1}{2} x^2+\\frac{1}{3} &amp; -1 \\leq x \\leq 1 \\\\ 0 &amp; \\text { otherwise } \\end{array}\\right. \\\\ &amp; f_Y(y)= \\begin{cases}\\frac{1}{6}+\\frac{1}{3} y &amp; 0 \\leq y \\leq 2 \\\\ 0 &amp; \\text { otherwise }\\end{cases} \\end{aligned} \\] </li> <li> <p>\\(P(X &gt; 0, Y &lt; 1)\\) = \u2159.</p> </li> <li>\\(P(X &gt; 0 \\text{ or } Y &lt; 1)=2/3\\).</li> <li>\\(P(X &gt; 0 \\mid Y &lt; 1)=1/2\\).</li> <li>\\(P(X + Y &gt; 0)=131/144\\).</li> </ol>"},{"location":"05_Point_Estimation_and_sampling/","title":"05 Point Estimation and Sampling","text":"05 Point Estimation and Sampling"},{"location":"05_Point_Estimation_and_sampling/#material","title":"Material:","text":"<p>ASPE: 7 (not 7.3.4 and 7.4.3)</p> <p>Recap Exercises</p> <p>Session material</p> <p>Session from 20/21: SMP 5</p>"},{"location":"05_Point_Estimation_and_sampling/#topics","title":"Topics","text":"<p>You will most likely experience that the next 2-3 topics are a bit less complex than the previous three topics.</p> <p>Point estimation and sampling are important concepts in statistics. Point estimation involves using a statistic, such as the sample mean or proportion, to estimate an unknown population parameter. The goal is to find the value of the statistic that is most likely to be the true value of the parameter. Sampling, on the other hand, involves selecting a subset of individuals from a larger population and using their data to make inferences about the entire population. The key to effective sampling is ensuring that the sample is representative of the population and that the sample size is large enough to accurately estimate the population parameter of interest. Together, point estimation and sampling provide a framework for making accurate and reliable statistical inferences.</p> <ul> <li>Correlation and Covariance (from last week\u2019s topic)</li> <li>Sampling Distribution</li> <li>Central Limit Theorem</li> <li>Standard Error</li> <li>Mean Squared Error</li> <li>Maximum Likelihood Estimator</li> </ul>"},{"location":"05_Point_Estimation_and_sampling/#problems-to-be-worked-on-inafter-class","title":"Problems to be worked on in/after class:","text":"<ul> <li>ASPE: 7.2.8 + 7.2.10 + 7.3.3 + 7.3.9 + 7.4.4. (not b) + 7S13</li> <li>Also do Problems 5.</li> </ul>"},{"location":"06_Statistical_Intervals/","title":"06 Statistical Intervals","text":"06 Statistical Intervals"},{"location":"06_Statistical_Intervals/#material","title":"Material:","text":"<p>ASPE: 8 (not 8.6)</p> <p>Recap notes</p> <p>Session Notes</p> <p>Session material</p> <p>Session from 20/21: SMP 6</p>"},{"location":"06_Statistical_Intervals/#topics","title":"Topics","text":"<p>Statistical intervals are a way of expressing the uncertainty associated with a statistical estimate. They provide a range of values within which the true value of a population parameter or a future observation is likely to fall, based on a sample of data. Confidence intervals estimate the value of a population parameter with a measure of uncertainty, while prediction intervals provide a range of values for a future observation, taking into account both the uncertainty associated with estimating the population parameter and the variability associated with predicting individual observations. Statistical intervals are commonly used in various fields to estimate population parameters or future outcomes with a measure of precision and reliability.</p> <ul> <li>CI for mean</li> <li>CI for proportion</li> <li>CI for variance</li> <li>Tolerance and prediction interval</li> </ul>"},{"location":"06_Statistical_Intervals/#problems-to-be-worked-on-inafter-class","title":"Problems to be worked on in/after class:","text":"<p>Do Problems 6.</p>"},{"location":"07_Hypothesis_Testing/","title":"07 Hypothesis Testing","text":"07 Hypothesis Testing"},{"location":"07_Hypothesis_Testing/#material","title":"Material:","text":"<p>ASPE: 9.1-9.3 + 9.5 + 9.8 + 10.1-10.4 + 10.6</p> <p>Notes recap</p> <p>Session notes</p> <p>Session material</p> <p>Session from 20/21: SMP 7</p>"},{"location":"07_Hypothesis_Testing/#topics","title":"Topics","text":"<p>Hypothesis testing is a statistical method used to evaluate whether a certain hypothesis about a population parameter is supported by the data. The key elements of hypothesis testing include the formulation of a null hypothesis and an alternative hypothesis, the selection of an appropriate test statistic, the determination of a significance level or alpha value, the calculation of a p-value, and the comparison of the p-value to the significance level to decide whether to reject or fail to reject the null hypothesis. The significance level is a pre-determined threshold that represents the maximum probability of observing the data if the null hypothesis is true, and the p-value is the probability of observing the data, or more extreme data, if the null hypothesis is true. Hypothesis testing is widely used in many fields to make inferences about population parameters based on sample data, and it is an essential tool for scientific research and decision-making.</p> <ul> <li>Basics of hypothesis testing</li> <li>Type I and II errors</li> <li>P-values and critical values and test statistic</li> <li>Tests on mean and proportion</li> <li>One and two tailed tests</li> <li>Paired t-test</li> <li>Contingency table tests (next time in recap)</li> </ul>"},{"location":"07_Hypothesis_Testing/#problems-to-be-worked-on-inafter-class","title":"Problems to be worked on in/after class:","text":"<ul> <li>ASPE: 9.3.8 + 9.3.9 + 9.5.3 + 9.5.4</li> <li>Exam 2014.2.c; 2015.3; 2015.4; 2016.4; 2017.5; Reexam 2018.4 (not g)</li> </ul>"},{"location":"08_Regression/","title":"08 Regression","text":"08 Regression"},{"location":"08_Regression/#material","title":"Material:","text":"<p>ASPE: 11 (not 11.9)</p> <p>Recap notes</p> <p>Session notes</p> <p>Session material</p> <p>Session from 20/21: SMP 8</p>"},{"location":"08_Regression/#topics","title":"Topics","text":"<p>Linear regression is a statistical method used to model the relationship between a dependent variable and one or more independent variables. The key elements of linear regression include the dependent variable, independent variable(s), regression coefficients, intercept, and residual error. The regression coefficients represent the change in the dependent variable associated with a one-unit change in the independent variable, while the intercept represents the expected value of the dependent variable when all independent variables are equal to zero. The residual error is the difference between the observed values of the dependent variable and the values predicted by the regression model. The goal of linear regression is to find the best-fitting line that minimizes the sum of the squared residual errors. Linear regression is a widely used method in various fields to make predictions or estimate the strength and direction of relationships between variables.</p> <ul> <li>Least Squares Estimates</li> <li>Regression Equation</li> <li>Correlation</li> <li>Coefficient of determination</li> <li>Prediction</li> <li>Residual Analysis</li> </ul> <p>I've added a page with all the useful formulas for calculating the parameters as well as the performance metrics, \\(r\\) and \\(r^2\\)</p>"},{"location":"08_Regression/#problems-to-be-worked-on-inafter-class","title":"Problems to be worked on in/after class:","text":"<p>If nothing is noted, assume it is \u201cExam\u201d. If it is the reexam, it will be stated.</p> <ul> <li>2020.4 (not f), 2020.5, 2020.6, 2020.7, Reexam 2018.4, Reexam 2018.5, Reexam 2018.6, 2018.6, 2017.4, 2017.5, 2017.6</li> </ul>"},{"location":"08_Regression/Calculating%20metrics/","title":"Calculating Metrics in Simple Linear Regression","text":""},{"location":"08_Regression/Calculating%20metrics/#the-slope-and-intercept","title":"The Slope (and intercept)","text":"<p>In simple linear regression, the slope parameter (often denoted as \\(\\beta_1\\)) represents the relationship between the independent variable (X) and the dependent variable (Y). The slope indicates how much the dependent variable is expected to increase (or decrease) for a one-unit increase in the independent variable. There are several ways to compute this slope, and here are some of the key methods:</p>"},{"location":"08_Regression/Calculating%20metrics/#least-squares-estimation","title":"Least Squares Estimation:","text":"<p>The most common method for calculating the slope in simple linear regression is the least squares estimation. The formula for the slope (\\(\\beta_1\\)) using this method is:</p> <p>$$\\boxed{    \\beta_1 = \\frac{\\sum_{i=1}^n (x_i - \\overline{x})(y_i - \\overline{y})}{\\sum_{i=1}^n (x_i - \\overline{x})^2}}    $$</p> <p>In this expression: - \\(\\sum_{i=1}^n (x_i - \\overline{x})(y_i - \\overline{y})\\) is the sum of the products of the deviations of \\(x\\) and \\(y\\) from their respective means. This term captures the covariance between \\(x\\) and \\(y\\), indicating how much \\(x\\) and \\(y\\) vary together from their mean values (though excluding \\(\\frac{1}{n-1}\\)). This term is often denoted \\(S_{xy}\\). - \\(\\overline{x}\\) and \\(\\overline{y}\\) are the means of \\(x\\) and \\(y\\), respectively. These are calculated as \\(\\overline{x} = \\frac{1}{n} \\sum_{i=1}^n x_i\\) and \\(\\overline{y} = \\frac{1}{n} \\sum_{i=1}^n y_i\\), where \\(n\\) is the number of observations. - \\(\\sum_{i=1}^n (x_i - \\overline{x})^2\\) represents the sum of the squares of the deviations of \\(x\\) from its mean. This term is a measure of the total variance in \\(x\\) and helps normalize the covariance in the numerator. This term is often denoted \\(S_{xy}\\). - \\(n\\) is the number of observations, indicating the total number of data points in the dataset.</p>"},{"location":"08_Regression/Calculating%20metrics/#sum-of-products","title":"Sum of Products","text":"<p>The fundamental expression for the slope is the one stated above. But we can also use the sum of products which is demonstrated here.</p> <p>Derivation of \\((S_{xy})\\)</p> <p>The regular form for the sum of products of deviations for \\(x\\) and \\(y\\) is: $$ S_{xy} = \\sum_{i=1}^n (x_i - \\overline{x})(y_i - \\overline{y}) $$</p> <p>Expanding this sum: $$ S_{xy} = \\sum_{i=1}^n (x_i y_i - x_i \\overline{y} - y_i \\overline{x} + \\overline{x} \\overline{y}) $$</p> <p>Simplifying this by distributing the summation: $$ S_{xy} = \\sum_{i=1}^n x_i y_i - \\sum_{i=1}^n x_i \\overline{y} - \\sum_{i=1}^n y_i \\overline{x} + n \\overline{x} \\overline{y} $$</p> <p>Notice that $\\sum_{i=1}^n x_i \\overline{y} $ can be rewritten because \\(\\overline{y}\\) is a constant: $$ \\sum_{i=1}^n x_i \\overline{y} = \\overline{y} \\sum_{i=1}^n x_i $$ And similarly for \\(\\sum_{i=1}^n y_i \\overline{x}\\): $$ \\sum_{i=1}^n y_i \\overline{x} = \\overline{x} \\sum_{i=1}^n y_i $$</p> <p>Since \\(\\sum_{i=1}^n x_i = n \\overline{x}\\) and \\(\\sum_{i=1}^n y_i = n \\overline{y}\\), the terms simplify to:  $$ S_{xy} = \\sum_{i=1}^n x_i y_i - n \\overline{x} \\overline{y} $$</p> <p>Derivation of \\(S_{xx}\\)</p> <p>The regular form for the sum of squares of deviations for $ x $ is: $$ S_{xx} = \\sum_{i=1}^n (x_i - \\overline{x})^2 $$</p> <p>Expanding this sum: $$ S_{xx} = \\sum_{i=1}^n (x_i^2 - 2x_i \\overline{x} + \\overline{x}^2) $$</p> <p>Simplifying this by distributing the summation: $$ S_{xx} = \\sum_{i=1}^n x_i^2 - 2\\overline{x} \\sum_{i=1}^n x_i + n\\overline{x}^2 $$</p> <p>Since \\(\\sum_{i=1}^n x_i = n\\overline{x}\\): $$ S_{xx} = \\sum_{i=1}^n x_i^2 - 2n\\overline{x}^2 + n\\overline{x}^2 $$</p> <p>Combining the terms results in:  $$ S_{xx} = \\sum_{i=1}^n x_i^2 - n\\overline{x}^2 $$</p> <p>These derivations provide a clear mathematical pathway from the traditional definitions of $ S_{xy} $ and $ S_{xx} $ to the forms that are easily implemented in a python script for instance, and also means we can also formulate the slope as:</p> <p>$$\\boxed{ \\beta_1 = \\frac{S_{xy}}{S_{xx}} = \\frac{\\sum_{i=1}^n x_i y_i - n \\overline{x} \\overline{y}}{\\sum_{i=1}^n x_i^2 - n\\overline{x}^2}} $$</p>"},{"location":"08_Regression/Calculating%20metrics/#breakdown-using-individual-sum-terms","title":"Breakdown Using Individual Sum Terms","text":"<p>Another way to express this is by explicitly calculating the sums:</p> \\[\\boxed{ \\beta_1=\\frac{n \\sum\\left(x_i y_i\\right)-\\sum x_i \\sum y_i}{n \\sum\\left(x_i^2\\right)-\\left(\\sum x_i\\right)^2}} \\] <p>In this expression: - \\(n\\) is the number of observations., - \\(\\sum\\left(x_i y_i\\right)\\) is the sum of the products of corresponding \\(x\\) and \\(y\\) values, - \\(\\sum x_i\\) and \\(\\sum y_i\\) are the sums of \\(x\\) and \\(y\\) values, respectively, - \\(\\sum\\left(x_i^2\\right)\\) is the sum of the squares of \\(x\\) values.</p>"},{"location":"08_Regression/Calculating%20metrics/#covariance-and-variance-method","title":"Covariance and Variance Method:","text":"<p>This is essentially a rearrangement of the least squares formula, emphasizing the use of covariance and variance:    $$\\boxed{    \\beta_1 = \\frac{\\text{Cov}(X, Y)}{\\text{Var}(X)}}    $$    where: - \\(\\text{Cov}(X, Y) = \\frac{\\sum_{i=1}^n (x_i - \\overline{x})(y_i - \\overline{y})}{n-1}\\) (assuming a sample covariance) - \\(\\text{Var}(X) = \\frac{\\sum_{i=1}^n (x_i - \\overline{x})^2}{n-1}\\) (also assuming sample variance)</p>"},{"location":"08_Regression/Calculating%20metrics/#matrix-algebra-using-normal-equation","title":"Matrix Algebra (Using Normal Equation):","text":"<p>When dealing with linear regression in matrix terms, the slope can be calculated using the normal equation:    $$ \\boxed{    \\beta = (X^T X)^{-1} X^T Y}    $$    Here, \\(X\\) is the matrix of input features (including a column of ones for the intercept if it's included in the model), and \\(Y\\) is the vector of output values, and \\(\\beta\\) is a vector that will contain all the coefficients.</p>"},{"location":"08_Regression/Calculating%20metrics/#gradient-descent","title":"Gradient Descent:","text":"<p>Though not a formula in the traditional sense, gradient descent is an algorithmic approach used to find the minimum of the cost function (typically mean squared error) in regression. The update rule in each iteration for \\(\\beta_1\\) would be:    $$\\boxed{    \\beta_1^{(new)} = \\beta_1^{(old)} - \\alpha \\frac{\\partial}{\\partial \\beta_1} MSE}    $$    where \\(\\alpha\\) is the learning rate and \\(\\frac{\\partial}{\\partial \\beta_1} MSE\\) is the derivative of the mean squared error with respect to \\(\\beta_1\\).</p>"},{"location":"08_Regression/Calculating%20metrics/#regression-line-intercept-inclusion","title":"Regression Line Intercept Inclusion","text":"<p>We will also explain how the slope relates to the intercept in the regression equation, presented here as part of the full regression formula:</p> \\[ y = \\beta_0 + \\beta_1 x \\] <p>where $$ \\beta_1 = \\frac{\\sum_{i=1}^n (x_i - \\overline{x})(y_i - \\overline{y})}{\\sum_{i=1}^n (x_i - \\overline{x})^2} $$ (or one of the alternatives from above) and $$\\boxed{ \\beta_0 = \\overline{y} - \\beta_1 \\overline{x}} $$</p>"},{"location":"08_Regression/Calculating%20metrics/#correlation-coefficient-r-and-correlation-of-determination-r2","title":"Correlation Coefficient (\\(r\\)) and Correlation of Determination (\\(r^2\\))","text":"<p>This section will present different formulations of \\(r\\) or \\(r^2\\). Depending on the formulation, one or the other is shown.</p>"},{"location":"08_Regression/Calculating%20metrics/#pearson-correlation-coefficient-r","title":"Pearson Correlation Coefficient (\\(r\\))","text":"<p>The Pearson correlation coefficient (\\(r\\)) measures the linear correlation between two variables, \\(x\\) and \\(y\\). It is defined as the ratio of the covariance of the variables to the product of their standard deviations. Mathematically, it's expressed as:</p> \\[\\boxed{ r = \\frac{\\sum_{i=1}^n (x_i - \\overline{x})(y_i - \\overline{y})}{\\sqrt{\\sum_{i=1}^n (x_i - \\overline{x})^2 \\sum_{i=1}^n (y_i - \\overline{y})^2}} = \\frac{S_{x y}}{\\sqrt{S_{x x} \\cdot S_{y y}}}} \\] <p>Here, \\(\\overline{x}\\) and \\(\\overline{y}\\) are the means of \\(x\\) and \\(y\\), respectively. This formula essentially scales the covariance between \\(x\\) and \\(y\\) by the product of their standard deviations, ensuring that \\(r\\) is dimensionless and ranges between -1 and +1. Also note</p>"},{"location":"08_Regression/Calculating%20metrics/#coefficient-of-determination-r2","title":"Coefficient of Determination (\\(r^2\\))","text":"<p>The coefficient of determination, known as \\(r^2\\), is the square of the Pearson correlation coefficient. It represents the proportion of the variance in the dependent variable that is predictable from the independent variable(s). It is calculated simply by squaring \\(r\\):</p> \\[\\boxed{ r^2 = \\left(\\frac{\\sum_{i=1}^n (x_i - \\overline{x})(y_i - \\overline{y})}{\\sqrt{\\sum_{i=1}^n (x_i - \\overline{x})^2 \\sum_{i=1}^n (y_i - \\overline{y})^2}}\\right)^2} \\] <p>This value ranges from 0 to 1, where 0 indicates no correlation and 1 indicates perfect correlation.</p>"},{"location":"08_Regression/Calculating%20metrics/#alternate-formulas-for-r-and-r2-in-the-context-of-regression","title":"Alternate Formulas for \\(r\\) and \\(r^2\\) in the Context of Regression","text":"<p>In the context of simple linear regression, where you have calculated the slope (\\(\\beta_1\\)) and the intercept (\\(\\beta_0\\)), \\(r\\) and \\(r^2\\) can also be calculated directly from the regression output:</p>"},{"location":"08_Regression/Calculating%20metrics/#using-standard-deviations-and-slope","title":"Using Standard Deviations and Slope:","text":"<p>$$\\boxed{   r = \\beta_1 \\frac{s_x}{s_y}}   $$   where \\(s_x\\) and \\(s_y\\) are the standard deviations of \\(x\\) and \\(y\\), respectively, and \\(\\beta_1\\) is the slope of the regression line. This formula derives from the relationship that the slope of the regression line in standardized units is the correlation coefficient. Note, \\(s_x = \\sqrt{S_{xx}}\\) and Note, \\(s_y = \\sqrt{S_{yy}}\\), in both cases omitting \\(\\frac{1}{n-1}\\).</p>"},{"location":"08_Regression/Calculating%20metrics/#from-the-sum-of-squares","title":"From the Sum of Squares:","text":"<p>$$\\boxed{   r^2 = \\frac{SSR}{SST} = 1-\\frac{SSE}{SST}}   $$</p> <p>In regression analysis, the total sum of squares (SST), the regression sum of squares (SSR), and the sum of squares of errors (SSE) are important quantities for measuring the variability in the data and the performance of the regression model.</p> <ul> <li> <p>Total Sum of Squares (SST)</p> <p>The Total Sum of Squares measures the total variability of the dataset relative to the mean. It is calculated as: $$ \\text{SST} = \\sum_{i=1}^n (y_i - \\overline{y})^2 $$ where \\(y_i\\) are the observed values and \\(\\overline{y}\\) is the mean of the \\(y\\) values.</p> </li> <li> <p>Regression Sum of Squares (SSR)</p> <p>The Regression Sum of Squares measures how much of the total variability in the dependent variable can be explained by the independent variable(s) in the model. It is calculated as: $$ \\text{SSR} = \\sum_{i=1}^n (\\hat{y}_i - \\overline{y})^2 $$ where \\(\\hat{y}_i\\) are the predicted values from the regression model.</p> </li> <li> <p>Sum of Squares of Errors (SSE)</p> <p>The Sum of Squares of Errors measures the variability of the model errors (residuals). It is calculated as: $$ \\text{SSE} = \\sum_{i=1}^n (y_i - \\hat{y}_i)^2 $$ where \\(y_i\\) are the observed values and \\(\\hat{y}_i\\) are the predicted values from the regression model.</p> </li> </ul> <p>These three components are related by the identity:    $$    \\text{SST} = \\text{SSR} + \\text{SSE}    $$    This identity shows that the total variability in the dataset (\\(\\text{SST}\\)) can be decomposed into the variability explained by the regression model (\\(\\text{SSR}\\)) and the variability that is not explained by the model (\\(\\text{SSE}\\)).</p> <p>Each of these formulas provides insight into different aspects of the regression analysis, such as the effectiveness of the model in explaining the variation in the data and the amount of error in the predictions.</p>"},{"location":"08_Regression/Calculating%20metrics/#from-the-z-scores","title":"From the \\(z\\)-scores:","text":"<p>The formula for calculating the Pearson correlation coefficient using standardized scores is:</p> \\[\\boxed{ r = \\frac{\\sum (z_x \\cdot z_y)}{n-1}} \\] <p>where: - \\(z_x = \\frac{x - \\overline{x}}{s_x}\\) and \\(z_y = \\frac{y - \\overline{y}}{s_y}\\) are the standardized scores of \\(x\\) and \\(y\\).  - \\(\\overline{x}\\) and \\(\\overline{y}\\) are the means of \\(x\\) and \\(y\\), respectively. - \\(s_x\\) and \\(s_y\\) are the standard deviations of \\(x\\) and \\(y\\), respectively. - The numerator, \\(\\sum (z_x \\cdot z_y)\\), represents the sum of the products of these standardized scores, effectively capturing the covariance of \\(x\\) and \\(y\\). - The denominator, \\(n-1\\), corrects for the bias in variance estimation from a sample, making the calculation an unbiased estimator of the population correlation coefficient.</p> <p>This approach normalizes both variables to have zero mean and unit variance, simplifying the interpretation of the correlation coefficient as it directly measures the degree of linear relationship between the standardized versions of the original variables.</p>"},{"location":"08_Regression/Calculating%20metrics/#breakdown-using-individual-sum-terms_1","title":"Breakdown Using Individual Sum Terms:","text":"<p>$$\\boxed{   r = \\frac{n \\cdot \\sum (x_i y_i) - \\sum x_i \\cdot \\sum y_i}{\\sqrt{n \\cdot \\sum x_i^2 - (\\sum x_i)^2} \\cdot \\sqrt{n \\cdot y_i^2 - (\\sum y_i)^2}}}   $$</p> <p>where:   - $ \\sum (x_i y_i) $ is the sum of the products of corresponding $ x $ and $ y $ values.   - $ \\sum x_i $ and $ \\sum y_i $ are the sums of all $ x $ values and $ y $ values, respectively.   - $ \\sum x_i^2 $ and $ \\sum y_i^2 $ are the sums of the squares of all $ x $ and $ y $ values, respectively.   - The term $ n $ is the number of data points.</p> <p>The denominator involves the square roots of the products of $ n $ and the sum of squares of $ x $ and $ y $, minus the square of the sum of $ x $ and $ y $ values, all scaled by $ n $. This structure follows the formula for the standard deviation, scaled to the sample size to adjust for bias, fitting the denominator of the correlation coefficient formula. This formula effectively measures the strength and direction of a linear relationship between two variables.</p>"},{"location":"08_Regression/Calculating%20metrics/#example-exam-2020-asignment-7","title":"Example: Exam 2020, Asignment 7:","text":"<p>Problem:</p> <p>A professor in the School of Engineering in a university polled a dozen colleagues about the number of professional meetings they attended in the past five years \\((x)\\) and the number of papers they submitted to refereed journals \\((y)\\) during the same period. The summary data are given as follows: $$ \\begin{aligned} n &amp; =12, \\quad \\bar{x}=4, \\quad \\bar{y}=12 \\ \\sum_{i=1}^n x_i^2 &amp; =232, \\quad \\sum_{i=1}^n x_i y_i=318 \\end{aligned} $$</p> <p>Fit a simple linear regression model between \\(x\\) and \\(y\\) by finding out the estimates of intercept and slope. Hint: Use the Least Squares Estimates formula from the book.</p> <p>Solution:</p> <p>Given the values, we can use one of the variations provided earlier:</p> \\[ \\beta_1 = \\frac{\\sum_{i=1}^n x_i y_i - n \\overline{x} \\overline{y}}{\\sum_{i=1}^n x_i^2 - n \\overline{x}^2} \\] <p>Let's plug in the values:</p> <ul> <li>\\(n = 12\\)</li> <li>\\(\\overline{x} = 4\\)</li> <li>\\(\\overline{y} = 12\\)</li> <li>\\(\\sum_{i=1}^n x_i^2 = 232\\)</li> <li>\\(\\sum_{i=1}^n x_i y_i = 318\\)</li> </ul> <p>Calculating \\(\\beta_1\\):</p> \\[ \\beta_1 = \\frac{318 - 12 \\times 4 \\times 12}{232 - 12 \\times 4^2} \\] <p>In the solution, the following formula, also presented above, is used:</p> \\[ \\beta_1=\\frac{n \\sum\\left(x_i y_i\\right)-\\sum x_i \\sum y_i}{n \\sum\\left(x_i^2\\right)-\\left(\\sum x_i\\right)^2} \\] <p>Plugging these values into the formula: $$ \\beta_1=\\frac{(12)(318)-[(12)(4)][(12)(12)]}{(12)(232)-[(12)(4)]^2} $$</p> <p>Once we have \\(\\beta_1\\), we can calculate the intercept \\(\\beta_0\\) using the formula:</p> \\[ \\beta_0 = \\overline{y} - \\beta_1 \\overline{x} \\] <p>We'll compute \\(\\beta_1\\) first and then use it to find \\(\\beta_0\\).</p> <p>Using the provided data, the estimated parameters for your linear regression model are:</p> <ul> <li>Slope (\\(\\beta_1\\)): \\(-6.45\\)</li> <li>Intercept (\\(\\beta_0\\)): \\(37.8\\)</li> </ul> <p>Thus, the fitted linear regression model can be expressed as: $$ y = 37.8 - 6.45x $$ This equation predicts the value of \\(y\\) based on the value of \\(x\\), with the model suggesting that \\(y\\) decreases by approximately 6.45 units for every one unit increase in \\(x\\).</p>"},{"location":"08_Regression/Test/","title":"Calculating Metrics in Simple Linear Regression","text":""},{"location":"08_Regression/Test/#the-slope-and-intercept","title":"The Slope (and intercept)","text":"<p>In simple linear regression, the slope parameter (often denoted as \\(\\beta_1\\)) represents the relationship between the independent variable (X) and the dependent variable (Y). The slope indicates how much the dependent variable is expected to increase (or decrease) for a one-unit increase in the independent variable. There are several ways to compute this slope, and here are some of the key methods:</p>"},{"location":"08_Regression/Test/#least-squares-estimation","title":"Least Squares Estimation:","text":"<p>The most common method for calculating the slope in simple linear regression is the least squares estimation. The formula for the slope (\\(\\beta_1\\)) using this method is:</p> \\[\\beta_1=\\frac{\\sum_{i=1}^n\\left(x_i-\\bar{x}\\right)\\left(y_i-\\bar{y}\\right)}{\\sum_{i=1}^n\\left(x_i-\\bar{x}\\right)^2}\\] <p>In this expression:</p> <p>\\(\\sum_{i=1}^n (x_i - \\overline{x})(y_i - \\overline{y})\\) is the sum of the products of the deviations of \\(x\\) and \\(y\\) from their respective means. This term captures the covariance between \\(x\\) and \\(y\\), indicating how much \\(x\\) and \\(y\\) vary together from their mean values (though excluding \\(\\frac{1}{n-1}\\)). This term is often denoted \\(S_{xy}\\).</p> <p>\\(\\overline{x}\\) and \\(\\overline{y}\\) are the means of \\(x\\) and \\(y\\), respectively. These are calculated as \\(\\overline{x} = \\frac{1}{n} \\sum_{i=1}^n x_i\\) and </p> <p>\\(\\overline{y} = \\frac{1}{n} \\sum_{i=1}^n y_i\\), where \\(n\\) is the number of observations.</p> <p>\\(\\sum_{i=1}^n (x_i - \\overline{x})^2\\) represents the sum of the squares of the deviations of \\(x\\) from its mean. This term is a measure of the total variance in \\(x\\) and helps normalize the covariance in the numerator. This term is often denoted \\(S_{xy}\\).</p> <p>\\(n\\) is the number of observations, indicating the total number of data points in the dataset.</p>"},{"location":"08_Regression/Test/#sum-of-products","title":"Sum of Products","text":"<p>The fundamental expression for the slope is the one stated above. But we can also use the sum of products which is demonstrated here.</p> <p>Derivation of \\((S_{xy})\\)</p> <p>The regular form for the sum of products of deviations for \\(x\\) and \\(y\\) is: \\(\\(S_{xy} = \\sum_{i=1}^n (x_i - \\overline{x})(y_i - \\overline{y})\\)\\)</p> <p>Expanding this sum: \\(\\(S_{xy} = \\sum_{i=1}^n (x_i y_i - x_i \\overline{y} - y_i \\overline{x} + \\overline{x} \\overline{y})\\)\\)</p> <p>Simplifying this by distributing the summation: \\(\\(S_{xy} = \\sum_{i=1}^n x_i y_i - \\sum_{i=1}^n x_i \\overline{y} - \\sum_{i=1}^n y_i \\overline{x} + n \\overline{x} \\overline{y}\\)\\)</p> <p>Notice that $\\sum_{i=1}^n x_i \\overline{y} $ can be rewritten because \\(\\overline{y}\\) is a constant: \\(\\(\\sum_{i=1}^n x_i \\overline{y} = \\overline{y} \\sum_{i=1}^n x_i\\)\\) And similarly for \\(\\sum_{i=1}^n y_i \\overline{x}\\): \\(\\(\\sum_{i=1}^n y_i \\overline{x} = \\overline{x} \\sum_{i=1}^n y_i\\)\\)</p> <p>Since \\(\\sum_{i=1}^n x_i = n \\overline{x}\\) and \\(\\sum_{i=1}^n y_i = n \\overline{y}\\), the terms simplify to: \\(\\(S_{xy} = \\sum_{i=1}^n x_i y_i - n \\overline{x} \\overline{y}\\)\\)</p> <p>Derivation of \\(S_{xx}\\)</p> <p>The regular form for the sum of squares of deviations for $ x $ is: \\(\\(S_{xx} = \\sum_{i=1}^n (x_i - \\overline{x})^2\\)\\)</p> <p>Expanding this sum: \\(\\(S_{xx} = \\sum_{i=1}^n (x_i^2 - 2x_i \\overline{x} + \\overline{x}^2)\\)\\)</p> <p>Simplifying this by distributing the summation: \\(\\(S_{xx} = \\sum_{i=1}^n x_i^2 - 2\\overline{x} \\sum_{i=1}^n x_i + n\\overline{x}^2\\)\\)</p> <p>Since \\(\\sum_{i=1}^n x_i = n\\overline{x}\\): \\(\\(S_{xx} = \\sum_{i=1}^n x_i^2 - 2n\\overline{x}^2 + n\\overline{x}^2\\)\\)</p> <p>Combining the terms results in: \\(\\(S_{xx} = \\sum_{i=1}^n x_i^2 - n\\overline{x}^2\\)\\)</p> <p>These derivations provide a clear mathematical pathway from the traditional definitions of $ S_{xy} $ and $ S_{xx} $ to the forms that are easily implemented in a python script for instance, and also means we can also formulate the slope as:</p> \\[\\boxed{\\beta_1 = \\frac{S_{xy}}{S_{xx}} = \\frac{\\sum_{i=1}^n x_i y_i - n \\overline{x} \\overline{y}}{\\sum_{i=1}^n x_i^2 - n\\overline{x}^2}}\\]"},{"location":"08_Regression/Test/#breakdown-using-individual-sum-terms","title":"Breakdown Using Individual Sum Terms","text":"<p>Another way to express this is by explicitly calculating the sums:</p> \\[\\boxed{\\beta_1=\\frac{n \\sum\\left(x_i y_i\\right)-\\sum x_i \\sum y_i}{n \\sum\\left(x_i^2\\right)-\\left(\\sum x_i\\right)^2}}\\] <p>In this expression: - \\(n\\) is the number of observations., - \\(\\sum\\left(x_i y_i\\right)\\) is the sum of the products of corresponding \\(x\\) and \\(y\\) values, - \\(\\sum x_i\\) and \\(\\sum y_i\\) are the sums of \\(x\\) and \\(y\\) values, respectively, - \\(\\sum\\left(x_i^2\\right)\\) is the sum of the squares of \\(x\\) values.</p>"},{"location":"08_Regression/Test/#covariance-and-variance-method","title":"Covariance and Variance Method:","text":"<p>This is essentially a rearrangement of the least squares formula, emphasizing the use of covariance and variance:    \\(\\(\\boxed{\\beta_1 = \\frac{\\text{Cov}(X, Y)}{\\text{Var}(X)}}\\)\\)    where: - \\(\\text{Cov}(X, Y) = \\frac{\\sum_{i=1}^n (x_i - \\overline{x})(y_i - \\overline{y})}{n-1}\\) (assuming a sample covariance) - \\(\\text{Var}(X) = \\frac{\\sum_{i=1}^n (x_i - \\overline{x})^2}{n-1}\\) (also assuming sample variance)</p>"},{"location":"08_Regression/Test/#matrix-algebra-using-normal-equation","title":"Matrix Algebra (Using Normal Equation):","text":"<p>When dealing with linear regression in matrix terms, the slope can be calculated using the normal equation:    $$ \\boxed{\\beta = (X^T X)^{-1} X^T Y}$$    Here, \\(X\\) is the matrix of input features (including a column of ones for the intercept if it's included in the model), and \\(Y\\) is the vector of output values, and \\(\\beta\\) is a vector that will contain all the coefficients.</p>"},{"location":"08_Regression/Test/#gradient-descent","title":"Gradient Descent:","text":"<p>Though not a formula in the traditional sense, gradient descent is an algorithmic approach used to find the minimum of the cost function (typically mean squared error) in regression. The update rule in each iteration for \\(\\beta_1\\) would be:    \\(\\(\\boxed{\\beta_1^{(new)} = \\beta_1^{(old)} - \\alpha \\frac{\\partial}{\\partial \\beta_1} MSE}\\)\\)    where \\(\\alpha\\) is the learning rate and \\(\\frac{\\partial}{\\partial \\beta_1} MSE\\) is the derivative of the mean squared error with respect to \\(\\beta_1\\).</p>"},{"location":"08_Regression/Test/#regression-line-intercept-inclusion","title":"Regression Line Intercept Inclusion","text":"<p>We will also explain how the slope relates to the intercept in the regression equation, presented here as part of the full regression formula:</p> \\[y = \\beta_0 + \\beta_1 x\\] <p>where \\(\\(\\beta_1 = \\frac{\\sum_{i=1}^n (x_i - \\overline{x})(y_i - \\overline{y})}{\\sum_{i=1}^n (x_i - \\overline{x})^2}\\)\\) (or one of the alternatives from above) and \\(\\(\\boxed{\\beta_0 = \\overline{y} - \\beta_1 \\overline{x}}\\)\\)</p>"},{"location":"08_Regression/Test/#correlation-coefficient-r-and-correlation-of-determination-r2","title":"Correlation Coefficient (\\(r\\)) and Correlation of Determination (\\(r^2\\))","text":"<p>This section will present different formulations of \\(r\\) or \\(r^2\\). Depending on the formulation, one or the other is shown.</p>"},{"location":"08_Regression/Test/#pearson-correlation-coefficient-r","title":"Pearson Correlation Coefficient (\\(r\\))","text":"<p>The Pearson correlation coefficient (\\(r\\)) measures the linear correlation between two variables, \\(x\\) and \\(y\\). It is defined as the ratio of the covariance of the variables to the product of their standard deviations. Mathematically, it's expressed as:</p> \\[\\boxed{r = \\frac{\\sum_{i=1}^n (x_i - \\overline{x})(y_i - \\overline{y})}{\\sqrt{\\sum_{i=1}^n (x_i - \\overline{x})^2 \\sum_{i=1}^n (y_i - \\overline{y})^2}} = \\frac{S_{x y}}{\\sqrt{S_{x x} \\cdot S_{y y}}}}\\] <p>Here, \\(\\overline{x}\\) and \\(\\overline{y}\\) are the means of \\(x\\) and \\(y\\), respectively. This formula essentially scales the covariance between \\(x\\) and \\(y\\) by the product of their standard deviations, ensuring that \\(r\\) is dimensionless and ranges between -1 and +1. Also note</p>"},{"location":"08_Regression/Test/#coefficient-of-determination-r2","title":"Coefficient of Determination (\\(r^2\\))","text":"<p>The coefficient of determination, known as \\(r^2\\), is the square of the Pearson correlation coefficient. It represents the proportion of the variance in the dependent variable that is predictable from the independent variable(s). It is calculated simply by squaring \\(r\\):</p> \\[\\boxed{r^2 = \\left(\\frac{\\sum_{i=1}^n (x_i - \\overline{x})(y_i - \\overline{y})}{\\sqrt{\\sum_{i=1}^n (x_i - \\overline{x})^2 \\sum_{i=1}^n (y_i - \\overline{y})^2}}\\right)^2}\\] <p>This value ranges from 0 to 1, where 0 indicates no correlation and 1 indicates perfect correlation.</p>"},{"location":"08_Regression/Test/#alternate-formulas-for-r-and-r2-in-the-context-of-regression","title":"Alternate Formulas for \\(r\\) and \\(r^2\\) in the Context of Regression","text":"<p>In the context of simple linear regression, where you have calculated the slope (\\(\\beta_1\\)) and the intercept (\\(\\beta_0\\)), \\(r\\) and \\(r^2\\) can also be calculated directly from the regression output:</p>"},{"location":"08_Regression/Test/#using-standard-deviations-and-slope","title":"Using Standard Deviations and Slope:","text":"<p>\\(\\(\\boxed{r = \\beta_1 \\frac{s_x}{s_y}}\\)\\)   where \\(s_x\\) and \\(s_y\\) are the standard deviations of \\(x\\) and \\(y\\), respectively, and \\(\\beta_1\\) is the slope of the regression line. This formula derives from the relationship that the slope of the regression line in standardized units is the correlation coefficient. Note, \\(s_x = \\sqrt{S_{xx}}\\) and Note, \\(s_y = \\sqrt{S_{yy}}\\), in both cases omitting \\(\\frac{1}{n-1}\\).</p>"},{"location":"08_Regression/Test/#from-the-sum-of-squares","title":"From the Sum of Squares:","text":"<p>\\(\\(\\boxed{r^2 = \\frac{SSR}{SST} = 1-\\frac{SSE}{SST}}\\)\\)</p> <p>In regression analysis, the total sum of squares (SST), the regression sum of squares (SSR), and the sum of squares of errors (SSE) are important quantities for measuring the variability in the data and the performance of the regression model.</p> <ul> <li> <p>Total Sum of Squares (SST)</p> <p>The Total Sum of Squares measures the total variability of the dataset relative to the mean. It is calculated as: \\(\\(\\text{SST} = \\sum_{i=1}^n (y_i - \\overline{y})^2\\)\\) where \\(y_i\\) are the observed values and \\(\\overline{y}\\) is the mean of the \\(y\\) values.</p> </li> <li> <p>Regression Sum of Squares (SSR)</p> <p>The Regression Sum of Squares measures how much of the total variability in the dependent variable can be explained by the independent variable(s) in the model. It is calculated as: \\(\\(\\text{SSR} = \\sum_{i=1}^n (\\hat{y}_i - \\overline{y})^2\\)\\) where \\(\\hat{y}_i\\) are the predicted values from the regression model.</p> </li> <li> <p>Sum of Squares of Errors (SSE)</p> <p>The Sum of Squares of Errors measures the variability of the model errors (residuals). It is calculated as: \\(\\(\\text{SSE} = \\sum_{i=1}^n (y_i - \\hat{y}_i)^2\\)\\) where \\(y_i\\) are the observed values and \\(\\hat{y}_i\\) are the predicted values from the regression model.</p> </li> </ul> <p>These three components are related by the identity:    \\(\\(\\text{SST} = \\text{SSR} + \\text{SSE}\\)\\)    This identity shows that the total variability in the dataset (\\(\\text{SST}\\)) can be decomposed into the variability explained by the regression model (\\(\\text{SSR}\\)) and the variability that is not explained by the model (\\(\\text{SSE}\\)).</p> <p>Each of these formulas provides insight into different aspects of the regression analysis, such as the effectiveness of the model in explaining the variation in the data and the amount of error in the predictions.</p>"},{"location":"08_Regression/Test/#from-the-z-scores","title":"From the \\(z\\)-scores:","text":"<p>The formula for calculating the Pearson correlation coefficient using standardized scores is:</p> \\[\\boxed{r = \\frac{\\sum (z_x \\cdot z_y)}{n-1}}\\] <p>where: - \\(z_x = \\frac{x - \\overline{x}}{s_x}\\) and \\(z_y = \\frac{y - \\overline{y}}{s_y}\\) are the standardized scores of \\(x\\) and \\(y\\).  - \\(\\overline{x}\\) and \\(\\overline{y}\\) are the means of \\(x\\) and \\(y\\), respectively. - \\(s_x\\) and \\(s_y\\) are the standard deviations of \\(x\\) and \\(y\\), respectively. - The numerator, \\(\\sum (z_x \\cdot z_y)\\), represents the sum of the products of these standardized scores, effectively capturing the covariance of \\(x\\) and \\(y\\). - The denominator, \\(n-1\\), corrects for the bias in variance estimation from a sample, making the calculation an unbiased estimator of the population correlation coefficient.</p> <p>This approach normalizes both variables to have zero mean and unit variance, simplifying the interpretation of the correlation coefficient as it directly measures the degree of linear relationship between the standardized versions of the original variables.</p>"},{"location":"08_Regression/Test/#breakdown-using-individual-sum-terms_1","title":"Breakdown Using Individual Sum Terms:","text":"<p>\\(\\(\\boxed{r = \\frac{n \\cdot \\sum (x_i y_i) - \\sum x_i \\cdot \\sum y_i}{\\sqrt{n \\cdot \\sum x_i^2 - (\\sum x_i)^2} \\cdot \\sqrt{n \\cdot y_i^2 - (\\sum y_i)^2}}}\\)\\)</p> <p>where:   - $ \\sum (x_i y_i) $ is the sum of the products of corresponding $ x $ and $ y $ values.   - $ \\sum x_i $ and $ \\sum y_i $ are the sums of all $ x $ values and $ y $ values, respectively.   - $ \\sum x_i^2 $ and $ \\sum y_i^2 $ are the sums of the squares of all $ x $ and $ y $ values, respectively.   - The term $ n $ is the number of data points.</p> <p>The denominator involves the square roots of the products of $ n $ and the sum of squares of $ x $ and $ y $, minus the square of the sum of $ x $ and $ y $ values, all scaled by $ n $. This structure follows the formula for the standard deviation, scaled to the sample size to adjust for bias, fitting the denominator of the correlation coefficient formula. This formula effectively measures the strength and direction of a linear relationship between two variables.</p>"},{"location":"08_Regression/Test/#example-exam-2020-asignment-7","title":"Example: Exam 2020, Asignment 7:","text":"<p>Problem:</p> <p>A professor in the School of Engineering in a university polled a dozen colleagues about the number of professional meetings they attended in the past five years \\((x)\\) and the number of papers they submitted to refereed journals \\((y)\\) during the same period. The summary data are given as follows: \\(\\(\\begin{aligned} n &amp; =12, \\quad \\bar{x}=4, \\quad \\bar{y}=12 \\\\ \\sum_{i=1}^n x_i^2 &amp; =232, \\quad \\sum_{i=1}^n x_i y_i=318 \\end{aligned}\\)\\)</p> <p>Fit a simple linear regression model between \\(x\\) and \\(y\\) by finding out the estimates of intercept and slope. Hint: Use the Least Squares Estimates formula from the book.</p> Click here to see the solution <p>Given the values, we can use one of the variations provided earlier:  $$\\beta_1 = \\frac{\\sum_{i=1}^n x_i y_i - n \\overline{x} \\overline{y}}{\\sum_{i=1}^n x_i^2 - n \\overline{x}^2}$$  Let's plug in the values:  - $n = 12$ - $\\overline{x} = 4$ - $\\overline{y} = 12$ - $\\sum_{i=1}^n x_i^2 = 232$ - $\\sum_{i=1}^n x_i y_i = 318$  Calculating $\\beta_1$:  $$\\beta_1 = \\frac{318 - 12 \\times 4 \\times 12}{232 - 12 \\times 4^2}$$  In the solution, the following formula, also presented above, is used:  $$\\beta_1=\\frac{n \\sum\\left(x_i y_i\\right)-\\sum x_i \\sum y_i}{n \\sum\\left(x_i^2\\right)-\\left(\\sum x_i\\right)^2}$$  Plugging these values into the formula: $$\\beta_1=\\frac{(12)(318)-[(12)(4)][(12)(12)]}{(12)(232)-[(12)(4)]^2}$$   Once we have $\\beta_1$, we can calculate the intercept $\\beta_0$ using the formula:  $$\\beta_0 = \\overline{y} - \\beta_1 \\overline{x}$$  We'll compute $\\beta_1$ first and then use it to find $\\beta_0$.  Using the provided data, the estimated parameters for your linear regression model are:  - Slope ($\\beta_1$): $-6.45$ - Intercept ($\\beta_0$): $37.8$  Thus, the fitted linear regression model can be expressed as: $$y = 37.8 - 6.45x$$ This equation predicts the value of $y$ based on the value of $x$, with the model suggesting that $y$ decreases by approximately 6.45 units for every one unit increase in $x$.</p>"},{"location":"09_Introduction_to_Stochastic_Processes/","title":"09 Introduction to Stochastic Processes","text":"09 Introduction to Stochastic Processes"},{"location":"09_Introduction_to_Stochastic_Processes/#material","title":"Material:","text":"<p>Markov Chains Ch. 1 (the rest is not in the syllabus)</p> <p>Matrix Algebra (optional)</p> <p>Recap Regression</p> <p>Session notes</p> <p>Session material</p> <p>Session from 20/21: SMP 9</p>"},{"location":"09_Introduction_to_Stochastic_Processes/#topics","title":"Topics","text":"<p>The topics of this and next week require a bit of knowledge of matrices and matrix algebra. I recommend reading \u201cMatrix Algebra\u201d which is the chapter we use from the Linear Algebra course. If you already passed the Linear Algebra course (i.e. you are on your 7<sup>th</sup> semester), you will probably not need to worry about this prerequisite.</p> <p>Stochastic processes are mathematical models used to describe the evolution of systems that involve randomness. The most important elements of stochastic processes are their underlying probability distributions and the properties of their randomness, such as stationarity, independence, and Markovianity. The probability distribution of a stochastic process describes the likelihood of different possible outcomes at any given time, while the properties of randomness determine how the outcomes are related to each other over time. Stochastic processes can be classified into discrete-time or continuous-time, and they can be used to model a wide range of phenomena, including financial markets, stock prices, traffic flow, weather patterns, and biological systems.</p> <ul> <li>What is a random/stochastic process (as opposed to a random variable)?</li> <li>Poisson process</li> <li>Random walk</li> <li>Markov chains</li> </ul> <p>The first two items are not directly covered in the literature and will be based on what I go through during class.</p>"},{"location":"09_Introduction_to_Stochastic_Processes/#problems-to-be-worked-on-inafter-class","title":"Problems to be worked on in/after class:","text":"<p>None specifically, but do some Wiseflow exercises</p>"},{"location":"10_Markov_Chains/","title":"10 Markov Chains","text":"10 Markov Chains <p>Material:</p> <p>Recap notes</p> <p>Session notes</p> <p>Session material</p> <p>Session from 20/21: SMP 10</p>"},{"location":"10_Markov_Chains/#topics","title":"Topics","text":"<p>Markov chains are a mathematical framework used to model systems that change over time, such as the weather or the stock market. The key feature of a Markov chain is that it assumes that the future state of the system depends only on its current state, and not on any previous states. This is known as the Markov property. Markov chains are defined by a set of states, a transition matrix that describes the probabilities of moving from one state to another, and an initial state. The long-term behavior of a Markov chain can be analyzed using techniques such as finding the stationary distribution or calculating expected values. Markov chains are used in a wide range of applications, including computer science, physics, finance, and biology, among others.</p> <ul> <li>Markov property: The assumption that the future state of a system depends only on its current state, and not on any previous states.</li> <li>State: A possible condition or configuration of the system being modeled.</li> <li>Transition matrix: A matrix that describes the probabilities of moving from one state to another.</li> <li>Stationary distribution: The long-term distribution of states that a Markov chain approaches over time.</li> <li>Expected value: The average value that a variable takes over many iterations of the Markov chain.</li> </ul>"},{"location":"10_Markov_Chains/#problems-to-be-worked-on-in-class","title":"Problems to be worked on in class:","text":"<p>Do Problems 10 and the Wiseflow exam cases covering the final topics.</p>"},{"location":"11_Recap_and_Exercises_Markov_Chains/","title":"11 Recap and Exercises","text":"11 Recap and Exercises Markov Chains <p>Material:</p> <p>Session notes</p> <p>Session exercises - Problems 10</p> <p>Session material</p>"},{"location":"11_Recap_and_Exercises_Markov_Chains/#topics","title":"Topics","text":"<p>Recap and exercises in last weeks topic.</p>"},{"location":"11_Recap_and_Exercises_Markov_Chains/#problems-to-be-worked-on-in-class","title":"Problems to be worked on in class:","text":"<p>Do Problems the Wiseflow exam cases covering the final topics as well as previous exams in Wiseflow.</p>"},{"location":"Sessions/","title":"Sessions","text":"<p>Click on a session to the left to access a plan of a specific session and additional resources for that session.</p> Session Date Topic 00 Important Recap 01 4 Feb 12:45 \u2013 16:05 Introduction + Recap Probability + Stochastic Variables 02 11 Feb 12:45 \u2013 16:05 Discrete Random Variables 03 18 Feb 12:45 \u2013 16:05 Continuous Random Variables 04 25 Feb 12:45 \u2013 16:05 Multivariate Random Variables 05 4 Mar 12:45 \u2013 16:05 Point Estimation and sampling 06 11 Mar 12:45 \u2013 16:05 Statistical Intervals 07 25 Mar 12:45 \u2013 16:05 Hypothesis Testing 08 1 Apr 12:45 \u2013 16:05 Regression 09 8 Apr 12:45 \u2013 16:05 Introduction to Stochastic Processes 10 22 Apr 12:45 \u2013 16:05 Markov Chains 11 29 Apr 12:45 \u2013 16:05 Recap and Exercises Markov Chains"},{"location":"blog/","title":"Blog","text":""},{"location":"pages/exam/","title":"Eksamen","text":"<p>Eksamen best\u00e5r af tre dele, der samlet skal bed\u00f8mmes til best\u00e5et for at best\u00e5 eksamen. De tre dele er:</p> <ol> <li> <p>En skriftlig hjemmeopgave i form af en rapport. Rapporten m\u00e5 maksimalt have et omfang p\u00e5 5 sider \u00e1 2.400 anslag inklusive mellemrum, men eksklusiv indholdsfortegnelse, litteraturliste og eventuelle bilag. Rapporten m\u00e5 skrives individuelt eller i grupper af maksimalt 3 studerende. For hvert ekstra medlem i en gruppe, m\u00e5 der skrives 1 side \u00e1 2.400 anslag yderligere. Opgaven t\u00e6ller 1 ECTS. S\u00e5fremt hverken rapporten eller den samlede eksamen er best\u00e5et, skal rapporten genafleveres til reeksamen.</p> </li> <li> <p>En skriftlig 3 timers individuel stedpr\u00f8ve i form af en bunden opgave. Opgaven t\u00e6ller 2 ECTS. S\u00e5fremt hverken opgaven eller den samlede eksamen er best\u00e5et, skal opgaven genafleveres til reeksamen.</p> </li> <li> <p>En skriftlig 1 times individuel MCQ-pr\u00f8ve. Pr\u00f8ven t\u00e6ller 1 ECTS. S\u00e5fremt hverken pr\u00f8ven eller den samlede eksamen er best\u00e5et, skal pr\u00f8ven genafleveres til reeksamen.</p> </li> </ol>"},{"location":"pages/faq/","title":"FAQ","text":""},{"location":"pages/faq/#generelt-om-kurset","title":"Generelt om kurset","text":"Hvad er kursets m\u00e5l og l\u00e6ringsudbytte? <p>Kursets m\u00e5l er at give de studerende en grundl\u00e6ggende forst\u00e5else af...</p> <p>L\u00e6ringsudbytte inkluderer: - Forst\u00e5else af centrale begreber. - Anvendelse af teorier i praksis.</p> Hvordan relaterer kurset sig til min uddannelse? <p>Kurset er en integreret del af uddannelsens fokus p\u00e5...</p>"},{"location":"pages/faq/#eksamen-og-vurdering","title":"Eksamen og vurdering","text":"Hvordan bliver jeg vurderet? <p>Du bliver vurderet gennem: - En skriftlig eksamen (50%). - Et gruppeprojekt (50%).</p> Hvorn\u00e5r og hvordan afholdes eksamen? <p>Eksamen afholdes i slutningen af semesteret. Detaljer findes i kursusplanen.</p>"},{"location":"pages/faq/#teknisk-support","title":"Teknisk support","text":"Hvad g\u00f8r jeg, hvis jeg oplever tekniske problemer? <p>Hvis du oplever tekniske problemer, kan du: - Kontakte support via helpdesk@example.com. - Tjekke vejledningen i kursusmaterialet.</p>"}]}